{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RL.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "WBSiyWnz8oOT",
        "colab_type": "code",
        "outputId": "5f105a89-994a-4088-fc35-ffd58ead6303",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 629
        }
      },
      "source": [
        "!pip install gym\n",
        "!apt-get install python-opengl -y\n",
        "!apt install xvfb -y\n",
        "!pip install pyvirtualdisplay\n",
        "!pip install piglet\n",
        "!pip install gym[atari]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gym in /usr/local/lib/python3.6/dist-packages (0.17.2)\n",
            "Requirement already satisfied: cloudpickle<1.4.0,>=1.2.0 in /usr/local/lib/python3.6/dist-packages (from gym) (1.3.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from gym) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.6/dist-packages (from gym) (1.18.4)\n",
            "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.6/dist-packages (from gym) (1.5.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym) (0.16.0)\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "python-opengl is already the newest version (3.1.0+dfsg-1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 31 not upgraded.\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "xvfb is already the newest version (2:1.19.6-1ubuntu4.4).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 31 not upgraded.\n",
            "Requirement already satisfied: pyvirtualdisplay in /usr/local/lib/python3.6/dist-packages (1.3)\n",
            "Requirement already satisfied: EasyProcess in /usr/local/lib/python3.6/dist-packages (from pyvirtualdisplay) (0.3)\n",
            "Requirement already satisfied: piglet in /usr/local/lib/python3.6/dist-packages (1.0.0)\n",
            "Requirement already satisfied: piglet-templates in /usr/local/lib/python3.6/dist-packages (from piglet) (1.0.0)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.6/dist-packages (from piglet-templates->piglet) (19.3.0)\n",
            "Requirement already satisfied: markupsafe in /usr/local/lib/python3.6/dist-packages (from piglet-templates->piglet) (1.1.1)\n",
            "Requirement already satisfied: Parsley in /usr/local/lib/python3.6/dist-packages (from piglet-templates->piglet) (1.3)\n",
            "Requirement already satisfied: astunparse in /usr/local/lib/python3.6/dist-packages (from piglet-templates->piglet) (1.6.3)\n",
            "Requirement already satisfied: six<2.0,>=1.6.1 in /usr/local/lib/python3.6/dist-packages (from astunparse->piglet-templates->piglet) (1.12.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.6/dist-packages (from astunparse->piglet-templates->piglet) (0.34.2)\n",
            "Requirement already satisfied: gym[atari] in /usr/local/lib/python3.6/dist-packages (0.17.2)\n",
            "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.6/dist-packages (from gym[atari]) (1.5.0)\n",
            "Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.6/dist-packages (from gym[atari]) (1.18.4)\n",
            "Requirement already satisfied: cloudpickle<1.4.0,>=1.2.0 in /usr/local/lib/python3.6/dist-packages (from gym[atari]) (1.3.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from gym[atari]) (1.4.1)\n",
            "Requirement already satisfied: atari-py~=0.2.0; extra == \"atari\" in /usr/local/lib/python3.6/dist-packages (from gym[atari]) (0.2.6)\n",
            "Requirement already satisfied: opencv-python; extra == \"atari\" in /usr/local/lib/python3.6/dist-packages (from gym[atari]) (4.1.2.30)\n",
            "Requirement already satisfied: Pillow; extra == \"atari\" in /usr/local/lib/python3.6/dist-packages (from gym[atari]) (7.0.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym[atari]) (0.16.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from atari-py~=0.2.0; extra == \"atari\"->gym[atari]) (1.12.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_blEEl6b_6OT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pyvirtualdisplay import Display\n",
        "display = Display(visible=0, size=(1400, 900))\n",
        "display.start()\n",
        "# create a virtual display to draw game images on. \n",
        "\n",
        "import os\n",
        "if type(os.environ.get(\"DISPLAY\")) is not str or len(os.environ.get(\"DISPLAY\"))==0:\n",
        "    !bash ../xvfb start\n",
        "    %env DISPLAY=:1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ne9FhBfJIxYG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import gym\n",
        "# gym initialization\n",
        "env = gym.make('Pong-v0')\n",
        "observation = env.reset()\n",
        "prev_input = None\n",
        "# Declaring the two actions that can happen in Pong for an agent, move up or move down\n",
        "# Decalring 0 means staying still. Note that this is pre-defined specific to package.\n",
        "UP_ACTION = 2\n",
        "DOWN_ACTION = 3\n",
        "# Hyperparameters. Gamma here allows you to measure the effect of future events\n",
        "gamma = 0.99\n",
        "# initialization of variables used in the main loop\n",
        "x_train, y_train, rewards = [],[],[]\n",
        "reward_sum = 0\n",
        "episode_nb = 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FgG0KTGdAL64",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Video recording code\n",
        "def show_video():\n",
        "  mp4list = glob.glob('recording/*.mp4')\n",
        "  if len(mp4list) > 0:\n",
        "    mp4 = mp4list[0]\n",
        "    video = io.open(mp4, 'r+b').read()\n",
        "    encoded = base64.b64encode(video)\n",
        "    ipythondisplay.display(HTML(data='''<video alt=\"test\" autoplay \n",
        "                loop controls style=\"height: 400px;\">\n",
        "                <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" />\n",
        "             </video>'''.format(encoded.decode('ascii'))))\n",
        "  else: \n",
        "    print(\"Could not find video\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cwxSWhLxIl43",
        "colab_type": "code",
        "outputId": "a39a5ebc-dbf5-4fd6-cbb3-7e40315482d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "source": [
        "#Letâ€™s take a look at the game in action.\n",
        "import matplotlib.pyplot as plt\n",
        "env = gym.make('Pong-v0') # environment info\n",
        "observation = env.reset()\n",
        "# The ball is released after 20 frames\n",
        "for i in range(24):\n",
        " \n",
        " if i > 22:\n",
        "  plt.imshow(observation)\n",
        "  plt.show()\n",
        "observation, _, _, _ = env.step(1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bzJTtasrJRlm",
        "colab_type": "code",
        "outputId": "2d5d073f-bfb0-4da3-cf0f-a663520736aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 268
        }
      },
      "source": [
        "def prepro(I):\n",
        "# Preprocess image\n",
        " I = I[35:195] # crop unesseserary parts of image\n",
        " I = I[::2,::2,0] # half pixels\n",
        " I[I == 144] = 0 # erase background (background type 1)\n",
        " I[I == 109] = 0 # erase background (background type 2)\n",
        " I[I != 0] = 1 # everything else (paddles, ball) just set to 1\n",
        " return I.astype(np.float).ravel()\n",
        "#Show preprocessed\n",
        "obs_preprocessed = prepro(observation).reshape(80,80)\n",
        "plt.imshow(obs_preprocessed, cmap='gray')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Su_zHWcEJbNh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def discount_rewards(r, gamma):\n",
        "#  calculate reward\n",
        "  r = np.array(r)\n",
        "  discounted_r = np.zeros_like(r)\n",
        "  running_add = 0\n",
        "\n",
        "  for t in reversed(range(0, r.size)):\n",
        "    if r[t] != 0: running_add = 0 # if the game ended (in Pong), reset \n",
        "    running_add = running_add * gamma + r[t] \n",
        "    discounted_r[t] = running_add\n",
        "  discounted_r -= np.mean(discounted_r) #normalizing the result\n",
        "  discounted_r /= np.std(discounted_r) #idem using standar deviation\n",
        "  return discounted_r"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8O8wdefXJsJ7",
        "colab_type": "code",
        "outputId": "8d37cddb-362c-4d9f-d861-e1fc79072103",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "# import necessary modules from keras\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Reshape\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import Flatten\n",
        "from keras.models import Sequential\n",
        "import keras\n",
        "from keras.models import InputLayer\n",
        "from keras.optimizers import Adam\n",
        "# Construct model\n",
        "model = Sequential()\n",
        "model.add(Dense(units=200,input_dim=80*80, activation='relu', kernel_initializer='glorot_uniform'))\n",
        "model.add(Dense(units=1, activation='sigmoid', kernel_initializer='RandomNormal'))\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "print(model.summary())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_1 (Dense)              (None, 200)               1280200   \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 201       \n",
            "=================================================================\n",
            "Total params: 1,280,401\n",
            "Trainable params: 1,280,401\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kuaGbI2IKDJF",
        "colab_type": "code",
        "outputId": "b342ce67-c0ec-4914-df65-eafbd34a1b27",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "history = []\n",
        "observation = env.reset()\n",
        "prev_input = None\n",
        "# main training loop\n",
        "while (True):\n",
        "  cur_input = prepro(observation)\n",
        "  x = cur_input - prev_input if prev_input is not None else np.zeros(80 * 80)\n",
        "  prev_input = cur_input\n",
        "  proba = model.predict(np.expand_dims(x, axis=1).T)\n",
        "  action = UP_ACTION if np.random.uniform() < proba else DOWN_ACTION\n",
        "  y = 1 if action == 2 else 0\n",
        "  x_train.append(x)\n",
        "  y_train.append(y)\n",
        "  observation, reward, done, info = env.step(action)\n",
        "  rewards.append(reward)\n",
        "  reward_sum += reward\n",
        "  if done:\n",
        "    history.append(reward_sum)\n",
        "    print('At the end of episode', episode_nb, 'the total reward was :', reward_sum)\n",
        "    if episode_nb>=3000 and reward_sum >=-12:\n",
        "      model.save(\"model.h5\")\n",
        "      break\n",
        "    else:\n",
        "    # increment episode number\n",
        "      episode_nb += 1\n",
        "      model.fit(x=np.vstack(x_train), y=np.vstack(y_train), verbose=1, sample_weight=discount_rewards(rewards, gamma))\n",
        "    # Reinitialization\n",
        "      x_train, y_train, rewards = [],[],[]\n",
        "      observation = env.reset()\n",
        "      reward_sum = 0\n",
        "      prev_input = None"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "2296/2296 [==============================] - 0s 113us/step - loss: 0.0027 - accuracy: 0.9909\n",
            "At the end of episode 1350 the total reward was : -21.0\n",
            "Epoch 1/1\n",
            "2399/2399 [==============================] - 0s 100us/step - loss: -8.2304e-04 - accuracy: 0.9879\n",
            "At the end of episode 1351 the total reward was : -20.0\n",
            "Epoch 1/1\n",
            "1964/1964 [==============================] - 0s 102us/step - loss: -0.0034 - accuracy: 0.9913\n",
            "At the end of episode 1352 the total reward was : -20.0\n",
            "Epoch 1/1\n",
            "2316/2316 [==============================] - 0s 105us/step - loss: 0.0124 - accuracy: 0.9892\n",
            "At the end of episode 1353 the total reward was : -21.0\n",
            "Epoch 1/1\n",
            "1900/1900 [==============================] - 0s 102us/step - loss: 0.0017 - accuracy: 0.9847\n",
            "At the end of episode 1354 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2183/2183 [==============================] - 0s 104us/step - loss: 0.0020 - accuracy: 0.9885\n",
            "At the end of episode 1355 the total reward was : -18.0\n",
            "Epoch 1/1\n",
            "2534/2534 [==============================] - 0s 102us/step - loss: -1.4827e-04 - accuracy: 0.9925\n",
            "At the end of episode 1356 the total reward was : -21.0\n",
            "Epoch 1/1\n",
            "1973/1973 [==============================] - 0s 103us/step - loss: -0.0061 - accuracy: 0.9797\n",
            "At the end of episode 1357 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "2579/2579 [==============================] - 0s 106us/step - loss: 0.0078 - accuracy: 0.9880\n",
            "At the end of episode 1358 the total reward was : -16.0\n",
            "Epoch 1/1\n",
            "2955/2955 [==============================] - 0s 109us/step - loss: -0.0057 - accuracy: 0.9902\n",
            "At the end of episode 1359 the total reward was : -20.0\n",
            "Epoch 1/1\n",
            "1942/1942 [==============================] - 0s 105us/step - loss: -0.0038 - accuracy: 0.9882\n",
            "At the end of episode 1360 the total reward was : -15.0\n",
            "Epoch 1/1\n",
            "2772/2772 [==============================] - 0s 107us/step - loss: 0.0061 - accuracy: 0.9877\n",
            "At the end of episode 1361 the total reward was : -21.0\n",
            "Epoch 1/1\n",
            "1271/1271 [==============================] - 0s 103us/step - loss: -0.0047 - accuracy: 0.9866\n",
            "At the end of episode 1362 the total reward was : -20.0\n",
            "Epoch 1/1\n",
            "1704/1704 [==============================] - 0s 105us/step - loss: 6.3792e-04 - accuracy: 0.9877\n",
            "At the end of episode 1363 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "1998/1998 [==============================] - 0s 102us/step - loss: -2.9900e-04 - accuracy: 0.9890\n",
            "At the end of episode 1364 the total reward was : -18.0\n",
            "Epoch 1/1\n",
            "2125/2125 [==============================] - 0s 108us/step - loss: -0.0095 - accuracy: 0.9849\n",
            "At the end of episode 1365 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "1839/1839 [==============================] - 0s 102us/step - loss: -0.0024 - accuracy: 0.9810\n",
            "At the end of episode 1366 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2013/2013 [==============================] - 0s 101us/step - loss: -0.0052 - accuracy: 0.9886\n",
            "At the end of episode 1367 the total reward was : -20.0\n",
            "Epoch 1/1\n",
            "1964/1964 [==============================] - 0s 105us/step - loss: -0.0158 - accuracy: 0.9801\n",
            "At the end of episode 1368 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2271/2271 [==============================] - 0s 107us/step - loss: -0.0019 - accuracy: 0.9859\n",
            "At the end of episode 1369 the total reward was : -15.0\n",
            "Epoch 1/1\n",
            "2743/2743 [==============================] - 0s 109us/step - loss: -0.0013 - accuracy: 0.9887\n",
            "At the end of episode 1370 the total reward was : -15.0\n",
            "Epoch 1/1\n",
            "2520/2520 [==============================] - 0s 108us/step - loss: -0.0085 - accuracy: 0.9873\n",
            "At the end of episode 1371 the total reward was : -16.0\n",
            "Epoch 1/1\n",
            "2685/2685 [==============================] - 0s 104us/step - loss: -0.0046 - accuracy: 0.9862\n",
            "At the end of episode 1372 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2004/2004 [==============================] - 0s 105us/step - loss: 0.0026 - accuracy: 0.9895\n",
            "At the end of episode 1373 the total reward was : -20.0\n",
            "Epoch 1/1\n",
            "1985/1985 [==============================] - 0s 107us/step - loss: 0.0013 - accuracy: 0.9899\n",
            "At the end of episode 1374 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "1902/1902 [==============================] - 0s 101us/step - loss: -0.0011 - accuracy: 0.9879\n",
            "At the end of episode 1375 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2406/2406 [==============================] - 0s 105us/step - loss: -5.7076e-04 - accuracy: 0.9884\n",
            "At the end of episode 1376 the total reward was : -18.0\n",
            "Epoch 1/1\n",
            "2448/2448 [==============================] - 0s 108us/step - loss: -0.0022 - accuracy: 0.9894\n",
            "At the end of episode 1377 the total reward was : -20.0\n",
            "Epoch 1/1\n",
            "2272/2272 [==============================] - 0s 102us/step - loss: -0.0064 - accuracy: 0.9908\n",
            "At the end of episode 1378 the total reward was : -18.0\n",
            "Epoch 1/1\n",
            "2770/2770 [==============================] - 0s 102us/step - loss: -0.0061 - accuracy: 0.9801\n",
            "At the end of episode 1379 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "2557/2557 [==============================] - 0s 106us/step - loss: -0.0042 - accuracy: 0.9836\n",
            "At the end of episode 1380 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "2414/2414 [==============================] - 0s 106us/step - loss: -0.0077 - accuracy: 0.9805\n",
            "At the end of episode 1381 the total reward was : -18.0\n",
            "Epoch 1/1\n",
            "2963/2963 [==============================] - 0s 109us/step - loss: 0.0065 - accuracy: 0.9858\n",
            "At the end of episode 1382 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2592/2592 [==============================] - 0s 112us/step - loss: 0.0022 - accuracy: 0.9838\n",
            "At the end of episode 1383 the total reward was : -18.0\n",
            "Epoch 1/1\n",
            "2850/2850 [==============================] - 0s 103us/step - loss: -0.0013 - accuracy: 0.9888\n",
            "At the end of episode 1384 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2327/2327 [==============================] - 0s 100us/step - loss: -0.0052 - accuracy: 0.9897\n",
            "At the end of episode 1385 the total reward was : -14.0\n",
            "Epoch 1/1\n",
            "3224/3224 [==============================] - 0s 108us/step - loss: -0.0060 - accuracy: 0.9860\n",
            "At the end of episode 1386 the total reward was : -21.0\n",
            "Epoch 1/1\n",
            "1749/1749 [==============================] - 0s 101us/step - loss: -0.0033 - accuracy: 0.9874\n",
            "At the end of episode 1387 the total reward was : -21.0\n",
            "Epoch 1/1\n",
            "2329/2329 [==============================] - 0s 110us/step - loss: 8.2421e-04 - accuracy: 0.9888\n",
            "At the end of episode 1388 the total reward was : -21.0\n",
            "Epoch 1/1\n",
            "1989/1989 [==============================] - 0s 107us/step - loss: -0.0045 - accuracy: 0.9889\n",
            "At the end of episode 1389 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "3064/3064 [==============================] - 0s 103us/step - loss: 0.0060 - accuracy: 0.9905\n",
            "At the end of episode 1390 the total reward was : -20.0\n",
            "Epoch 1/1\n",
            "2286/2286 [==============================] - 0s 107us/step - loss: -0.0029 - accuracy: 0.9856\n",
            "At the end of episode 1391 the total reward was : -21.0\n",
            "Epoch 1/1\n",
            "2060/2060 [==============================] - 0s 113us/step - loss: -0.0026 - accuracy: 0.9835\n",
            "At the end of episode 1392 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "2936/2936 [==============================] - 0s 106us/step - loss: -0.0060 - accuracy: 0.9837\n",
            "At the end of episode 1393 the total reward was : -14.0\n",
            "Epoch 1/1\n",
            "2970/2970 [==============================] - 0s 112us/step - loss: -0.0029 - accuracy: 0.9852\n",
            "At the end of episode 1394 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "2521/2521 [==============================] - 0s 101us/step - loss: 0.0020 - accuracy: 0.9845\n",
            "At the end of episode 1395 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2655/2655 [==============================] - 0s 101us/step - loss: -0.0068 - accuracy: 0.9857\n",
            "At the end of episode 1396 the total reward was : -21.0\n",
            "Epoch 1/1\n",
            "1825/1825 [==============================] - 0s 103us/step - loss: -0.0111 - accuracy: 0.9781\n",
            "At the end of episode 1397 the total reward was : -18.0\n",
            "Epoch 1/1\n",
            "2855/2855 [==============================] - 0s 101us/step - loss: 0.0010 - accuracy: 0.9842\n",
            "At the end of episode 1398 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2319/2319 [==============================] - 0s 103us/step - loss: 0.0053 - accuracy: 0.9875\n",
            "At the end of episode 1399 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2106/2106 [==============================] - 0s 105us/step - loss: -0.0054 - accuracy: 0.9896\n",
            "At the end of episode 1400 the total reward was : -21.0\n",
            "Epoch 1/1\n",
            "2462/2462 [==============================] - 0s 106us/step - loss: 0.0061 - accuracy: 0.9874\n",
            "At the end of episode 1401 the total reward was : -18.0\n",
            "Epoch 1/1\n",
            "2784/2784 [==============================] - 0s 107us/step - loss: 0.0117 - accuracy: 0.9824\n",
            "At the end of episode 1402 the total reward was : -18.0\n",
            "Epoch 1/1\n",
            "2555/2555 [==============================] - 0s 104us/step - loss: 0.0013 - accuracy: 0.9879\n",
            "At the end of episode 1403 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "3461/3461 [==============================] - 0s 103us/step - loss: 5.5283e-04 - accuracy: 0.9893\n",
            "At the end of episode 1404 the total reward was : -21.0\n",
            "Epoch 1/1\n",
            "2385/2385 [==============================] - 0s 104us/step - loss: 0.0077 - accuracy: 0.9874\n",
            "At the end of episode 1405 the total reward was : -14.0\n",
            "Epoch 1/1\n",
            "3527/3527 [==============================] - 0s 105us/step - loss: 0.0105 - accuracy: 0.9819\n",
            "At the end of episode 1406 the total reward was : -20.0\n",
            "Epoch 1/1\n",
            "2201/2201 [==============================] - 0s 102us/step - loss: 0.0024 - accuracy: 0.9891\n",
            "At the end of episode 1407 the total reward was : -21.0\n",
            "Epoch 1/1\n",
            "2718/2718 [==============================] - 0s 120us/step - loss: 8.3232e-04 - accuracy: 0.9838\n",
            "At the end of episode 1408 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "3014/3014 [==============================] - 0s 108us/step - loss: -0.0032 - accuracy: 0.9894\n",
            "At the end of episode 1409 the total reward was : -14.0\n",
            "Epoch 1/1\n",
            "2897/2897 [==============================] - 0s 106us/step - loss: -0.0040 - accuracy: 0.9879\n",
            "At the end of episode 1410 the total reward was : -21.0\n",
            "Epoch 1/1\n",
            "2070/2070 [==============================] - 0s 114us/step - loss: 8.7474e-04 - accuracy: 0.9889\n",
            "At the end of episode 1411 the total reward was : -21.0\n",
            "Epoch 1/1\n",
            "2720/2720 [==============================] - 0s 110us/step - loss: -0.0081 - accuracy: 0.9879\n",
            "At the end of episode 1412 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2340/2340 [==============================] - 0s 104us/step - loss: 0.0031 - accuracy: 0.9893\n",
            "At the end of episode 1413 the total reward was : -21.0\n",
            "Epoch 1/1\n",
            "2397/2397 [==============================] - 0s 105us/step - loss: -0.0013 - accuracy: 0.9917\n",
            "At the end of episode 1414 the total reward was : -21.0\n",
            "Epoch 1/1\n",
            "2418/2418 [==============================] - 0s 101us/step - loss: -0.0119 - accuracy: 0.9843\n",
            "At the end of episode 1415 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2905/2905 [==============================] - 0s 107us/step - loss: -0.0055 - accuracy: 0.9859\n",
            "At the end of episode 1416 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "2761/2761 [==============================] - 0s 108us/step - loss: 0.0022 - accuracy: 0.9870\n",
            "At the end of episode 1417 the total reward was : -18.0\n",
            "Epoch 1/1\n",
            "2568/2568 [==============================] - 0s 107us/step - loss: -0.0117 - accuracy: 0.9848\n",
            "At the end of episode 1418 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2754/2754 [==============================] - 0s 109us/step - loss: -0.0057 - accuracy: 0.9855\n",
            "At the end of episode 1419 the total reward was : -21.0\n",
            "Epoch 1/1\n",
            "2718/2718 [==============================] - 0s 107us/step - loss: 0.0035 - accuracy: 0.9857\n",
            "At the end of episode 1420 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2565/2565 [==============================] - 0s 109us/step - loss: -0.0164 - accuracy: 0.9797\n",
            "At the end of episode 1421 the total reward was : -20.0\n",
            "Epoch 1/1\n",
            "3091/3091 [==============================] - 0s 108us/step - loss: 0.0053 - accuracy: 0.9812\n",
            "At the end of episode 1422 the total reward was : -21.0\n",
            "Epoch 1/1\n",
            "2819/2819 [==============================] - 0s 103us/step - loss: -0.0063 - accuracy: 0.9855\n",
            "At the end of episode 1423 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "2674/2674 [==============================] - 0s 103us/step - loss: -0.0042 - accuracy: 0.9847\n",
            "At the end of episode 1424 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "3114/3114 [==============================] - 0s 108us/step - loss: -0.0015 - accuracy: 0.9798\n",
            "At the end of episode 1425 the total reward was : -16.0\n",
            "Epoch 1/1\n",
            "3051/3051 [==============================] - 0s 103us/step - loss: -0.0203 - accuracy: 0.9767\n",
            "At the end of episode 1426 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2574/2574 [==============================] - 0s 104us/step - loss: -3.2589e-05 - accuracy: 0.9876\n",
            "At the end of episode 1427 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "2739/2739 [==============================] - 0s 105us/step - loss: 0.0037 - accuracy: 0.9861\n",
            "At the end of episode 1428 the total reward was : -21.0\n",
            "Epoch 1/1\n",
            "2013/2013 [==============================] - 0s 109us/step - loss: 0.0096 - accuracy: 0.9856\n",
            "At the end of episode 1429 the total reward was : -18.0\n",
            "Epoch 1/1\n",
            "2375/2375 [==============================] - 0s 109us/step - loss: 0.0026 - accuracy: 0.9722\n",
            "At the end of episode 1430 the total reward was : -20.0\n",
            "Epoch 1/1\n",
            "2206/2206 [==============================] - 0s 110us/step - loss: -0.0108 - accuracy: 0.9805\n",
            "At the end of episode 1431 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2913/2913 [==============================] - 0s 103us/step - loss: -0.0081 - accuracy: 0.9849\n",
            "At the end of episode 1432 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2181/2181 [==============================] - 0s 108us/step - loss: -0.0067 - accuracy: 0.9862\n",
            "At the end of episode 1433 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "3329/3329 [==============================] - 0s 110us/step - loss: -7.8636e-04 - accuracy: 0.9838\n",
            "At the end of episode 1434 the total reward was : -20.0\n",
            "Epoch 1/1\n",
            "2137/2137 [==============================] - 0s 111us/step - loss: -6.9091e-05 - accuracy: 0.9836\n",
            "At the end of episode 1435 the total reward was : -21.0\n",
            "Epoch 1/1\n",
            "3059/3059 [==============================] - 0s 100us/step - loss: 0.0037 - accuracy: 0.9895\n",
            "At the end of episode 1436 the total reward was : -20.0\n",
            "Epoch 1/1\n",
            "2852/2852 [==============================] - 0s 101us/step - loss: 0.0095 - accuracy: 0.9835\n",
            "At the end of episode 1437 the total reward was : -20.0\n",
            "Epoch 1/1\n",
            "2772/2772 [==============================] - 0s 107us/step - loss: -8.3885e-04 - accuracy: 0.9845\n",
            "At the end of episode 1438 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2919/2919 [==============================] - 0s 101us/step - loss: -0.0102 - accuracy: 0.9798\n",
            "At the end of episode 1439 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "3104/3104 [==============================] - 0s 108us/step - loss: 0.0073 - accuracy: 0.9820\n",
            "At the end of episode 1440 the total reward was : -15.0\n",
            "Epoch 1/1\n",
            "2914/2914 [==============================] - 0s 109us/step - loss: -0.0048 - accuracy: 0.9911\n",
            "At the end of episode 1441 the total reward was : -16.0\n",
            "Epoch 1/1\n",
            "2874/2874 [==============================] - 0s 102us/step - loss: -0.0070 - accuracy: 0.9809\n",
            "At the end of episode 1442 the total reward was : -21.0\n",
            "Epoch 1/1\n",
            "2231/2231 [==============================] - 0s 102us/step - loss: -0.0024 - accuracy: 0.9874\n",
            "At the end of episode 1443 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2171/2171 [==============================] - 0s 104us/step - loss: -0.0090 - accuracy: 0.9802\n",
            "At the end of episode 1444 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2487/2487 [==============================] - 0s 100us/step - loss: 0.0028 - accuracy: 0.9835\n",
            "At the end of episode 1445 the total reward was : -21.0\n",
            "Epoch 1/1\n",
            "2769/2769 [==============================] - 0s 105us/step - loss: 0.0020 - accuracy: 0.9866\n",
            "At the end of episode 1446 the total reward was : -15.0\n",
            "Epoch 1/1\n",
            "2673/2673 [==============================] - 0s 106us/step - loss: -3.6749e-04 - accuracy: 0.9850\n",
            "At the end of episode 1447 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2504/2504 [==============================] - 0s 102us/step - loss: 0.0047 - accuracy: 0.9892\n",
            "At the end of episode 1448 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "2680/2680 [==============================] - 0s 103us/step - loss: 0.0017 - accuracy: 0.9843\n",
            "At the end of episode 1449 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "2329/2329 [==============================] - 0s 101us/step - loss: 0.0017 - accuracy: 0.9863\n",
            "At the end of episode 1450 the total reward was : -18.0\n",
            "Epoch 1/1\n",
            "2945/2945 [==============================] - 0s 109us/step - loss: 0.0036 - accuracy: 0.9874\n",
            "At the end of episode 1451 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "2442/2442 [==============================] - 0s 101us/step - loss: -0.0074 - accuracy: 0.9889\n",
            "At the end of episode 1452 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "2702/2702 [==============================] - 0s 102us/step - loss: -0.0029 - accuracy: 0.9867\n",
            "At the end of episode 1453 the total reward was : -21.0\n",
            "Epoch 1/1\n",
            "2741/2741 [==============================] - 0s 102us/step - loss: 0.0029 - accuracy: 0.9861\n",
            "At the end of episode 1454 the total reward was : -15.0\n",
            "Epoch 1/1\n",
            "2435/2435 [==============================] - 0s 108us/step - loss: 0.0116 - accuracy: 0.9856\n",
            "At the end of episode 1455 the total reward was : -15.0\n",
            "Epoch 1/1\n",
            "3573/3573 [==============================] - 0s 103us/step - loss: -0.0028 - accuracy: 0.9815\n",
            "At the end of episode 1456 the total reward was : -18.0\n",
            "Epoch 1/1\n",
            "2877/2877 [==============================] - 0s 102us/step - loss: 0.0016 - accuracy: 0.9844\n",
            "At the end of episode 1457 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2653/2653 [==============================] - 0s 102us/step - loss: -0.0020 - accuracy: 0.9849\n",
            "At the end of episode 1458 the total reward was : -13.0\n",
            "Epoch 1/1\n",
            "3513/3513 [==============================] - 0s 116us/step - loss: -0.0014 - accuracy: 0.9843\n",
            "At the end of episode 1459 the total reward was : -20.0\n",
            "Epoch 1/1\n",
            "2439/2439 [==============================] - 0s 112us/step - loss: -0.0074 - accuracy: 0.9869\n",
            "At the end of episode 1460 the total reward was : -20.0\n",
            "Epoch 1/1\n",
            "2765/2765 [==============================] - 0s 105us/step - loss: -0.0015 - accuracy: 0.9902\n",
            "At the end of episode 1461 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "2906/2906 [==============================] - 0s 101us/step - loss: -0.0041 - accuracy: 0.9900\n",
            "At the end of episode 1462 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2340/2340 [==============================] - 0s 105us/step - loss: 0.0042 - accuracy: 0.9868\n",
            "At the end of episode 1463 the total reward was : -18.0\n",
            "Epoch 1/1\n",
            "2450/2450 [==============================] - 0s 100us/step - loss: 0.0094 - accuracy: 0.9898\n",
            "At the end of episode 1464 the total reward was : -20.0\n",
            "Epoch 1/1\n",
            "2517/2517 [==============================] - 0s 101us/step - loss: -0.0056 - accuracy: 0.9873\n",
            "At the end of episode 1465 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "2590/2590 [==============================] - 0s 107us/step - loss: -0.0046 - accuracy: 0.9849\n",
            "At the end of episode 1466 the total reward was : -18.0\n",
            "Epoch 1/1\n",
            "2449/2449 [==============================] - 0s 105us/step - loss: -0.0057 - accuracy: 0.9861\n",
            "At the end of episode 1467 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "1998/1998 [==============================] - 0s 104us/step - loss: -0.0060 - accuracy: 0.9875\n",
            "At the end of episode 1468 the total reward was : -21.0\n",
            "Epoch 1/1\n",
            "2133/2133 [==============================] - 0s 101us/step - loss: -0.0017 - accuracy: 0.9869\n",
            "At the end of episode 1469 the total reward was : -21.0\n",
            "Epoch 1/1\n",
            "2712/2712 [==============================] - 0s 105us/step - loss: -5.0444e-04 - accuracy: 0.9845\n",
            "At the end of episode 1470 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "2808/2808 [==============================] - 0s 103us/step - loss: 0.0046 - accuracy: 0.9868\n",
            "At the end of episode 1471 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "2744/2744 [==============================] - 0s 106us/step - loss: -0.0016 - accuracy: 0.9851\n",
            "At the end of episode 1472 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2580/2580 [==============================] - 0s 101us/step - loss: -0.0074 - accuracy: 0.9833\n",
            "At the end of episode 1473 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "2347/2347 [==============================] - 0s 106us/step - loss: 0.0060 - accuracy: 0.9851\n",
            "At the end of episode 1474 the total reward was : -20.0\n",
            "Epoch 1/1\n",
            "2443/2443 [==============================] - 0s 105us/step - loss: 0.0067 - accuracy: 0.9828\n",
            "At the end of episode 1475 the total reward was : -21.0\n",
            "Epoch 1/1\n",
            "2159/2159 [==============================] - 0s 105us/step - loss: -7.8889e-04 - accuracy: 0.9926\n",
            "At the end of episode 1476 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "2505/2505 [==============================] - 0s 112us/step - loss: -0.0044 - accuracy: 0.9892\n",
            "At the end of episode 1477 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2310/2310 [==============================] - 0s 102us/step - loss: -0.0024 - accuracy: 0.9848\n",
            "At the end of episode 1478 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "2407/2407 [==============================] - 0s 107us/step - loss: 0.0053 - accuracy: 0.9846\n",
            "At the end of episode 1479 the total reward was : -20.0\n",
            "Epoch 1/1\n",
            "2221/2221 [==============================] - 0s 103us/step - loss: 0.0013 - accuracy: 0.9887\n",
            "At the end of episode 1480 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "2752/2752 [==============================] - 0s 101us/step - loss: -0.0032 - accuracy: 0.9840\n",
            "At the end of episode 1481 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "2996/2996 [==============================] - 0s 110us/step - loss: -9.4573e-05 - accuracy: 0.9850\n",
            "At the end of episode 1482 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2104/2104 [==============================] - 0s 116us/step - loss: 0.0021 - accuracy: 0.9838\n",
            "At the end of episode 1483 the total reward was : -16.0\n",
            "Epoch 1/1\n",
            "2801/2801 [==============================] - 0s 107us/step - loss: 3.9433e-04 - accuracy: 0.9907\n",
            "At the end of episode 1484 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2334/2334 [==============================] - 0s 103us/step - loss: 0.0033 - accuracy: 0.9841\n",
            "At the end of episode 1485 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "2425/2425 [==============================] - 0s 105us/step - loss: -0.0013 - accuracy: 0.9905\n",
            "At the end of episode 1486 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "2828/2828 [==============================] - 0s 114us/step - loss: -0.0072 - accuracy: 0.9894\n",
            "At the end of episode 1487 the total reward was : -16.0\n",
            "Epoch 1/1\n",
            "2615/2615 [==============================] - 0s 106us/step - loss: -0.0057 - accuracy: 0.9851\n",
            "At the end of episode 1488 the total reward was : -20.0\n",
            "Epoch 1/1\n",
            "2053/2053 [==============================] - 0s 102us/step - loss: -0.0082 - accuracy: 0.9883\n",
            "At the end of episode 1489 the total reward was : -13.0\n",
            "Epoch 1/1\n",
            "2684/2684 [==============================] - 0s 109us/step - loss: -0.0269 - accuracy: 0.9817\n",
            "At the end of episode 1490 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2166/2166 [==============================] - 0s 102us/step - loss: -0.0044 - accuracy: 0.9861\n",
            "At the end of episode 1491 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "3139/3139 [==============================] - 0s 112us/step - loss: -5.6757e-05 - accuracy: 0.9888\n",
            "At the end of episode 1492 the total reward was : -21.0\n",
            "Epoch 1/1\n",
            "2965/2965 [==============================] - 0s 109us/step - loss: -0.0036 - accuracy: 0.9848\n",
            "At the end of episode 1493 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2428/2428 [==============================] - 0s 101us/step - loss: 6.6546e-04 - accuracy: 0.9872\n",
            "At the end of episode 1494 the total reward was : -21.0\n",
            "Epoch 1/1\n",
            "2814/2814 [==============================] - 0s 102us/step - loss: -0.0049 - accuracy: 0.9886\n",
            "At the end of episode 1495 the total reward was : -16.0\n",
            "Epoch 1/1\n",
            "2955/2955 [==============================] - 0s 115us/step - loss: -0.0033 - accuracy: 0.9882\n",
            "At the end of episode 1496 the total reward was : -20.0\n",
            "Epoch 1/1\n",
            "2452/2452 [==============================] - 0s 105us/step - loss: 0.0134 - accuracy: 0.9821\n",
            "At the end of episode 1497 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "2829/2829 [==============================] - 0s 103us/step - loss: -0.0040 - accuracy: 0.9933\n",
            "At the end of episode 1498 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "3081/3081 [==============================] - 0s 112us/step - loss: -0.0046 - accuracy: 0.9860\n",
            "At the end of episode 1499 the total reward was : -15.0\n",
            "Epoch 1/1\n",
            "2820/2820 [==============================] - 0s 111us/step - loss: -9.5956e-04 - accuracy: 0.9894\n",
            "At the end of episode 1500 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "3047/3047 [==============================] - 0s 107us/step - loss: -0.0041 - accuracy: 0.9859\n",
            "At the end of episode 1501 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "2253/2253 [==============================] - 0s 105us/step - loss: -0.0050 - accuracy: 0.9827\n",
            "At the end of episode 1502 the total reward was : -15.0\n",
            "Epoch 1/1\n",
            "3221/3221 [==============================] - 0s 109us/step - loss: -1.6111e-04 - accuracy: 0.9792\n",
            "At the end of episode 1503 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "2672/2672 [==============================] - 0s 107us/step - loss: -0.0041 - accuracy: 0.9880\n",
            "At the end of episode 1504 the total reward was : -18.0\n",
            "Epoch 1/1\n",
            "3013/3013 [==============================] - 0s 102us/step - loss: -0.0062 - accuracy: 0.9864\n",
            "At the end of episode 1505 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2505/2505 [==============================] - 0s 108us/step - loss: -0.0037 - accuracy: 0.9860\n",
            "At the end of episode 1506 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "3152/3152 [==============================] - 0s 104us/step - loss: -0.0026 - accuracy: 0.9838\n",
            "At the end of episode 1507 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2415/2415 [==============================] - 0s 103us/step - loss: -4.9434e-04 - accuracy: 0.9805\n",
            "At the end of episode 1508 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2670/2670 [==============================] - 0s 104us/step - loss: 0.0015 - accuracy: 0.9888\n",
            "At the end of episode 1509 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2830/2830 [==============================] - 0s 102us/step - loss: 7.6447e-04 - accuracy: 0.9876\n",
            "At the end of episode 1510 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2497/2497 [==============================] - 0s 106us/step - loss: -0.0243 - accuracy: 0.9760\n",
            "At the end of episode 1511 the total reward was : -21.0\n",
            "Epoch 1/1\n",
            "2473/2473 [==============================] - 0s 108us/step - loss: -0.0040 - accuracy: 0.9899\n",
            "At the end of episode 1512 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "2640/2640 [==============================] - 0s 102us/step - loss: 0.0060 - accuracy: 0.9886\n",
            "At the end of episode 1513 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2661/2661 [==============================] - 0s 101us/step - loss: -0.0056 - accuracy: 0.9835\n",
            "At the end of episode 1514 the total reward was : -21.0\n",
            "Epoch 1/1\n",
            "2696/2696 [==============================] - 0s 103us/step - loss: -0.0031 - accuracy: 0.9881\n",
            "At the end of episode 1515 the total reward was : -20.0\n",
            "Epoch 1/1\n",
            "2296/2296 [==============================] - 0s 101us/step - loss: -6.5327e-04 - accuracy: 0.9874\n",
            "At the end of episode 1516 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2657/2657 [==============================] - 0s 106us/step - loss: -0.0069 - accuracy: 0.9883\n",
            "At the end of episode 1517 the total reward was : -20.0\n",
            "Epoch 1/1\n",
            "2608/2608 [==============================] - 0s 104us/step - loss: 0.0174 - accuracy: 0.9827\n",
            "At the end of episode 1518 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "3027/3027 [==============================] - 0s 110us/step - loss: 0.0027 - accuracy: 0.9841\n",
            "At the end of episode 1519 the total reward was : -15.0\n",
            "Epoch 1/1\n",
            "2774/2774 [==============================] - 0s 102us/step - loss: -0.0089 - accuracy: 0.9813\n",
            "At the end of episode 1520 the total reward was : -15.0\n",
            "Epoch 1/1\n",
            "3002/3002 [==============================] - 0s 108us/step - loss: -0.0054 - accuracy: 0.9883\n",
            "At the end of episode 1521 the total reward was : -15.0\n",
            "Epoch 1/1\n",
            "3331/3331 [==============================] - 0s 110us/step - loss: 0.0040 - accuracy: 0.9841\n",
            "At the end of episode 1522 the total reward was : -21.0\n",
            "Epoch 1/1\n",
            "2724/2724 [==============================] - 0s 105us/step - loss: 0.0099 - accuracy: 0.9820\n",
            "At the end of episode 1523 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "3367/3367 [==============================] - 0s 110us/step - loss: -0.0019 - accuracy: 0.9860\n",
            "At the end of episode 1524 the total reward was : -21.0\n",
            "Epoch 1/1\n",
            "2370/2370 [==============================] - 0s 101us/step - loss: -0.0011 - accuracy: 0.9844\n",
            "At the end of episode 1525 the total reward was : -21.0\n",
            "Epoch 1/1\n",
            "2414/2414 [==============================] - 0s 108us/step - loss: 0.0063 - accuracy: 0.9872\n",
            "At the end of episode 1526 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2575/2575 [==============================] - 0s 100us/step - loss: -0.0051 - accuracy: 0.9837\n",
            "At the end of episode 1527 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2736/2736 [==============================] - 0s 104us/step - loss: 0.0021 - accuracy: 0.9854\n",
            "At the end of episode 1528 the total reward was : -11.0\n",
            "Epoch 1/1\n",
            "3509/3509 [==============================] - 0s 108us/step - loss: -0.0025 - accuracy: 0.9846\n",
            "At the end of episode 1529 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2498/2498 [==============================] - 0s 104us/step - loss: 5.9700e-05 - accuracy: 0.9860\n",
            "At the end of episode 1530 the total reward was : -16.0\n",
            "Epoch 1/1\n",
            "3382/3382 [==============================] - 0s 106us/step - loss: -0.0039 - accuracy: 0.9879\n",
            "At the end of episode 1531 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "2924/2924 [==============================] - 0s 108us/step - loss: 0.0057 - accuracy: 0.9870\n",
            "At the end of episode 1532 the total reward was : -20.0\n",
            "Epoch 1/1\n",
            "2586/2586 [==============================] - 0s 104us/step - loss: 0.0068 - accuracy: 0.9915\n",
            "At the end of episode 1533 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "2765/2765 [==============================] - 0s 107us/step - loss: -0.0062 - accuracy: 0.9830\n",
            "At the end of episode 1534 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2754/2754 [==============================] - 0s 113us/step - loss: 0.0037 - accuracy: 0.9855\n",
            "At the end of episode 1535 the total reward was : -16.0\n",
            "Epoch 1/1\n",
            "3016/3016 [==============================] - 0s 113us/step - loss: -0.0019 - accuracy: 0.9818\n",
            "At the end of episode 1536 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2601/2601 [==============================] - 0s 106us/step - loss: -0.0014 - accuracy: 0.9892\n",
            "At the end of episode 1537 the total reward was : -13.0\n",
            "Epoch 1/1\n",
            "3264/3264 [==============================] - 0s 104us/step - loss: -0.0018 - accuracy: 0.9819\n",
            "At the end of episode 1538 the total reward was : -20.0\n",
            "Epoch 1/1\n",
            "2382/2382 [==============================] - 0s 100us/step - loss: 0.0012 - accuracy: 0.9845\n",
            "At the end of episode 1539 the total reward was : -16.0\n",
            "Epoch 1/1\n",
            "3024/3024 [==============================] - 0s 102us/step - loss: -0.0018 - accuracy: 0.9851\n",
            "At the end of episode 1540 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2743/2743 [==============================] - 0s 100us/step - loss: 0.0080 - accuracy: 0.9858\n",
            "At the end of episode 1541 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2780/2780 [==============================] - 0s 101us/step - loss: 0.0056 - accuracy: 0.9874\n",
            "At the end of episode 1542 the total reward was : -16.0\n",
            "Epoch 1/1\n",
            "3275/3275 [==============================] - 0s 105us/step - loss: -3.0572e-04 - accuracy: 0.9860\n",
            "At the end of episode 1543 the total reward was : -21.0\n",
            "Epoch 1/1\n",
            "3045/3045 [==============================] - 0s 108us/step - loss: 0.0020 - accuracy: 0.9918\n",
            "At the end of episode 1544 the total reward was : -13.0\n",
            "Epoch 1/1\n",
            "3413/3413 [==============================] - 0s 108us/step - loss: -0.0077 - accuracy: 0.9856\n",
            "At the end of episode 1545 the total reward was : -18.0\n",
            "Epoch 1/1\n",
            "2705/2705 [==============================] - 0s 103us/step - loss: -8.9046e-04 - accuracy: 0.9878\n",
            "At the end of episode 1546 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "3238/3238 [==============================] - 0s 110us/step - loss: -0.0137 - accuracy: 0.9846\n",
            "At the end of episode 1547 the total reward was : -18.0\n",
            "Epoch 1/1\n",
            "2212/2212 [==============================] - 0s 102us/step - loss: 0.0052 - accuracy: 0.9837\n",
            "At the end of episode 1548 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2567/2567 [==============================] - 0s 104us/step - loss: -0.0082 - accuracy: 0.9852\n",
            "At the end of episode 1549 the total reward was : -16.0\n",
            "Epoch 1/1\n",
            "3358/3358 [==============================] - 0s 106us/step - loss: 0.0092 - accuracy: 0.9827\n",
            "At the end of episode 1550 the total reward was : -14.0\n",
            "Epoch 1/1\n",
            "2819/2819 [==============================] - 0s 113us/step - loss: 0.0078 - accuracy: 0.9862\n",
            "At the end of episode 1551 the total reward was : -21.0\n",
            "Epoch 1/1\n",
            "2253/2253 [==============================] - 0s 104us/step - loss: 9.7371e-04 - accuracy: 0.9836\n",
            "At the end of episode 1552 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2481/2481 [==============================] - 0s 101us/step - loss: 0.0065 - accuracy: 0.9855\n",
            "At the end of episode 1553 the total reward was : -14.0\n",
            "Epoch 1/1\n",
            "2313/2313 [==============================] - 0s 106us/step - loss: 0.0049 - accuracy: 0.9870\n",
            "At the end of episode 1554 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "2567/2567 [==============================] - 0s 106us/step - loss: 0.0040 - accuracy: 0.9887\n",
            "At the end of episode 1555 the total reward was : -18.0\n",
            "Epoch 1/1\n",
            "2629/2629 [==============================] - 0s 106us/step - loss: 0.0026 - accuracy: 0.9855\n",
            "At the end of episode 1556 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2554/2554 [==============================] - 0s 102us/step - loss: 0.0025 - accuracy: 0.9879\n",
            "At the end of episode 1557 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2327/2327 [==============================] - 0s 101us/step - loss: -8.1614e-04 - accuracy: 0.9858\n",
            "At the end of episode 1558 the total reward was : -16.0\n",
            "Epoch 1/1\n",
            "2911/2911 [==============================] - 0s 106us/step - loss: -0.0082 - accuracy: 0.9821\n",
            "At the end of episode 1559 the total reward was : -18.0\n",
            "Epoch 1/1\n",
            "2533/2533 [==============================] - 0s 101us/step - loss: -0.0013 - accuracy: 0.9893\n",
            "At the end of episode 1560 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "2665/2665 [==============================] - 0s 101us/step - loss: 0.0035 - accuracy: 0.9872\n",
            "At the end of episode 1561 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "2679/2679 [==============================] - 0s 103us/step - loss: 0.0041 - accuracy: 0.9866\n",
            "At the end of episode 1562 the total reward was : -21.0\n",
            "Epoch 1/1\n",
            "2981/2981 [==============================] - 0s 114us/step - loss: -0.0131 - accuracy: 0.9772\n",
            "At the end of episode 1563 the total reward was : -21.0\n",
            "Epoch 1/1\n",
            "3364/3364 [==============================] - 0s 113us/step - loss: -0.0015 - accuracy: 0.9869\n",
            "At the end of episode 1564 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2813/2813 [==============================] - 0s 102us/step - loss: 0.0041 - accuracy: 0.9915\n",
            "At the end of episode 1565 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "3039/3039 [==============================] - 0s 103us/step - loss: -6.4401e-04 - accuracy: 0.9908\n",
            "At the end of episode 1566 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2731/2731 [==============================] - 0s 105us/step - loss: 0.0019 - accuracy: 0.9806\n",
            "At the end of episode 1567 the total reward was : -16.0\n",
            "Epoch 1/1\n",
            "3283/3283 [==============================] - 0s 102us/step - loss: 2.7841e-04 - accuracy: 0.9848\n",
            "At the end of episode 1568 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "2830/2830 [==============================] - 0s 106us/step - loss: 0.0014 - accuracy: 0.9852\n",
            "At the end of episode 1569 the total reward was : -15.0\n",
            "Epoch 1/1\n",
            "3619/3619 [==============================] - 0s 102us/step - loss: -0.0064 - accuracy: 0.9851\n",
            "At the end of episode 1570 the total reward was : -15.0\n",
            "Epoch 1/1\n",
            "3264/3264 [==============================] - 0s 104us/step - loss: -0.0020 - accuracy: 0.9828\n",
            "At the end of episode 1571 the total reward was : -14.0\n",
            "Epoch 1/1\n",
            "3043/3043 [==============================] - 0s 105us/step - loss: -0.0131 - accuracy: 0.9790\n",
            "At the end of episode 1572 the total reward was : -16.0\n",
            "Epoch 1/1\n",
            "3956/3956 [==============================] - 0s 101us/step - loss: 0.0029 - accuracy: 0.9853\n",
            "At the end of episode 1573 the total reward was : -18.0\n",
            "Epoch 1/1\n",
            "2906/2906 [==============================] - 0s 103us/step - loss: -0.0049 - accuracy: 0.9904\n",
            "At the end of episode 1574 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2893/2893 [==============================] - 0s 107us/step - loss: -0.0017 - accuracy: 0.9889\n",
            "At the end of episode 1575 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2638/2638 [==============================] - 0s 110us/step - loss: -4.4814e-04 - accuracy: 0.9901\n",
            "At the end of episode 1576 the total reward was : -20.0\n",
            "Epoch 1/1\n",
            "2424/2424 [==============================] - 0s 104us/step - loss: 0.0030 - accuracy: 0.9913\n",
            "At the end of episode 1577 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "2980/2980 [==============================] - 0s 109us/step - loss: 0.0122 - accuracy: 0.9859\n",
            "At the end of episode 1578 the total reward was : -21.0\n",
            "Epoch 1/1\n",
            "2876/2876 [==============================] - 0s 105us/step - loss: -0.0074 - accuracy: 0.9805\n",
            "At the end of episode 1579 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "2897/2897 [==============================] - 0s 101us/step - loss: -0.0111 - accuracy: 0.9845\n",
            "At the end of episode 1580 the total reward was : -18.0\n",
            "Epoch 1/1\n",
            "2951/2951 [==============================] - 0s 106us/step - loss: 0.0071 - accuracy: 0.9895\n",
            "At the end of episode 1581 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2678/2678 [==============================] - 0s 104us/step - loss: 0.0028 - accuracy: 0.9895\n",
            "At the end of episode 1582 the total reward was : -15.0\n",
            "Epoch 1/1\n",
            "3322/3322 [==============================] - 0s 102us/step - loss: 0.0014 - accuracy: 0.9859\n",
            "At the end of episode 1583 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "3126/3126 [==============================] - 0s 102us/step - loss: 0.0032 - accuracy: 0.9827\n",
            "At the end of episode 1584 the total reward was : -16.0\n",
            "Epoch 1/1\n",
            "2653/2653 [==============================] - 0s 102us/step - loss: 0.0042 - accuracy: 0.9812\n",
            "At the end of episode 1585 the total reward was : -16.0\n",
            "Epoch 1/1\n",
            "3379/3379 [==============================] - 0s 105us/step - loss: -6.8333e-04 - accuracy: 0.9885\n",
            "At the end of episode 1586 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2898/2898 [==============================] - 0s 101us/step - loss: 0.0043 - accuracy: 0.9917\n",
            "At the end of episode 1587 the total reward was : -15.0\n",
            "Epoch 1/1\n",
            "2852/2852 [==============================] - 0s 107us/step - loss: -0.0049 - accuracy: 0.9881\n",
            "At the end of episode 1588 the total reward was : -20.0\n",
            "Epoch 1/1\n",
            "3286/3286 [==============================] - 0s 109us/step - loss: -0.0034 - accuracy: 0.9823\n",
            "At the end of episode 1589 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "3134/3134 [==============================] - 0s 101us/step - loss: 0.0131 - accuracy: 0.9837\n",
            "At the end of episode 1590 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "3472/3472 [==============================] - 0s 104us/step - loss: 0.0025 - accuracy: 0.9868\n",
            "At the end of episode 1591 the total reward was : -16.0\n",
            "Epoch 1/1\n",
            "2801/2801 [==============================] - 0s 103us/step - loss: -0.0059 - accuracy: 0.9846\n",
            "At the end of episode 1592 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "2977/2977 [==============================] - 0s 103us/step - loss: -0.0021 - accuracy: 0.9748\n",
            "At the end of episode 1593 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "3216/3216 [==============================] - 0s 105us/step - loss: -9.1518e-04 - accuracy: 0.9857\n",
            "At the end of episode 1594 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2420/2420 [==============================] - 0s 103us/step - loss: -0.0083 - accuracy: 0.9888\n",
            "At the end of episode 1595 the total reward was : -16.0\n",
            "Epoch 1/1\n",
            "3752/3752 [==============================] - 0s 105us/step - loss: 0.0074 - accuracy: 0.9840\n",
            "At the end of episode 1596 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2168/2168 [==============================] - 0s 103us/step - loss: -9.6631e-04 - accuracy: 0.9871\n",
            "At the end of episode 1597 the total reward was : -18.0\n",
            "Epoch 1/1\n",
            "2642/2642 [==============================] - 0s 104us/step - loss: 0.0013 - accuracy: 0.9890\n",
            "At the end of episode 1598 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "3166/3166 [==============================] - 0s 102us/step - loss: -0.0043 - accuracy: 0.9880\n",
            "At the end of episode 1599 the total reward was : -14.0\n",
            "Epoch 1/1\n",
            "3830/3830 [==============================] - 0s 104us/step - loss: -0.0011 - accuracy: 0.9854\n",
            "At the end of episode 1600 the total reward was : -16.0\n",
            "Epoch 1/1\n",
            "2860/2860 [==============================] - 0s 102us/step - loss: 0.0021 - accuracy: 0.9850\n",
            "At the end of episode 1601 the total reward was : -16.0\n",
            "Epoch 1/1\n",
            "2308/2308 [==============================] - 0s 107us/step - loss: -8.3200e-04 - accuracy: 0.9870\n",
            "At the end of episode 1602 the total reward was : -15.0\n",
            "Epoch 1/1\n",
            "3008/3008 [==============================] - 0s 103us/step - loss: -0.0039 - accuracy: 0.9877\n",
            "At the end of episode 1603 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "3394/3394 [==============================] - 0s 105us/step - loss: 0.0053 - accuracy: 0.9859\n",
            "At the end of episode 1604 the total reward was : -18.0\n",
            "Epoch 1/1\n",
            "3341/3341 [==============================] - 0s 108us/step - loss: 0.0028 - accuracy: 0.9868\n",
            "At the end of episode 1605 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "3062/3062 [==============================] - 0s 106us/step - loss: -0.0025 - accuracy: 0.9860\n",
            "At the end of episode 1606 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "2760/2760 [==============================] - 0s 120us/step - loss: 0.0030 - accuracy: 0.9888\n",
            "At the end of episode 1607 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "3237/3237 [==============================] - 0s 107us/step - loss: 0.0014 - accuracy: 0.9901\n",
            "At the end of episode 1608 the total reward was : -18.0\n",
            "Epoch 1/1\n",
            "2953/2953 [==============================] - 0s 104us/step - loss: 0.0033 - accuracy: 0.9878\n",
            "At the end of episode 1609 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "3016/3016 [==============================] - 0s 102us/step - loss: -4.9186e-04 - accuracy: 0.9894\n",
            "At the end of episode 1610 the total reward was : -18.0\n",
            "Epoch 1/1\n",
            "3256/3256 [==============================] - 0s 109us/step - loss: 0.0042 - accuracy: 0.9831\n",
            "At the end of episode 1611 the total reward was : -18.0\n",
            "Epoch 1/1\n",
            "2636/2636 [==============================] - 0s 103us/step - loss: -2.5307e-04 - accuracy: 0.9867\n",
            "At the end of episode 1612 the total reward was : -14.0\n",
            "Epoch 1/1\n",
            "3127/3127 [==============================] - 0s 105us/step - loss: 0.0014 - accuracy: 0.9914\n",
            "At the end of episode 1613 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "3439/3439 [==============================] - 0s 113us/step - loss: -0.0075 - accuracy: 0.9796\n",
            "At the end of episode 1614 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "3128/3128 [==============================] - 0s 105us/step - loss: 7.7226e-04 - accuracy: 0.9859\n",
            "At the end of episode 1615 the total reward was : -16.0\n",
            "Epoch 1/1\n",
            "2939/2939 [==============================] - 0s 106us/step - loss: -0.0159 - accuracy: 0.9837\n",
            "At the end of episode 1616 the total reward was : -14.0\n",
            "Epoch 1/1\n",
            "2649/2649 [==============================] - 0s 106us/step - loss: 0.0012 - accuracy: 0.9853\n",
            "At the end of episode 1617 the total reward was : -15.0\n",
            "Epoch 1/1\n",
            "3802/3802 [==============================] - 0s 108us/step - loss: -0.0082 - accuracy: 0.9834\n",
            "At the end of episode 1618 the total reward was : -16.0\n",
            "Epoch 1/1\n",
            "2886/2886 [==============================] - 0s 105us/step - loss: -0.0110 - accuracy: 0.9834\n",
            "At the end of episode 1619 the total reward was : -20.0\n",
            "Epoch 1/1\n",
            "3040/3040 [==============================] - 0s 104us/step - loss: -0.0057 - accuracy: 0.9895\n",
            "At the end of episode 1620 the total reward was : -13.0\n",
            "Epoch 1/1\n",
            "2919/2919 [==============================] - 0s 108us/step - loss: -0.0178 - accuracy: 0.9887\n",
            "At the end of episode 1621 the total reward was : -18.0\n",
            "Epoch 1/1\n",
            "2372/2372 [==============================] - 0s 102us/step - loss: 0.0056 - accuracy: 0.9852\n",
            "At the end of episode 1622 the total reward was : -15.0\n",
            "Epoch 1/1\n",
            "3511/3511 [==============================] - 0s 102us/step - loss: 0.0045 - accuracy: 0.9841\n",
            "At the end of episode 1623 the total reward was : -14.0\n",
            "Epoch 1/1\n",
            "3204/3204 [==============================] - 0s 104us/step - loss: 0.0096 - accuracy: 0.9816\n",
            "At the end of episode 1624 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "2599/2599 [==============================] - 0s 111us/step - loss: -0.0130 - accuracy: 0.9850\n",
            "At the end of episode 1625 the total reward was : -20.0\n",
            "Epoch 1/1\n",
            "3025/3025 [==============================] - 0s 102us/step - loss: -0.0032 - accuracy: 0.9888\n",
            "At the end of episode 1626 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2743/2743 [==============================] - 0s 106us/step - loss: 0.0040 - accuracy: 0.9883\n",
            "At the end of episode 1627 the total reward was : -20.0\n",
            "Epoch 1/1\n",
            "2046/2046 [==============================] - 0s 108us/step - loss: -0.0057 - accuracy: 0.9888\n",
            "At the end of episode 1628 the total reward was : -15.0\n",
            "Epoch 1/1\n",
            "2522/2522 [==============================] - 0s 99us/step - loss: 0.0050 - accuracy: 0.9857\n",
            "At the end of episode 1629 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2574/2574 [==============================] - 0s 105us/step - loss: 0.0033 - accuracy: 0.9837\n",
            "At the end of episode 1630 the total reward was : -20.0\n",
            "Epoch 1/1\n",
            "2447/2447 [==============================] - 0s 104us/step - loss: 0.0023 - accuracy: 0.9890\n",
            "At the end of episode 1631 the total reward was : -16.0\n",
            "Epoch 1/1\n",
            "2456/2456 [==============================] - 0s 102us/step - loss: -0.0103 - accuracy: 0.9882\n",
            "At the end of episode 1632 the total reward was : -20.0\n",
            "Epoch 1/1\n",
            "2456/2456 [==============================] - 0s 104us/step - loss: -0.0034 - accuracy: 0.9902\n",
            "At the end of episode 1633 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "1702/1702 [==============================] - 0s 102us/step - loss: 4.7239e-04 - accuracy: 0.9882\n",
            "At the end of episode 1634 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "2262/2262 [==============================] - 0s 102us/step - loss: 0.0032 - accuracy: 0.9881\n",
            "At the end of episode 1635 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "3272/3272 [==============================] - 0s 110us/step - loss: -0.0029 - accuracy: 0.9878\n",
            "At the end of episode 1636 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "2925/2925 [==============================] - 0s 103us/step - loss: 5.6283e-04 - accuracy: 0.9860\n",
            "At the end of episode 1637 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2440/2440 [==============================] - 0s 114us/step - loss: 5.1871e-04 - accuracy: 0.9889\n",
            "At the end of episode 1638 the total reward was : -20.0\n",
            "Epoch 1/1\n",
            "1958/1958 [==============================] - 0s 101us/step - loss: 0.0025 - accuracy: 0.9903\n",
            "At the end of episode 1639 the total reward was : -18.0\n",
            "Epoch 1/1\n",
            "2375/2375 [==============================] - 0s 105us/step - loss: 0.0038 - accuracy: 0.9869\n",
            "At the end of episode 1640 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2005/2005 [==============================] - 0s 107us/step - loss: -0.0041 - accuracy: 0.9820\n",
            "At the end of episode 1641 the total reward was : -20.0\n",
            "Epoch 1/1\n",
            "2758/2758 [==============================] - 0s 103us/step - loss: 0.0087 - accuracy: 0.9859\n",
            "At the end of episode 1642 the total reward was : -15.0\n",
            "Epoch 1/1\n",
            "2581/2581 [==============================] - 0s 105us/step - loss: 5.7913e-04 - accuracy: 0.9880\n",
            "At the end of episode 1643 the total reward was : -20.0\n",
            "Epoch 1/1\n",
            "2026/2026 [==============================] - 0s 109us/step - loss: -0.0018 - accuracy: 0.9931\n",
            "At the end of episode 1644 the total reward was : -20.0\n",
            "Epoch 1/1\n",
            "2525/2525 [==============================] - 0s 114us/step - loss: 0.0012 - accuracy: 0.9850\n",
            "At the end of episode 1645 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "2595/2595 [==============================] - 0s 106us/step - loss: 0.0072 - accuracy: 0.9811\n",
            "At the end of episode 1646 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2420/2420 [==============================] - 0s 101us/step - loss: -0.0040 - accuracy: 0.9860\n",
            "At the end of episode 1647 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "3390/3390 [==============================] - 0s 104us/step - loss: 0.0042 - accuracy: 0.9820\n",
            "At the end of episode 1648 the total reward was : -18.0\n",
            "Epoch 1/1\n",
            "2155/2155 [==============================] - 0s 103us/step - loss: -0.0084 - accuracy: 0.9884\n",
            "At the end of episode 1649 the total reward was : -20.0\n",
            "Epoch 1/1\n",
            "1308/1308 [==============================] - 0s 111us/step - loss: 0.0158 - accuracy: 0.9885\n",
            "At the end of episode 1650 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2058/2058 [==============================] - 0s 103us/step - loss: 0.0036 - accuracy: 0.9849\n",
            "At the end of episode 1651 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2174/2174 [==============================] - 0s 112us/step - loss: 0.0066 - accuracy: 0.9857\n",
            "At the end of episode 1652 the total reward was : -20.0\n",
            "Epoch 1/1\n",
            "2338/2338 [==============================] - 0s 103us/step - loss: -2.3787e-04 - accuracy: 0.9910\n",
            "At the end of episode 1653 the total reward was : -16.0\n",
            "Epoch 1/1\n",
            "2299/2299 [==============================] - 0s 110us/step - loss: 0.0046 - accuracy: 0.9896\n",
            "At the end of episode 1654 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "2994/2994 [==============================] - 0s 101us/step - loss: 0.0102 - accuracy: 0.9846\n",
            "At the end of episode 1655 the total reward was : -18.0\n",
            "Epoch 1/1\n",
            "2539/2539 [==============================] - 0s 110us/step - loss: 0.0065 - accuracy: 0.9819\n",
            "At the end of episode 1656 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "1852/1852 [==============================] - 0s 104us/step - loss: -0.0045 - accuracy: 0.9903\n",
            "At the end of episode 1657 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "2502/2502 [==============================] - 0s 103us/step - loss: -0.0156 - accuracy: 0.9824\n",
            "At the end of episode 1658 the total reward was : -14.0\n",
            "Epoch 1/1\n",
            "2586/2586 [==============================] - 0s 102us/step - loss: -0.0091 - accuracy: 0.9884\n",
            "At the end of episode 1659 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2074/2074 [==============================] - 0s 102us/step - loss: -0.0028 - accuracy: 0.9918\n",
            "At the end of episode 1660 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "2909/2909 [==============================] - 0s 106us/step - loss: 3.8298e-04 - accuracy: 0.9897\n",
            "At the end of episode 1661 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "3392/3392 [==============================] - 0s 107us/step - loss: -0.0043 - accuracy: 0.9876\n",
            "At the end of episode 1662 the total reward was : -16.0\n",
            "Epoch 1/1\n",
            "3455/3455 [==============================] - 0s 109us/step - loss: 9.4026e-04 - accuracy: 0.9881\n",
            "At the end of episode 1663 the total reward was : -18.0\n",
            "Epoch 1/1\n",
            "2437/2437 [==============================] - 0s 103us/step - loss: -0.0054 - accuracy: 0.9787\n",
            "At the end of episode 1664 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "3088/3088 [==============================] - 0s 106us/step - loss: 0.0030 - accuracy: 0.9812\n",
            "At the end of episode 1665 the total reward was : -18.0\n",
            "Epoch 1/1\n",
            "3023/3023 [==============================] - 0s 102us/step - loss: -0.0059 - accuracy: 0.9897\n",
            "At the end of episode 1666 the total reward was : -15.0\n",
            "Epoch 1/1\n",
            "3629/3629 [==============================] - 0s 107us/step - loss: 0.0028 - accuracy: 0.9854\n",
            "At the end of episode 1667 the total reward was : -16.0\n",
            "Epoch 1/1\n",
            "2685/2685 [==============================] - 0s 107us/step - loss: -0.0053 - accuracy: 0.9866\n",
            "At the end of episode 1668 the total reward was : -16.0\n",
            "Epoch 1/1\n",
            "2638/2638 [==============================] - 0s 109us/step - loss: -0.0046 - accuracy: 0.9886\n",
            "At the end of episode 1669 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "2648/2648 [==============================] - 0s 109us/step - loss: -0.0046 - accuracy: 0.9823\n",
            "At the end of episode 1670 the total reward was : -18.0\n",
            "Epoch 1/1\n",
            "3032/3032 [==============================] - 0s 104us/step - loss: -0.0057 - accuracy: 0.9832\n",
            "At the end of episode 1671 the total reward was : -20.0\n",
            "Epoch 1/1\n",
            "2213/2213 [==============================] - 0s 106us/step - loss: -0.0015 - accuracy: 0.9873\n",
            "At the end of episode 1672 the total reward was : -16.0\n",
            "Epoch 1/1\n",
            "2879/2879 [==============================] - 0s 110us/step - loss: -0.0056 - accuracy: 0.9875\n",
            "At the end of episode 1673 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "3171/3171 [==============================] - 0s 109us/step - loss: 0.0024 - accuracy: 0.9845\n",
            "At the end of episode 1674 the total reward was : -14.0\n",
            "Epoch 1/1\n",
            "2994/2994 [==============================] - 0s 106us/step - loss: -0.0056 - accuracy: 0.9820\n",
            "At the end of episode 1675 the total reward was : -15.0\n",
            "Epoch 1/1\n",
            "3072/3072 [==============================] - 0s 105us/step - loss: -6.0389e-04 - accuracy: 0.9857\n",
            "At the end of episode 1676 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2957/2957 [==============================] - 0s 108us/step - loss: -0.0033 - accuracy: 0.9858\n",
            "At the end of episode 1677 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2981/2981 [==============================] - 0s 102us/step - loss: 0.0037 - accuracy: 0.9866\n",
            "At the end of episode 1678 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "3329/3329 [==============================] - 0s 106us/step - loss: 0.0056 - accuracy: 0.9832\n",
            "At the end of episode 1679 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "3242/3242 [==============================] - 0s 105us/step - loss: -7.0247e-04 - accuracy: 0.9861\n",
            "At the end of episode 1680 the total reward was : -13.0\n",
            "Epoch 1/1\n",
            "3506/3506 [==============================] - 0s 114us/step - loss: 0.0011 - accuracy: 0.9860\n",
            "At the end of episode 1681 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "3143/3143 [==============================] - 0s 106us/step - loss: -0.0063 - accuracy: 0.9876\n",
            "At the end of episode 1682 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2422/2422 [==============================] - 0s 102us/step - loss: 0.0013 - accuracy: 0.9876\n",
            "At the end of episode 1683 the total reward was : -13.0\n",
            "Epoch 1/1\n",
            "3179/3179 [==============================] - 0s 106us/step - loss: 0.0042 - accuracy: 0.9921\n",
            "At the end of episode 1684 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2727/2727 [==============================] - 0s 105us/step - loss: -0.0089 - accuracy: 0.9916\n",
            "At the end of episode 1685 the total reward was : -20.0\n",
            "Epoch 1/1\n",
            "2604/2604 [==============================] - 0s 106us/step - loss: 4.0339e-04 - accuracy: 0.9873\n",
            "At the end of episode 1686 the total reward was : -14.0\n",
            "Epoch 1/1\n",
            "4072/4072 [==============================] - 0s 106us/step - loss: 0.0025 - accuracy: 0.9887\n",
            "At the end of episode 1687 the total reward was : -14.0\n",
            "Epoch 1/1\n",
            "3547/3547 [==============================] - 0s 106us/step - loss: -0.0032 - accuracy: 0.9893\n",
            "At the end of episode 1688 the total reward was : -15.0\n",
            "Epoch 1/1\n",
            "3076/3076 [==============================] - 0s 105us/step - loss: -2.4450e-04 - accuracy: 0.9922\n",
            "At the end of episode 1689 the total reward was : -16.0\n",
            "Epoch 1/1\n",
            "3325/3325 [==============================] - 0s 103us/step - loss: -0.0062 - accuracy: 0.9880\n",
            "At the end of episode 1690 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2962/2962 [==============================] - 0s 110us/step - loss: 0.0117 - accuracy: 0.9875\n",
            "At the end of episode 1691 the total reward was : -13.0\n",
            "Epoch 1/1\n",
            "3506/3506 [==============================] - 0s 102us/step - loss: 0.0152 - accuracy: 0.9857\n",
            "At the end of episode 1692 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "3151/3151 [==============================] - 0s 107us/step - loss: -0.0040 - accuracy: 0.9851\n",
            "At the end of episode 1693 the total reward was : -18.0\n",
            "Epoch 1/1\n",
            "3263/3263 [==============================] - 0s 106us/step - loss: -6.1336e-04 - accuracy: 0.9896\n",
            "At the end of episode 1694 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2358/2358 [==============================] - 0s 102us/step - loss: -9.1557e-04 - accuracy: 0.9924\n",
            "At the end of episode 1695 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "3022/3022 [==============================] - 0s 106us/step - loss: 0.0020 - accuracy: 0.9884\n",
            "At the end of episode 1696 the total reward was : -15.0\n",
            "Epoch 1/1\n",
            "3268/3268 [==============================] - 0s 118us/step - loss: -2.4968e-04 - accuracy: 0.9927\n",
            "At the end of episode 1697 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "2478/2478 [==============================] - 0s 102us/step - loss: 0.0031 - accuracy: 0.9891\n",
            "At the end of episode 1698 the total reward was : -14.0\n",
            "Epoch 1/1\n",
            "3682/3682 [==============================] - 0s 107us/step - loss: -0.0029 - accuracy: 0.9878\n",
            "At the end of episode 1699 the total reward was : -16.0\n",
            "Epoch 1/1\n",
            "3037/3037 [==============================] - 0s 108us/step - loss: -5.3558e-04 - accuracy: 0.9855\n",
            "At the end of episode 1700 the total reward was : -13.0\n",
            "Epoch 1/1\n",
            "3572/3572 [==============================] - 0s 102us/step - loss: 0.0078 - accuracy: 0.9829\n",
            "At the end of episode 1701 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "3383/3383 [==============================] - 0s 101us/step - loss: -0.0050 - accuracy: 0.9846\n",
            "At the end of episode 1702 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "2901/2901 [==============================] - 0s 105us/step - loss: -0.0038 - accuracy: 0.9876\n",
            "At the end of episode 1703 the total reward was : -12.0\n",
            "Epoch 1/1\n",
            "2971/2971 [==============================] - 0s 109us/step - loss: 0.0024 - accuracy: 0.9879\n",
            "At the end of episode 1704 the total reward was : -18.0\n",
            "Epoch 1/1\n",
            "2530/2530 [==============================] - 0s 104us/step - loss: -0.0013 - accuracy: 0.9897\n",
            "At the end of episode 1705 the total reward was : -21.0\n",
            "Epoch 1/1\n",
            "2649/2649 [==============================] - 0s 105us/step - loss: 0.0075 - accuracy: 0.9887\n",
            "At the end of episode 1706 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "2844/2844 [==============================] - 0s 101us/step - loss: -8.3479e-04 - accuracy: 0.9842\n",
            "At the end of episode 1707 the total reward was : -13.0\n",
            "Epoch 1/1\n",
            "3411/3411 [==============================] - 0s 107us/step - loss: -0.0014 - accuracy: 0.9868\n",
            "At the end of episode 1708 the total reward was : -16.0\n",
            "Epoch 1/1\n",
            "2562/2562 [==============================] - 0s 106us/step - loss: -0.0041 - accuracy: 0.9891\n",
            "At the end of episode 1709 the total reward was : -20.0\n",
            "Epoch 1/1\n",
            "2205/2205 [==============================] - 0s 102us/step - loss: -0.0031 - accuracy: 0.9896\n",
            "At the end of episode 1710 the total reward was : -13.0\n",
            "Epoch 1/1\n",
            "3902/3902 [==============================] - 0s 103us/step - loss: 9.5518e-05 - accuracy: 0.9903\n",
            "At the end of episode 1711 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "2671/2671 [==============================] - 0s 102us/step - loss: 3.0471e-04 - accuracy: 0.9899\n",
            "At the end of episode 1712 the total reward was : -15.0\n",
            "Epoch 1/1\n",
            "3229/3229 [==============================] - 0s 107us/step - loss: -0.0122 - accuracy: 0.9780\n",
            "At the end of episode 1713 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "2337/2337 [==============================] - 0s 108us/step - loss: 9.1416e-04 - accuracy: 0.9876\n",
            "At the end of episode 1714 the total reward was : -15.0\n",
            "Epoch 1/1\n",
            "2619/2619 [==============================] - 0s 101us/step - loss: 5.8434e-04 - accuracy: 0.9905\n",
            "At the end of episode 1715 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2339/2339 [==============================] - 0s 108us/step - loss: -6.6811e-04 - accuracy: 0.9906\n",
            "At the end of episode 1716 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "2681/2681 [==============================] - 0s 109us/step - loss: -0.0049 - accuracy: 0.9866\n",
            "At the end of episode 1717 the total reward was : -18.0\n",
            "Epoch 1/1\n",
            "2456/2456 [==============================] - 0s 104us/step - loss: 0.0057 - accuracy: 0.9837\n",
            "At the end of episode 1718 the total reward was : -21.0\n",
            "Epoch 1/1\n",
            "2162/2162 [==============================] - 0s 106us/step - loss: 0.0023 - accuracy: 0.9912\n",
            "At the end of episode 1719 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "2646/2646 [==============================] - 0s 106us/step - loss: -0.0057 - accuracy: 0.9872\n",
            "At the end of episode 1720 the total reward was : -13.0\n",
            "Epoch 1/1\n",
            "3098/3098 [==============================] - 0s 102us/step - loss: 0.0028 - accuracy: 0.9900\n",
            "At the end of episode 1721 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "2684/2684 [==============================] - 0s 105us/step - loss: 0.0056 - accuracy: 0.9892\n",
            "At the end of episode 1722 the total reward was : -12.0\n",
            "Epoch 1/1\n",
            "2905/2905 [==============================] - 0s 105us/step - loss: -0.0026 - accuracy: 0.9924\n",
            "At the end of episode 1723 the total reward was : -12.0\n",
            "Epoch 1/1\n",
            "2826/2826 [==============================] - 0s 103us/step - loss: 0.0038 - accuracy: 0.9929\n",
            "At the end of episode 1724 the total reward was : -15.0\n",
            "Epoch 1/1\n",
            "2807/2807 [==============================] - 0s 101us/step - loss: 0.0011 - accuracy: 0.9893\n",
            "At the end of episode 1725 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "2977/2977 [==============================] - 0s 104us/step - loss: -0.0020 - accuracy: 0.9889\n",
            "At the end of episode 1726 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "3155/3155 [==============================] - 0s 100us/step - loss: -0.0101 - accuracy: 0.9880\n",
            "At the end of episode 1727 the total reward was : -15.0\n",
            "Epoch 1/1\n",
            "2686/2686 [==============================] - 0s 101us/step - loss: 0.0056 - accuracy: 0.9903\n",
            "At the end of episode 1728 the total reward was : -20.0\n",
            "Epoch 1/1\n",
            "2354/2354 [==============================] - 0s 101us/step - loss: 0.0041 - accuracy: 0.9894\n",
            "At the end of episode 1729 the total reward was : -20.0\n",
            "Epoch 1/1\n",
            "2441/2441 [==============================] - 0s 109us/step - loss: -0.0083 - accuracy: 0.9873\n",
            "At the end of episode 1730 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2170/2170 [==============================] - 0s 101us/step - loss: 7.7577e-04 - accuracy: 0.9866\n",
            "At the end of episode 1731 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2725/2725 [==============================] - 0s 106us/step - loss: -0.0121 - accuracy: 0.9886\n",
            "At the end of episode 1732 the total reward was : -16.0\n",
            "Epoch 1/1\n",
            "2724/2724 [==============================] - 0s 101us/step - loss: -0.0024 - accuracy: 0.9872\n",
            "At the end of episode 1733 the total reward was : -18.0\n",
            "Epoch 1/1\n",
            "2362/2362 [==============================] - 0s 103us/step - loss: -0.0026 - accuracy: 0.9843\n",
            "At the end of episode 1734 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2012/2012 [==============================] - 0s 103us/step - loss: 0.0017 - accuracy: 0.9916\n",
            "At the end of episode 1735 the total reward was : -15.0\n",
            "Epoch 1/1\n",
            "2607/2607 [==============================] - 0s 103us/step - loss: -0.0082 - accuracy: 0.9881\n",
            "At the end of episode 1736 the total reward was : -12.0\n",
            "Epoch 1/1\n",
            "3321/3321 [==============================] - 0s 106us/step - loss: -0.0030 - accuracy: 0.9916\n",
            "At the end of episode 1737 the total reward was : -15.0\n",
            "Epoch 1/1\n",
            "2935/2935 [==============================] - 0s 105us/step - loss: 0.0019 - accuracy: 0.9860\n",
            "At the end of episode 1738 the total reward was : -16.0\n",
            "Epoch 1/1\n",
            "2487/2487 [==============================] - 0s 108us/step - loss: -0.0214 - accuracy: 0.9791\n",
            "At the end of episode 1739 the total reward was : -21.0\n",
            "Epoch 1/1\n",
            "2490/2490 [==============================] - 0s 105us/step - loss: -0.0032 - accuracy: 0.9924\n",
            "At the end of episode 1740 the total reward was : -15.0\n",
            "Epoch 1/1\n",
            "3139/3139 [==============================] - 0s 108us/step - loss: -0.0043 - accuracy: 0.9822\n",
            "At the end of episode 1741 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2650/2650 [==============================] - 0s 101us/step - loss: 0.0016 - accuracy: 0.9898\n",
            "At the end of episode 1742 the total reward was : -12.0\n",
            "Epoch 1/1\n",
            "2906/2906 [==============================] - 0s 107us/step - loss: -0.0050 - accuracy: 0.9890\n",
            "At the end of episode 1743 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "2978/2978 [==============================] - 0s 104us/step - loss: 1.1520e-04 - accuracy: 0.9889\n",
            "At the end of episode 1744 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2503/2503 [==============================] - 0s 100us/step - loss: 0.0054 - accuracy: 0.9892\n",
            "At the end of episode 1745 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "2828/2828 [==============================] - 0s 108us/step - loss: 0.0067 - accuracy: 0.9859\n",
            "At the end of episode 1746 the total reward was : -16.0\n",
            "Epoch 1/1\n",
            "2782/2782 [==============================] - 0s 101us/step - loss: 0.0069 - accuracy: 0.9881\n",
            "At the end of episode 1747 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "2915/2915 [==============================] - 0s 102us/step - loss: -1.2048e-04 - accuracy: 0.9907\n",
            "At the end of episode 1748 the total reward was : -16.0\n",
            "Epoch 1/1\n",
            "2505/2505 [==============================] - 0s 102us/step - loss: 2.9760e-05 - accuracy: 0.9900\n",
            "At the end of episode 1749 the total reward was : -14.0\n",
            "Epoch 1/1\n",
            "2812/2812 [==============================] - 0s 101us/step - loss: -0.0018 - accuracy: 0.9900\n",
            "At the end of episode 1750 the total reward was : -15.0\n",
            "Epoch 1/1\n",
            "2267/2267 [==============================] - 0s 108us/step - loss: 0.0032 - accuracy: 0.9943\n",
            "At the end of episode 1751 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "2521/2521 [==============================] - 0s 106us/step - loss: 0.0062 - accuracy: 0.9845\n",
            "At the end of episode 1752 the total reward was : -15.0\n",
            "Epoch 1/1\n",
            "3000/3000 [==============================] - 0s 107us/step - loss: 0.0041 - accuracy: 0.9887\n",
            "At the end of episode 1753 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "2529/2529 [==============================] - 0s 103us/step - loss: 0.0011 - accuracy: 0.9866\n",
            "At the end of episode 1754 the total reward was : -15.0\n",
            "Epoch 1/1\n",
            "3663/3663 [==============================] - 0s 111us/step - loss: -0.0041 - accuracy: 0.9853\n",
            "At the end of episode 1755 the total reward was : -15.0\n",
            "Epoch 1/1\n",
            "2745/2745 [==============================] - 0s 105us/step - loss: -0.0018 - accuracy: 0.9872\n",
            "At the end of episode 1756 the total reward was : -15.0\n",
            "Epoch 1/1\n",
            "2899/2899 [==============================] - 0s 108us/step - loss: -0.0047 - accuracy: 0.9862\n",
            "At the end of episode 1757 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "2558/2558 [==============================] - 0s 105us/step - loss: 2.0029e-05 - accuracy: 0.9891\n",
            "At the end of episode 1758 the total reward was : -14.0\n",
            "Epoch 1/1\n",
            "2709/2709 [==============================] - 0s 105us/step - loss: -0.0068 - accuracy: 0.9867\n",
            "At the end of episode 1759 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2676/2676 [==============================] - 0s 105us/step - loss: 0.0022 - accuracy: 0.9854\n",
            "At the end of episode 1760 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2908/2908 [==============================] - 0s 104us/step - loss: -0.0023 - accuracy: 0.9897\n",
            "At the end of episode 1761 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "3321/3321 [==============================] - 0s 115us/step - loss: -0.0033 - accuracy: 0.9880\n",
            "At the end of episode 1762 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "3348/3348 [==============================] - 0s 114us/step - loss: -5.7999e-04 - accuracy: 0.9881\n",
            "At the end of episode 1763 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2835/2835 [==============================] - 0s 106us/step - loss: 0.0088 - accuracy: 0.9862\n",
            "At the end of episode 1764 the total reward was : -13.0\n",
            "Epoch 1/1\n",
            "3320/3320 [==============================] - 0s 105us/step - loss: -0.0103 - accuracy: 0.9843\n",
            "At the end of episode 1765 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2474/2474 [==============================] - 0s 106us/step - loss: 0.0080 - accuracy: 0.9907\n",
            "At the end of episode 1766 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "2345/2345 [==============================] - 0s 103us/step - loss: -0.0018 - accuracy: 0.9923\n",
            "At the end of episode 1767 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2839/2839 [==============================] - 0s 102us/step - loss: 0.0052 - accuracy: 0.9856\n",
            "At the end of episode 1768 the total reward was : -20.0\n",
            "Epoch 1/1\n",
            "2867/2867 [==============================] - 0s 106us/step - loss: -0.0028 - accuracy: 0.9899\n",
            "At the end of episode 1769 the total reward was : -15.0\n",
            "Epoch 1/1\n",
            "3212/3212 [==============================] - 0s 102us/step - loss: -0.0028 - accuracy: 0.9869\n",
            "At the end of episode 1770 the total reward was : -13.0\n",
            "Epoch 1/1\n",
            "3600/3600 [==============================] - 0s 110us/step - loss: 0.0037 - accuracy: 0.9867\n",
            "At the end of episode 1771 the total reward was : -18.0\n",
            "Epoch 1/1\n",
            "2953/2953 [==============================] - 0s 105us/step - loss: -0.0019 - accuracy: 0.9919\n",
            "At the end of episode 1772 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "2478/2478 [==============================] - 0s 105us/step - loss: -0.0014 - accuracy: 0.9879\n",
            "At the end of episode 1773 the total reward was : -18.0\n",
            "Epoch 1/1\n",
            "2781/2781 [==============================] - 0s 100us/step - loss: -0.0065 - accuracy: 0.9867\n",
            "At the end of episode 1774 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2588/2588 [==============================] - 0s 102us/step - loss: -0.0109 - accuracy: 0.9853\n",
            "At the end of episode 1775 the total reward was : -18.0\n",
            "Epoch 1/1\n",
            "2612/2612 [==============================] - 0s 102us/step - loss: 0.0021 - accuracy: 0.9897\n",
            "At the end of episode 1776 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2821/2821 [==============================] - 0s 101us/step - loss: -0.0068 - accuracy: 0.9784\n",
            "At the end of episode 1777 the total reward was : -15.0\n",
            "Epoch 1/1\n",
            "3019/3019 [==============================] - 0s 102us/step - loss: 0.0043 - accuracy: 0.9901\n",
            "At the end of episode 1778 the total reward was : -15.0\n",
            "Epoch 1/1\n",
            "2923/2923 [==============================] - 0s 111us/step - loss: 3.5315e-04 - accuracy: 0.9894\n",
            "At the end of episode 1779 the total reward was : -16.0\n",
            "Epoch 1/1\n",
            "3357/3357 [==============================] - 0s 112us/step - loss: 7.7314e-04 - accuracy: 0.9863\n",
            "At the end of episode 1780 the total reward was : -18.0\n",
            "Epoch 1/1\n",
            "2938/2938 [==============================] - 0s 103us/step - loss: -0.0014 - accuracy: 0.9864\n",
            "At the end of episode 1781 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "3228/3228 [==============================] - 0s 105us/step - loss: 0.0060 - accuracy: 0.9857\n",
            "At the end of episode 1782 the total reward was : -15.0\n",
            "Epoch 1/1\n",
            "3584/3584 [==============================] - 0s 104us/step - loss: -0.0012 - accuracy: 0.9863\n",
            "At the end of episode 1783 the total reward was : -13.0\n",
            "Epoch 1/1\n",
            "3067/3067 [==============================] - 0s 104us/step - loss: -0.0022 - accuracy: 0.9876\n",
            "At the end of episode 1784 the total reward was : -15.0\n",
            "Epoch 1/1\n",
            "3092/3092 [==============================] - 0s 108us/step - loss: -0.0011 - accuracy: 0.9900\n",
            "At the end of episode 1785 the total reward was : -16.0\n",
            "Epoch 1/1\n",
            "3119/3119 [==============================] - 0s 103us/step - loss: 0.0140 - accuracy: 0.9875\n",
            "At the end of episode 1786 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "2614/2614 [==============================] - 0s 106us/step - loss: 0.0102 - accuracy: 0.9858\n",
            "At the end of episode 1787 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "2816/2816 [==============================] - 0s 102us/step - loss: 0.0088 - accuracy: 0.9869\n",
            "At the end of episode 1788 the total reward was : -18.0\n",
            "Epoch 1/1\n",
            "2700/2700 [==============================] - 0s 107us/step - loss: 3.3581e-04 - accuracy: 0.9856\n",
            "At the end of episode 1789 the total reward was : -20.0\n",
            "Epoch 1/1\n",
            "2940/2940 [==============================] - 0s 102us/step - loss: -0.0013 - accuracy: 0.9895\n",
            "At the end of episode 1790 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "2753/2753 [==============================] - 0s 105us/step - loss: -0.0025 - accuracy: 0.9873\n",
            "At the end of episode 1791 the total reward was : -20.0\n",
            "Epoch 1/1\n",
            "2978/2978 [==============================] - 0s 105us/step - loss: 0.0022 - accuracy: 0.9889\n",
            "At the end of episode 1792 the total reward was : -13.0\n",
            "Epoch 1/1\n",
            "3434/3434 [==============================] - 0s 110us/step - loss: 4.2148e-04 - accuracy: 0.9889\n",
            "At the end of episode 1793 the total reward was : -15.0\n",
            "Epoch 1/1\n",
            "3600/3600 [==============================] - 0s 106us/step - loss: -0.0053 - accuracy: 0.9869\n",
            "At the end of episode 1794 the total reward was : -21.0\n",
            "Epoch 1/1\n",
            "2463/2463 [==============================] - 0s 103us/step - loss: 0.0030 - accuracy: 0.9931\n",
            "At the end of episode 1795 the total reward was : -14.0\n",
            "Epoch 1/1\n",
            "3374/3374 [==============================] - 0s 106us/step - loss: -0.0068 - accuracy: 0.9890\n",
            "At the end of episode 1796 the total reward was : -18.0\n",
            "Epoch 1/1\n",
            "2376/2376 [==============================] - 0s 103us/step - loss: 2.6696e-04 - accuracy: 0.9865\n",
            "At the end of episode 1797 the total reward was : -18.0\n",
            "Epoch 1/1\n",
            "2537/2537 [==============================] - 0s 107us/step - loss: 0.0081 - accuracy: 0.9866\n",
            "At the end of episode 1798 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2334/2334 [==============================] - 0s 101us/step - loss: 0.0024 - accuracy: 0.9910\n",
            "At the end of episode 1799 the total reward was : -13.0\n",
            "Epoch 1/1\n",
            "3318/3318 [==============================] - 0s 114us/step - loss: 0.0012 - accuracy: 0.9888\n",
            "At the end of episode 1800 the total reward was : -16.0\n",
            "Epoch 1/1\n",
            "2608/2608 [==============================] - 0s 102us/step - loss: -0.0114 - accuracy: 0.9889\n",
            "At the end of episode 1801 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "3322/3322 [==============================] - 0s 107us/step - loss: -0.0216 - accuracy: 0.9840\n",
            "At the end of episode 1802 the total reward was : -16.0\n",
            "Epoch 1/1\n",
            "2446/2446 [==============================] - 0s 103us/step - loss: 0.0167 - accuracy: 0.9877\n",
            "At the end of episode 1803 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "2683/2683 [==============================] - 0s 100us/step - loss: -4.7505e-04 - accuracy: 0.9911\n",
            "At the end of episode 1804 the total reward was : -15.0\n",
            "Epoch 1/1\n",
            "3249/3249 [==============================] - 0s 105us/step - loss: -0.0020 - accuracy: 0.9877\n",
            "At the end of episode 1805 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2896/2896 [==============================] - 0s 103us/step - loss: 0.0011 - accuracy: 0.9917\n",
            "At the end of episode 1806 the total reward was : -14.0\n",
            "Epoch 1/1\n",
            "3036/3036 [==============================] - 0s 106us/step - loss: 2.8324e-04 - accuracy: 0.9891\n",
            "At the end of episode 1807 the total reward was : -16.0\n",
            "Epoch 1/1\n",
            "2855/2855 [==============================] - 0s 105us/step - loss: 5.3849e-04 - accuracy: 0.9877\n",
            "At the end of episode 1808 the total reward was : -15.0\n",
            "Epoch 1/1\n",
            "2759/2759 [==============================] - 0s 102us/step - loss: -0.0033 - accuracy: 0.9844\n",
            "At the end of episode 1809 the total reward was : -16.0\n",
            "Epoch 1/1\n",
            "2642/2642 [==============================] - 0s 103us/step - loss: -0.0044 - accuracy: 0.9886\n",
            "At the end of episode 1810 the total reward was : -12.0\n",
            "Epoch 1/1\n",
            "3383/3383 [==============================] - 0s 111us/step - loss: -0.0119 - accuracy: 0.9769\n",
            "At the end of episode 1811 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "2828/2828 [==============================] - 0s 100us/step - loss: -0.0023 - accuracy: 0.9873\n",
            "At the end of episode 1812 the total reward was : -15.0\n",
            "Epoch 1/1\n",
            "3145/3145 [==============================] - 0s 106us/step - loss: -0.0035 - accuracy: 0.9898\n",
            "At the end of episode 1813 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "2984/2984 [==============================] - 0s 102us/step - loss: 6.6656e-04 - accuracy: 0.9839\n",
            "At the end of episode 1814 the total reward was : -15.0\n",
            "Epoch 1/1\n",
            "2834/2834 [==============================] - 0s 104us/step - loss: 0.0031 - accuracy: 0.9901\n",
            "At the end of episode 1815 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "2343/2343 [==============================] - 0s 107us/step - loss: -3.5287e-04 - accuracy: 0.9927\n",
            "At the end of episode 1816 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "2972/2972 [==============================] - 0s 108us/step - loss: -0.0016 - accuracy: 0.9916\n",
            "At the end of episode 1817 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2494/2494 [==============================] - 0s 107us/step - loss: -0.0050 - accuracy: 0.9924\n",
            "At the end of episode 1818 the total reward was : -18.0\n",
            "Epoch 1/1\n",
            "2940/2940 [==============================] - 0s 101us/step - loss: 0.0020 - accuracy: 0.9840\n",
            "At the end of episode 1819 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2851/2851 [==============================] - 0s 102us/step - loss: -0.0056 - accuracy: 0.9856\n",
            "At the end of episode 1820 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "2926/2926 [==============================] - 0s 109us/step - loss: 0.0028 - accuracy: 0.9874\n",
            "At the end of episode 1821 the total reward was : -16.0\n",
            "Epoch 1/1\n",
            "2869/2869 [==============================] - 0s 106us/step - loss: -0.0094 - accuracy: 0.9881\n",
            "At the end of episode 1822 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "2408/2408 [==============================] - 0s 114us/step - loss: -0.0062 - accuracy: 0.9892\n",
            "At the end of episode 1823 the total reward was : -12.0\n",
            "Epoch 1/1\n",
            "3263/3263 [==============================] - 0s 119us/step - loss: 0.0053 - accuracy: 0.9917\n",
            "At the end of episode 1824 the total reward was : -14.0\n",
            "Epoch 1/1\n",
            "3120/3120 [==============================] - 0s 105us/step - loss: -0.0014 - accuracy: 0.9798\n",
            "At the end of episode 1825 the total reward was : -18.0\n",
            "Epoch 1/1\n",
            "2542/2542 [==============================] - 0s 106us/step - loss: -0.0068 - accuracy: 0.9894\n",
            "At the end of episode 1826 the total reward was : -14.0\n",
            "Epoch 1/1\n",
            "3295/3295 [==============================] - 0s 108us/step - loss: -0.0020 - accuracy: 0.9909\n",
            "At the end of episode 1827 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "3323/3323 [==============================] - 0s 107us/step - loss: -0.0309 - accuracy: 0.9825\n",
            "At the end of episode 1828 the total reward was : -12.0\n",
            "Epoch 1/1\n",
            "3526/3526 [==============================] - 0s 110us/step - loss: 8.4375e-04 - accuracy: 0.9858\n",
            "At the end of episode 1829 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "3373/3373 [==============================] - 0s 103us/step - loss: -0.0092 - accuracy: 0.9881\n",
            "At the end of episode 1830 the total reward was : -14.0\n",
            "Epoch 1/1\n",
            "3194/3194 [==============================] - 0s 106us/step - loss: 5.6048e-04 - accuracy: 0.9915\n",
            "At the end of episode 1831 the total reward was : -14.0\n",
            "Epoch 1/1\n",
            "3362/3362 [==============================] - 0s 107us/step - loss: -0.0014 - accuracy: 0.9863\n",
            "At the end of episode 1832 the total reward was : -16.0\n",
            "Epoch 1/1\n",
            "3685/3685 [==============================] - 0s 103us/step - loss: 0.0171 - accuracy: 0.9856\n",
            "At the end of episode 1833 the total reward was : -16.0\n",
            "Epoch 1/1\n",
            "3216/3216 [==============================] - 0s 102us/step - loss: -0.0210 - accuracy: 0.9764\n",
            "At the end of episode 1834 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2509/2509 [==============================] - 0s 101us/step - loss: -5.7345e-04 - accuracy: 0.9912\n",
            "At the end of episode 1835 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2507/2507 [==============================] - 0s 103us/step - loss: -0.0061 - accuracy: 0.9900\n",
            "At the end of episode 1836 the total reward was : -16.0\n",
            "Epoch 1/1\n",
            "2558/2558 [==============================] - 0s 106us/step - loss: 0.0049 - accuracy: 0.9902\n",
            "At the end of episode 1837 the total reward was : -18.0\n",
            "Epoch 1/1\n",
            "2804/2804 [==============================] - 0s 107us/step - loss: -7.7068e-04 - accuracy: 0.9893\n",
            "At the end of episode 1838 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "2404/2404 [==============================] - 0s 100us/step - loss: -0.0020 - accuracy: 0.9896\n",
            "At the end of episode 1839 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "3134/3134 [==============================] - 0s 101us/step - loss: 0.0016 - accuracy: 0.9927\n",
            "At the end of episode 1840 the total reward was : -16.0\n",
            "Epoch 1/1\n",
            "2884/2884 [==============================] - 0s 102us/step - loss: 0.0061 - accuracy: 0.9896\n",
            "At the end of episode 1841 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "2725/2725 [==============================] - 0s 102us/step - loss: 0.0028 - accuracy: 0.9868\n",
            "At the end of episode 1842 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2732/2732 [==============================] - 0s 106us/step - loss: 0.0102 - accuracy: 0.9883\n",
            "At the end of episode 1843 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "3226/3226 [==============================] - 0s 105us/step - loss: 8.1514e-04 - accuracy: 0.9879\n",
            "At the end of episode 1844 the total reward was : -18.0\n",
            "Epoch 1/1\n",
            "2466/2466 [==============================] - 0s 106us/step - loss: 0.0047 - accuracy: 0.9923\n",
            "At the end of episode 1845 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2667/2667 [==============================] - 0s 106us/step - loss: 6.1147e-04 - accuracy: 0.9918\n",
            "At the end of episode 1846 the total reward was : -15.0\n",
            "Epoch 1/1\n",
            "3458/3458 [==============================] - 0s 106us/step - loss: -0.0035 - accuracy: 0.9876\n",
            "At the end of episode 1847 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "3085/3085 [==============================] - 0s 101us/step - loss: -0.0056 - accuracy: 0.9861\n",
            "At the end of episode 1848 the total reward was : -13.0\n",
            "Epoch 1/1\n",
            "2999/2999 [==============================] - 0s 101us/step - loss: -0.0085 - accuracy: 0.9903\n",
            "At the end of episode 1849 the total reward was : -21.0\n",
            "Epoch 1/1\n",
            "2484/2484 [==============================] - 0s 106us/step - loss: -0.0052 - accuracy: 0.9907\n",
            "At the end of episode 1850 the total reward was : -18.0\n",
            "Epoch 1/1\n",
            "2773/2773 [==============================] - 0s 108us/step - loss: -0.0061 - accuracy: 0.9906\n",
            "At the end of episode 1851 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "3381/3381 [==============================] - 0s 116us/step - loss: 0.0022 - accuracy: 0.9920\n",
            "At the end of episode 1852 the total reward was : -16.0\n",
            "Epoch 1/1\n",
            "3179/3179 [==============================] - 0s 101us/step - loss: -0.0073 - accuracy: 0.9887\n",
            "At the end of episode 1853 the total reward was : -18.0\n",
            "Epoch 1/1\n",
            "2619/2619 [==============================] - 0s 100us/step - loss: 0.0012 - accuracy: 0.9893\n",
            "At the end of episode 1854 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "3363/3363 [==============================] - 0s 107us/step - loss: 0.0014 - accuracy: 0.9881\n",
            "At the end of episode 1855 the total reward was : -21.0\n",
            "Epoch 1/1\n",
            "2667/2667 [==============================] - 0s 108us/step - loss: -0.0047 - accuracy: 0.9880\n",
            "At the end of episode 1856 the total reward was : -18.0\n",
            "Epoch 1/1\n",
            "2445/2445 [==============================] - 0s 109us/step - loss: -0.0026 - accuracy: 0.9885\n",
            "At the end of episode 1857 the total reward was : -18.0\n",
            "Epoch 1/1\n",
            "2456/2456 [==============================] - 0s 101us/step - loss: 0.0018 - accuracy: 0.9866\n",
            "At the end of episode 1858 the total reward was : -20.0\n",
            "Epoch 1/1\n",
            "2542/2542 [==============================] - 0s 102us/step - loss: -0.0043 - accuracy: 0.9882\n",
            "At the end of episode 1859 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2650/2650 [==============================] - 0s 101us/step - loss: -0.0036 - accuracy: 0.9883\n",
            "At the end of episode 1860 the total reward was : -20.0\n",
            "Epoch 1/1\n",
            "2533/2533 [==============================] - 0s 107us/step - loss: 2.6222e-05 - accuracy: 0.9941\n",
            "At the end of episode 1861 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "2801/2801 [==============================] - 0s 101us/step - loss: 0.0113 - accuracy: 0.9896\n",
            "At the end of episode 1862 the total reward was : -18.0\n",
            "Epoch 1/1\n",
            "3351/3351 [==============================] - 0s 107us/step - loss: 0.0031 - accuracy: 0.9854\n",
            "At the end of episode 1863 the total reward was : -16.0\n",
            "Epoch 1/1\n",
            "2890/2890 [==============================] - 0s 104us/step - loss: 0.0095 - accuracy: 0.9875\n",
            "At the end of episode 1864 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2240/2240 [==============================] - 0s 104us/step - loss: -0.0119 - accuracy: 0.9879\n",
            "At the end of episode 1865 the total reward was : -20.0\n",
            "Epoch 1/1\n",
            "2526/2526 [==============================] - 0s 106us/step - loss: 9.9142e-04 - accuracy: 0.9877\n",
            "At the end of episode 1866 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "3058/3058 [==============================] - 0s 104us/step - loss: -0.0013 - accuracy: 0.9892\n",
            "At the end of episode 1867 the total reward was : -20.0\n",
            "Epoch 1/1\n",
            "2748/2748 [==============================] - 0s 106us/step - loss: 0.0058 - accuracy: 0.9862\n",
            "At the end of episode 1868 the total reward was : -16.0\n",
            "Epoch 1/1\n",
            "2872/2872 [==============================] - 0s 106us/step - loss: 6.7725e-04 - accuracy: 0.9913\n",
            "At the end of episode 1869 the total reward was : -18.0\n",
            "Epoch 1/1\n",
            "2841/2841 [==============================] - 0s 99us/step - loss: -0.0028 - accuracy: 0.9891\n",
            "At the end of episode 1870 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2463/2463 [==============================] - 0s 103us/step - loss: -0.0021 - accuracy: 0.9898\n",
            "At the end of episode 1871 the total reward was : -13.0\n",
            "Epoch 1/1\n",
            "3311/3311 [==============================] - 0s 109us/step - loss: 5.4065e-04 - accuracy: 0.9858\n",
            "At the end of episode 1872 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2152/2152 [==============================] - 0s 103us/step - loss: -0.0013 - accuracy: 0.9912\n",
            "At the end of episode 1873 the total reward was : -16.0\n",
            "Epoch 1/1\n",
            "3136/3136 [==============================] - 0s 106us/step - loss: 0.0021 - accuracy: 0.9869\n",
            "At the end of episode 1874 the total reward was : -12.0\n",
            "Epoch 1/1\n",
            "2638/2638 [==============================] - 0s 105us/step - loss: -0.0044 - accuracy: 0.9867\n",
            "At the end of episode 1875 the total reward was : -16.0\n",
            "Epoch 1/1\n",
            "2623/2623 [==============================] - 0s 106us/step - loss: -0.0052 - accuracy: 0.9897\n",
            "At the end of episode 1876 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "2191/2191 [==============================] - 0s 103us/step - loss: -0.0021 - accuracy: 0.9895\n",
            "At the end of episode 1877 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "3063/3063 [==============================] - 0s 101us/step - loss: -0.0090 - accuracy: 0.9817\n",
            "At the end of episode 1878 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "3308/3308 [==============================] - 0s 107us/step - loss: -7.6261e-04 - accuracy: 0.9876\n",
            "At the end of episode 1879 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "2417/2417 [==============================] - 0s 110us/step - loss: 0.0015 - accuracy: 0.9872\n",
            "At the end of episode 1880 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "3255/3255 [==============================] - 0s 112us/step - loss: 0.0020 - accuracy: 0.9892\n",
            "At the end of episode 1881 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "3631/3631 [==============================] - 0s 105us/step - loss: -1.7303e-04 - accuracy: 0.9909\n",
            "At the end of episode 1882 the total reward was : -15.0\n",
            "Epoch 1/1\n",
            "2828/2828 [==============================] - 0s 105us/step - loss: -0.0024 - accuracy: 0.9915\n",
            "At the end of episode 1883 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "2495/2495 [==============================] - 0s 105us/step - loss: -9.8994e-04 - accuracy: 0.9928\n",
            "At the end of episode 1884 the total reward was : -15.0\n",
            "Epoch 1/1\n",
            "3262/3262 [==============================] - 0s 102us/step - loss: 0.0059 - accuracy: 0.9899\n",
            "At the end of episode 1885 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "2576/2576 [==============================] - 0s 103us/step - loss: -0.0023 - accuracy: 0.9884\n",
            "At the end of episode 1886 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2833/2833 [==============================] - 0s 102us/step - loss: 0.0023 - accuracy: 0.9936\n",
            "At the end of episode 1887 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2940/2940 [==============================] - 0s 106us/step - loss: -2.5044e-04 - accuracy: 0.9929\n",
            "At the end of episode 1888 the total reward was : -16.0\n",
            "Epoch 1/1\n",
            "2801/2801 [==============================] - 0s 101us/step - loss: -0.0049 - accuracy: 0.9896\n",
            "At the end of episode 1889 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "2913/2913 [==============================] - 0s 108us/step - loss: -0.0035 - accuracy: 0.9873\n",
            "At the end of episode 1890 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2306/2306 [==============================] - 0s 104us/step - loss: 8.0938e-04 - accuracy: 0.9892\n",
            "At the end of episode 1891 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "3395/3395 [==============================] - 0s 107us/step - loss: -0.0079 - accuracy: 0.9867\n",
            "At the end of episode 1892 the total reward was : -18.0\n",
            "Epoch 1/1\n",
            "2279/2279 [==============================] - 0s 120us/step - loss: 0.0199 - accuracy: 0.9855\n",
            "At the end of episode 1893 the total reward was : -18.0\n",
            "Epoch 1/1\n",
            "2614/2614 [==============================] - 0s 115us/step - loss: -0.0037 - accuracy: 0.9901\n",
            "At the end of episode 1894 the total reward was : -13.0\n",
            "Epoch 1/1\n",
            "3189/3189 [==============================] - 0s 117us/step - loss: -0.0344 - accuracy: 0.9821\n",
            "At the end of episode 1895 the total reward was : -13.0\n",
            "Epoch 1/1\n",
            "3106/3106 [==============================] - 0s 102us/step - loss: -0.0111 - accuracy: 0.9894\n",
            "At the end of episode 1896 the total reward was : -16.0\n",
            "Epoch 1/1\n",
            "3598/3598 [==============================] - 0s 107us/step - loss: -0.0039 - accuracy: 0.9886\n",
            "At the end of episode 1897 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "3066/3066 [==============================] - 0s 100us/step - loss: -0.0105 - accuracy: 0.9837\n",
            "At the end of episode 1898 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "2640/2640 [==============================] - 0s 102us/step - loss: 0.0021 - accuracy: 0.9924\n",
            "At the end of episode 1899 the total reward was : -15.0\n",
            "Epoch 1/1\n",
            "2931/2931 [==============================] - 0s 103us/step - loss: -0.0032 - accuracy: 0.9925\n",
            "At the end of episode 1900 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "2787/2787 [==============================] - 0s 110us/step - loss: -0.0107 - accuracy: 0.9853\n",
            "At the end of episode 1901 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "3010/3010 [==============================] - 0s 105us/step - loss: 0.0041 - accuracy: 0.9924\n",
            "At the end of episode 1902 the total reward was : -14.0\n",
            "Epoch 1/1\n",
            "3944/3944 [==============================] - 0s 102us/step - loss: -0.0012 - accuracy: 0.9921\n",
            "At the end of episode 1903 the total reward was : -16.0\n",
            "Epoch 1/1\n",
            "2623/2623 [==============================] - 0s 104us/step - loss: -0.0219 - accuracy: 0.9874\n",
            "At the end of episode 1904 the total reward was : -16.0\n",
            "Epoch 1/1\n",
            "3312/3312 [==============================] - 0s 105us/step - loss: -0.0085 - accuracy: 0.9906\n",
            "At the end of episode 1905 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "3556/3556 [==============================] - 0s 106us/step - loss: 6.7100e-05 - accuracy: 0.9904\n",
            "At the end of episode 1906 the total reward was : -15.0\n",
            "Epoch 1/1\n",
            "3257/3257 [==============================] - 0s 104us/step - loss: 0.0119 - accuracy: 0.9846\n",
            "At the end of episode 1907 the total reward was : -12.0\n",
            "Epoch 1/1\n",
            "4271/4271 [==============================] - 0s 103us/step - loss: 0.0094 - accuracy: 0.9815\n",
            "At the end of episode 1908 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "3539/3539 [==============================] - 0s 99us/step - loss: 0.0022 - accuracy: 0.9898\n",
            "At the end of episode 1909 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "2967/2967 [==============================] - 0s 107us/step - loss: -0.0129 - accuracy: 0.9869\n",
            "At the end of episode 1910 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "3150/3150 [==============================] - 0s 101us/step - loss: 0.0113 - accuracy: 0.9870\n",
            "At the end of episode 1911 the total reward was : -12.0\n",
            "Epoch 1/1\n",
            "3302/3302 [==============================] - 0s 109us/step - loss: -0.0033 - accuracy: 0.9903\n",
            "At the end of episode 1912 the total reward was : -21.0\n",
            "Epoch 1/1\n",
            "2489/2489 [==============================] - 0s 101us/step - loss: 0.0052 - accuracy: 0.9928\n",
            "At the end of episode 1913 the total reward was : -13.0\n",
            "Epoch 1/1\n",
            "3415/3415 [==============================] - 0s 115us/step - loss: -0.0027 - accuracy: 0.9883\n",
            "At the end of episode 1914 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "4017/4017 [==============================] - 0s 100us/step - loss: -0.0138 - accuracy: 0.9871\n",
            "At the end of episode 1915 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "3972/3972 [==============================] - 0s 107us/step - loss: 0.0034 - accuracy: 0.9904\n",
            "At the end of episode 1916 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "3061/3061 [==============================] - 0s 102us/step - loss: 8.1004e-04 - accuracy: 0.9909\n",
            "At the end of episode 1917 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "3049/3049 [==============================] - 0s 101us/step - loss: -6.0119e-04 - accuracy: 0.9888\n",
            "At the end of episode 1918 the total reward was : -15.0\n",
            "Epoch 1/1\n",
            "2434/2434 [==============================] - 0s 109us/step - loss: -0.0039 - accuracy: 0.9893\n",
            "At the end of episode 1919 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "2992/2992 [==============================] - 0s 102us/step - loss: 1.9460e-04 - accuracy: 0.9890\n",
            "At the end of episode 1920 the total reward was : -18.0\n",
            "Epoch 1/1\n",
            "3116/3116 [==============================] - 0s 111us/step - loss: -0.0041 - accuracy: 0.9888\n",
            "At the end of episode 1921 the total reward was : -15.0\n",
            "Epoch 1/1\n",
            "2930/2930 [==============================] - 0s 100us/step - loss: 0.0099 - accuracy: 0.9809\n",
            "At the end of episode 1922 the total reward was : -15.0\n",
            "Epoch 1/1\n",
            "3003/3003 [==============================] - 0s 103us/step - loss: -0.0017 - accuracy: 0.9903\n",
            "At the end of episode 1923 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2420/2420 [==============================] - 0s 101us/step - loss: 0.0029 - accuracy: 0.9893\n",
            "At the end of episode 1924 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "4044/4044 [==============================] - 0s 105us/step - loss: -4.5377e-04 - accuracy: 0.9931\n",
            "At the end of episode 1925 the total reward was : -13.0\n",
            "Epoch 1/1\n",
            "3234/3234 [==============================] - 0s 105us/step - loss: -3.2467e-04 - accuracy: 0.9873\n",
            "At the end of episode 1926 the total reward was : -15.0\n",
            "Epoch 1/1\n",
            "3660/3660 [==============================] - 0s 104us/step - loss: 0.0028 - accuracy: 0.9915\n",
            "At the end of episode 1927 the total reward was : -20.0\n",
            "Epoch 1/1\n",
            "2630/2630 [==============================] - 0s 105us/step - loss: 0.0010 - accuracy: 0.9825\n",
            "At the end of episode 1928 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "3058/3058 [==============================] - 0s 101us/step - loss: 0.0112 - accuracy: 0.9928\n",
            "At the end of episode 1929 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "3157/3157 [==============================] - 0s 103us/step - loss: -0.0023 - accuracy: 0.9892\n",
            "At the end of episode 1930 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2673/2673 [==============================] - 0s 102us/step - loss: 5.8612e-04 - accuracy: 0.9925\n",
            "At the end of episode 1931 the total reward was : -15.0\n",
            "Epoch 1/1\n",
            "2439/2439 [==============================] - 0s 115us/step - loss: 0.0035 - accuracy: 0.9914\n",
            "At the end of episode 1932 the total reward was : -15.0\n",
            "Epoch 1/1\n",
            "2752/2752 [==============================] - 0s 105us/step - loss: 0.0068 - accuracy: 0.9873\n",
            "At the end of episode 1933 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "2829/2829 [==============================] - 0s 103us/step - loss: -0.0040 - accuracy: 0.9876\n",
            "At the end of episode 1934 the total reward was : -12.0\n",
            "Epoch 1/1\n",
            "3806/3806 [==============================] - 0s 110us/step - loss: 0.0071 - accuracy: 0.9877\n",
            "At the end of episode 1935 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "2447/2447 [==============================] - 0s 101us/step - loss: -0.0035 - accuracy: 0.9902\n",
            "At the end of episode 1936 the total reward was : -15.0\n",
            "Epoch 1/1\n",
            "3066/3066 [==============================] - 0s 105us/step - loss: -0.0062 - accuracy: 0.9902\n",
            "At the end of episode 1937 the total reward was : -15.0\n",
            "Epoch 1/1\n",
            "3163/3163 [==============================] - 0s 111us/step - loss: 0.0011 - accuracy: 0.9924\n",
            "At the end of episode 1938 the total reward was : -16.0\n",
            "Epoch 1/1\n",
            "3528/3528 [==============================] - 0s 112us/step - loss: -7.5552e-04 - accuracy: 0.9901\n",
            "At the end of episode 1939 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2636/2636 [==============================] - 0s 105us/step - loss: -0.0075 - accuracy: 0.9844\n",
            "At the end of episode 1940 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "2936/2936 [==============================] - 0s 101us/step - loss: 0.0027 - accuracy: 0.9843\n",
            "At the end of episode 1941 the total reward was : -20.0\n",
            "Epoch 1/1\n",
            "2687/2687 [==============================] - 0s 101us/step - loss: 0.0065 - accuracy: 0.9873\n",
            "At the end of episode 1942 the total reward was : -15.0\n",
            "Epoch 1/1\n",
            "3881/3881 [==============================] - 0s 104us/step - loss: -0.0019 - accuracy: 0.9892\n",
            "At the end of episode 1943 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "3304/3304 [==============================] - 0s 102us/step - loss: -8.6680e-04 - accuracy: 0.9927\n",
            "At the end of episode 1944 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2799/2799 [==============================] - 0s 105us/step - loss: 0.0080 - accuracy: 0.9886\n",
            "At the end of episode 1945 the total reward was : -18.0\n",
            "Epoch 1/1\n",
            "2700/2700 [==============================] - 0s 104us/step - loss: 0.0013 - accuracy: 0.9889\n",
            "At the end of episode 1946 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2882/2882 [==============================] - 0s 103us/step - loss: -0.0012 - accuracy: 0.9927\n",
            "At the end of episode 1947 the total reward was : -15.0\n",
            "Epoch 1/1\n",
            "3173/3173 [==============================] - 0s 117us/step - loss: 0.0024 - accuracy: 0.9877\n",
            "At the end of episode 1948 the total reward was : -21.0\n",
            "Epoch 1/1\n",
            "2641/2641 [==============================] - 0s 108us/step - loss: -0.0012 - accuracy: 0.9909\n",
            "At the end of episode 1949 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "3479/3479 [==============================] - 0s 114us/step - loss: 0.0026 - accuracy: 0.9833\n",
            "At the end of episode 1950 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2707/2707 [==============================] - 0s 102us/step - loss: -0.0029 - accuracy: 0.9922\n",
            "At the end of episode 1951 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "3415/3415 [==============================] - 0s 104us/step - loss: -0.0030 - accuracy: 0.9912\n",
            "At the end of episode 1952 the total reward was : -20.0\n",
            "Epoch 1/1\n",
            "2703/2703 [==============================] - 0s 107us/step - loss: 0.0031 - accuracy: 0.9863\n",
            "At the end of episode 1953 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "3400/3400 [==============================] - 0s 109us/step - loss: -1.5879e-04 - accuracy: 0.9897\n",
            "At the end of episode 1954 the total reward was : -16.0\n",
            "Epoch 1/1\n",
            "3763/3763 [==============================] - 0s 108us/step - loss: 4.5029e-04 - accuracy: 0.9910\n",
            "At the end of episode 1955 the total reward was : -14.0\n",
            "Epoch 1/1\n",
            "2966/2966 [==============================] - 0s 101us/step - loss: 0.0018 - accuracy: 0.9892\n",
            "At the end of episode 1956 the total reward was : -20.0\n",
            "Epoch 1/1\n",
            "2837/2837 [==============================] - 0s 102us/step - loss: 0.0025 - accuracy: 0.9880\n",
            "At the end of episode 1957 the total reward was : -15.0\n",
            "Epoch 1/1\n",
            "3076/3076 [==============================] - 0s 107us/step - loss: -0.0088 - accuracy: 0.9834\n",
            "At the end of episode 1958 the total reward was : -15.0\n",
            "Epoch 1/1\n",
            "3878/3878 [==============================] - 0s 112us/step - loss: -0.0052 - accuracy: 0.9866\n",
            "At the end of episode 1959 the total reward was : -12.0\n",
            "Epoch 1/1\n",
            "3208/3208 [==============================] - 0s 111us/step - loss: -5.9960e-04 - accuracy: 0.9888\n",
            "At the end of episode 1960 the total reward was : -18.0\n",
            "Epoch 1/1\n",
            "2877/2877 [==============================] - 0s 103us/step - loss: -0.0038 - accuracy: 0.9871\n",
            "At the end of episode 1961 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "3224/3224 [==============================] - 0s 103us/step - loss: 0.0064 - accuracy: 0.9882\n",
            "At the end of episode 1962 the total reward was : -13.0\n",
            "Epoch 1/1\n",
            "3440/3440 [==============================] - 0s 104us/step - loss: -0.0071 - accuracy: 0.9875\n",
            "At the end of episode 1963 the total reward was : -21.0\n",
            "Epoch 1/1\n",
            "3149/3149 [==============================] - 0s 105us/step - loss: 0.0052 - accuracy: 0.9825\n",
            "At the end of episode 1964 the total reward was : -21.0\n",
            "Epoch 1/1\n",
            "2426/2426 [==============================] - 0s 103us/step - loss: 0.0181 - accuracy: 0.9847\n",
            "At the end of episode 1965 the total reward was : -16.0\n",
            "Epoch 1/1\n",
            "2896/2896 [==============================] - 0s 110us/step - loss: 0.0015 - accuracy: 0.9820\n",
            "At the end of episode 1966 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "3559/3559 [==============================] - 0s 106us/step - loss: 0.0121 - accuracy: 0.9865\n",
            "At the end of episode 1967 the total reward was : -20.0\n",
            "Epoch 1/1\n",
            "2787/2787 [==============================] - 0s 106us/step - loss: -6.1582e-04 - accuracy: 0.9928\n",
            "At the end of episode 1968 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "3302/3302 [==============================] - 0s 104us/step - loss: 0.0031 - accuracy: 0.9897\n",
            "At the end of episode 1969 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "3156/3156 [==============================] - 0s 103us/step - loss: 7.7132e-05 - accuracy: 0.9880\n",
            "At the end of episode 1970 the total reward was : -21.0\n",
            "Epoch 1/1\n",
            "3287/3287 [==============================] - 0s 115us/step - loss: -2.5620e-04 - accuracy: 0.9869\n",
            "At the end of episode 1971 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2484/2484 [==============================] - 0s 108us/step - loss: -0.0053 - accuracy: 0.9887\n",
            "At the end of episode 1972 the total reward was : -18.0\n",
            "Epoch 1/1\n",
            "2829/2829 [==============================] - 0s 106us/step - loss: -0.0055 - accuracy: 0.9862\n",
            "At the end of episode 1973 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "2766/2766 [==============================] - 0s 104us/step - loss: 0.0032 - accuracy: 0.9895\n",
            "At the end of episode 1974 the total reward was : -20.0\n",
            "Epoch 1/1\n",
            "2788/2788 [==============================] - 0s 103us/step - loss: 0.0125 - accuracy: 0.9892\n",
            "At the end of episode 1975 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "2424/2424 [==============================] - 0s 101us/step - loss: 0.0062 - accuracy: 0.9897\n",
            "At the end of episode 1976 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2816/2816 [==============================] - 0s 106us/step - loss: -0.0040 - accuracy: 0.9904\n",
            "At the end of episode 1977 the total reward was : -20.0\n",
            "Epoch 1/1\n",
            "2614/2614 [==============================] - 0s 103us/step - loss: 1.1203e-04 - accuracy: 0.9855\n",
            "At the end of episode 1978 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "3010/3010 [==============================] - 0s 101us/step - loss: -6.9320e-04 - accuracy: 0.9890\n",
            "At the end of episode 1979 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2734/2734 [==============================] - 0s 103us/step - loss: 0.0022 - accuracy: 0.9916\n",
            "At the end of episode 1980 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2732/2732 [==============================] - 0s 105us/step - loss: 0.0030 - accuracy: 0.9919\n",
            "At the end of episode 1981 the total reward was : -16.0\n",
            "Epoch 1/1\n",
            "2696/2696 [==============================] - 0s 102us/step - loss: 0.0014 - accuracy: 0.9941\n",
            "At the end of episode 1982 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "2733/2733 [==============================] - 0s 102us/step - loss: -0.0020 - accuracy: 0.9920\n",
            "At the end of episode 1983 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "2833/2833 [==============================] - 0s 107us/step - loss: -0.0042 - accuracy: 0.9898\n",
            "At the end of episode 1984 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "2252/2252 [==============================] - 0s 111us/step - loss: 0.0070 - accuracy: 0.9889\n",
            "At the end of episode 1985 the total reward was : -21.0\n",
            "Epoch 1/1\n",
            "2244/2244 [==============================] - 0s 103us/step - loss: -8.2034e-04 - accuracy: 0.9915\n",
            "At the end of episode 1986 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "2649/2649 [==============================] - 0s 107us/step - loss: 3.0994e-04 - accuracy: 0.9943\n",
            "At the end of episode 1987 the total reward was : -21.0\n",
            "Epoch 1/1\n",
            "2077/2077 [==============================] - 0s 105us/step - loss: 0.0169 - accuracy: 0.9904\n",
            "At the end of episode 1988 the total reward was : -18.0\n",
            "Epoch 1/1\n",
            "2622/2622 [==============================] - 0s 110us/step - loss: -0.0029 - accuracy: 0.9901\n",
            "At the end of episode 1989 the total reward was : -21.0\n",
            "Epoch 1/1\n",
            "2910/2910 [==============================] - 0s 108us/step - loss: 5.9186e-05 - accuracy: 0.9883\n",
            "At the end of episode 1990 the total reward was : -16.0\n",
            "Epoch 1/1\n",
            "2742/2742 [==============================] - 0s 101us/step - loss: -0.0068 - accuracy: 0.9923\n",
            "At the end of episode 1991 the total reward was : -20.0\n",
            "Epoch 1/1\n",
            "3253/3253 [==============================] - 0s 108us/step - loss: -0.0023 - accuracy: 0.9865\n",
            "At the end of episode 1992 the total reward was : -21.0\n",
            "Epoch 1/1\n",
            "2639/2639 [==============================] - 0s 102us/step - loss: 0.0064 - accuracy: 0.9864\n",
            "At the end of episode 1993 the total reward was : -16.0\n",
            "Epoch 1/1\n",
            "2893/2893 [==============================] - 0s 104us/step - loss: -0.0026 - accuracy: 0.9941\n",
            "At the end of episode 1994 the total reward was : -16.0\n",
            "Epoch 1/1\n",
            "3433/3433 [==============================] - 0s 109us/step - loss: 0.0029 - accuracy: 0.9913\n",
            "At the end of episode 1995 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "3183/3183 [==============================] - 0s 102us/step - loss: -0.0044 - accuracy: 0.9821\n",
            "At the end of episode 1996 the total reward was : -16.0\n",
            "Epoch 1/1\n",
            "3002/3002 [==============================] - 0s 104us/step - loss: 0.0024 - accuracy: 0.9900\n",
            "At the end of episode 1997 the total reward was : -18.0\n",
            "Epoch 1/1\n",
            "3294/3294 [==============================] - 0s 107us/step - loss: -0.0048 - accuracy: 0.9894\n",
            "At the end of episode 1998 the total reward was : -14.0\n",
            "Epoch 1/1\n",
            "3363/3363 [==============================] - 0s 108us/step - loss: 0.0065 - accuracy: 0.9893\n",
            "At the end of episode 1999 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2669/2669 [==============================] - 0s 101us/step - loss: -0.0022 - accuracy: 0.9910\n",
            "At the end of episode 2000 the total reward was : -15.0\n",
            "Epoch 1/1\n",
            "4121/4121 [==============================] - 0s 99us/step - loss: 1.6814e-04 - accuracy: 0.9859\n",
            "At the end of episode 2001 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "3734/3734 [==============================] - 0s 106us/step - loss: -0.0038 - accuracy: 0.9898\n",
            "At the end of episode 2002 the total reward was : -13.0\n",
            "Epoch 1/1\n",
            "4136/4136 [==============================] - 0s 103us/step - loss: 6.3808e-04 - accuracy: 0.9872\n",
            "At the end of episode 2003 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "3207/3207 [==============================] - 0s 106us/step - loss: 5.2442e-04 - accuracy: 0.9903\n",
            "At the end of episode 2004 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "4018/4018 [==============================] - 0s 107us/step - loss: -0.0121 - accuracy: 0.9856\n",
            "At the end of episode 2005 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "2456/2456 [==============================] - 0s 102us/step - loss: -0.0041 - accuracy: 0.9935\n",
            "At the end of episode 2006 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "3459/3459 [==============================] - 0s 108us/step - loss: 0.0025 - accuracy: 0.9870\n",
            "At the end of episode 2007 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "2998/2998 [==============================] - 0s 101us/step - loss: 0.0067 - accuracy: 0.9840\n",
            "At the end of episode 2008 the total reward was : -21.0\n",
            "Epoch 1/1\n",
            "2804/2804 [==============================] - 0s 105us/step - loss: -0.0091 - accuracy: 0.9875\n",
            "At the end of episode 2009 the total reward was : -16.0\n",
            "Epoch 1/1\n",
            "3674/3674 [==============================] - 0s 106us/step - loss: -0.0020 - accuracy: 0.9842\n",
            "At the end of episode 2010 the total reward was : -21.0\n",
            "Epoch 1/1\n",
            "2471/2471 [==============================] - 0s 103us/step - loss: -0.0018 - accuracy: 0.9915\n",
            "At the end of episode 2011 the total reward was : -18.0\n",
            "Epoch 1/1\n",
            "2855/2855 [==============================] - 0s 103us/step - loss: 9.5928e-05 - accuracy: 0.9933\n",
            "At the end of episode 2012 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "2906/2906 [==============================] - 0s 107us/step - loss: -8.8455e-04 - accuracy: 0.9945\n",
            "At the end of episode 2013 the total reward was : -18.0\n",
            "Epoch 1/1\n",
            "2712/2712 [==============================] - 0s 104us/step - loss: -0.0023 - accuracy: 0.9912\n",
            "At the end of episode 2014 the total reward was : -21.0\n",
            "Epoch 1/1\n",
            "2648/2648 [==============================] - 0s 103us/step - loss: 0.0037 - accuracy: 0.9940\n",
            "At the end of episode 2015 the total reward was : -15.0\n",
            "Epoch 1/1\n",
            "3236/3236 [==============================] - 0s 115us/step - loss: 1.1826e-04 - accuracy: 0.9873\n",
            "At the end of episode 2016 the total reward was : -18.0\n",
            "Epoch 1/1\n",
            "4062/4062 [==============================] - 0s 108us/step - loss: 5.2561e-04 - accuracy: 0.9911\n",
            "At the end of episode 2017 the total reward was : -20.0\n",
            "Epoch 1/1\n",
            "2540/2540 [==============================] - 0s 101us/step - loss: 0.0165 - accuracy: 0.9831\n",
            "At the end of episode 2018 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "2939/2939 [==============================] - 0s 108us/step - loss: 0.0052 - accuracy: 0.9881\n",
            "At the end of episode 2019 the total reward was : -16.0\n",
            "Epoch 1/1\n",
            "3285/3285 [==============================] - 0s 111us/step - loss: -8.1984e-04 - accuracy: 0.9903\n",
            "At the end of episode 2020 the total reward was : -14.0\n",
            "Epoch 1/1\n",
            "3678/3678 [==============================] - 0s 102us/step - loss: 5.3057e-04 - accuracy: 0.9913\n",
            "At the end of episode 2021 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2828/2828 [==============================] - 0s 105us/step - loss: -0.0056 - accuracy: 0.9894\n",
            "At the end of episode 2022 the total reward was : -13.0\n",
            "Epoch 1/1\n",
            "3404/3404 [==============================] - 0s 105us/step - loss: 0.0084 - accuracy: 0.9868\n",
            "At the end of episode 2023 the total reward was : -16.0\n",
            "Epoch 1/1\n",
            "3224/3224 [==============================] - 0s 102us/step - loss: 0.0110 - accuracy: 0.9879\n",
            "At the end of episode 2024 the total reward was : -13.0\n",
            "Epoch 1/1\n",
            "3975/3975 [==============================] - 0s 102us/step - loss: -6.6635e-04 - accuracy: 0.9919\n",
            "At the end of episode 2025 the total reward was : -16.0\n",
            "Epoch 1/1\n",
            "3132/3132 [==============================] - 0s 108us/step - loss: 0.0081 - accuracy: 0.9853\n",
            "At the end of episode 2026 the total reward was : -21.0\n",
            "Epoch 1/1\n",
            "1900/1900 [==============================] - 0s 112us/step - loss: 0.0213 - accuracy: 0.9868\n",
            "At the end of episode 2027 the total reward was : -18.0\n",
            "Epoch 1/1\n",
            "2540/2540 [==============================] - 0s 113us/step - loss: 0.0028 - accuracy: 0.9909\n",
            "At the end of episode 2028 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "2497/2497 [==============================] - 0s 105us/step - loss: -1.2790e-05 - accuracy: 0.9976\n",
            "At the end of episode 2029 the total reward was : -20.0\n",
            "Epoch 1/1\n",
            "2943/2943 [==============================] - 0s 102us/step - loss: -0.0035 - accuracy: 0.9908\n",
            "At the end of episode 2030 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "2899/2899 [==============================] - 0s 106us/step - loss: 0.0081 - accuracy: 0.9914\n",
            "At the end of episode 2031 the total reward was : -14.0\n",
            "Epoch 1/1\n",
            "2967/2967 [==============================] - 0s 103us/step - loss: 0.0045 - accuracy: 0.9869\n",
            "At the end of episode 2032 the total reward was : -18.0\n",
            "Epoch 1/1\n",
            "3368/3368 [==============================] - 0s 115us/step - loss: 0.0049 - accuracy: 0.9893\n",
            "At the end of episode 2033 the total reward was : -12.0\n",
            "Epoch 1/1\n",
            "3394/3394 [==============================] - 0s 112us/step - loss: 0.0074 - accuracy: 0.9856\n",
            "At the end of episode 2034 the total reward was : -20.0\n",
            "Epoch 1/1\n",
            "2422/2422 [==============================] - 0s 103us/step - loss: 0.0094 - accuracy: 0.9889\n",
            "At the end of episode 2035 the total reward was : -20.0\n",
            "Epoch 1/1\n",
            "2522/2522 [==============================] - 0s 101us/step - loss: 0.0014 - accuracy: 0.9897\n",
            "At the end of episode 2036 the total reward was : -20.0\n",
            "Epoch 1/1\n",
            "2053/2053 [==============================] - 0s 102us/step - loss: -0.0025 - accuracy: 0.9912\n",
            "At the end of episode 2037 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "3464/3464 [==============================] - 0s 110us/step - loss: -0.0013 - accuracy: 0.9934\n",
            "At the end of episode 2038 the total reward was : -21.0\n",
            "Epoch 1/1\n",
            "3215/3215 [==============================] - 0s 102us/step - loss: 9.2786e-04 - accuracy: 0.9894\n",
            "At the end of episode 2039 the total reward was : -13.0\n",
            "Epoch 1/1\n",
            "3593/3593 [==============================] - 0s 108us/step - loss: -3.9805e-04 - accuracy: 0.9883\n",
            "At the end of episode 2040 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "2675/2675 [==============================] - 0s 102us/step - loss: 0.0013 - accuracy: 0.9907\n",
            "At the end of episode 2041 the total reward was : -20.0\n",
            "Epoch 1/1\n",
            "2214/2214 [==============================] - 0s 105us/step - loss: 0.0017 - accuracy: 0.9919\n",
            "At the end of episode 2042 the total reward was : -20.0\n",
            "Epoch 1/1\n",
            "2557/2557 [==============================] - 0s 108us/step - loss: -9.9982e-04 - accuracy: 0.9890\n",
            "At the end of episode 2043 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "3228/3228 [==============================] - 0s 103us/step - loss: -0.0042 - accuracy: 0.9910\n",
            "At the end of episode 2044 the total reward was : -15.0\n",
            "Epoch 1/1\n",
            "2993/2993 [==============================] - 0s 104us/step - loss: -0.0026 - accuracy: 0.9937\n",
            "At the end of episode 2045 the total reward was : -14.0\n",
            "Epoch 1/1\n",
            "3563/3563 [==============================] - 0s 109us/step - loss: -0.0052 - accuracy: 0.9905\n",
            "At the end of episode 2046 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2990/2990 [==============================] - 0s 108us/step - loss: 0.0030 - accuracy: 0.9846\n",
            "At the end of episode 2047 the total reward was : -18.0\n",
            "Epoch 1/1\n",
            "2772/2772 [==============================] - 0s 101us/step - loss: 0.0032 - accuracy: 0.9906\n",
            "At the end of episode 2048 the total reward was : -16.0\n",
            "Epoch 1/1\n",
            "3027/3027 [==============================] - 0s 101us/step - loss: 0.0029 - accuracy: 0.9911\n",
            "At the end of episode 2049 the total reward was : -16.0\n",
            "Epoch 1/1\n",
            "2638/2638 [==============================] - 0s 101us/step - loss: 0.0044 - accuracy: 0.9894\n",
            "At the end of episode 2050 the total reward was : -15.0\n",
            "Epoch 1/1\n",
            "3021/3021 [==============================] - 0s 106us/step - loss: 0.0022 - accuracy: 0.9911\n",
            "At the end of episode 2051 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2736/2736 [==============================] - 0s 103us/step - loss: -0.0018 - accuracy: 0.9879\n",
            "At the end of episode 2052 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "3246/3246 [==============================] - 0s 105us/step - loss: -8.1703e-04 - accuracy: 0.9920\n",
            "At the end of episode 2053 the total reward was : -20.0\n",
            "Epoch 1/1\n",
            "3180/3180 [==============================] - 0s 106us/step - loss: 0.0064 - accuracy: 0.9931\n",
            "At the end of episode 2054 the total reward was : -18.0\n",
            "Epoch 1/1\n",
            "2053/2053 [==============================] - 0s 106us/step - loss: -7.9493e-04 - accuracy: 0.9873\n",
            "At the end of episode 2055 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "2400/2593 [==========================>...] - ETA: 0s - loss: -8.8157e-04 - accuracy: 0.9933At the end of episode 2056 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2742/2742 [==============================] - 0s 109us/step - loss: -1.3341e-04 - accuracy: 0.9931\n",
            "At the end of episode 2057 the total reward was : -18.0\n",
            "Epoch 1/1\n",
            "2450/2450 [==============================] - 0s 103us/step - loss: 1.6010e-04 - accuracy: 0.9878\n",
            "At the end of episode 2058 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2579/2579 [==============================] - 0s 102us/step - loss: -0.0038 - accuracy: 0.9895\n",
            "At the end of episode 2059 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "2685/2685 [==============================] - 0s 101us/step - loss: 0.0015 - accuracy: 0.9922\n",
            "At the end of episode 2060 the total reward was : -13.0\n",
            "Epoch 1/1\n",
            "3071/3071 [==============================] - 0s 102us/step - loss: 9.5369e-04 - accuracy: 0.9866\n",
            "At the end of episode 2061 the total reward was : -14.0\n",
            "Epoch 1/1\n",
            "2648/2648 [==============================] - 0s 107us/step - loss: 3.5649e-04 - accuracy: 0.9932\n",
            "At the end of episode 2062 the total reward was : -15.0\n",
            "Epoch 1/1\n",
            "2840/2840 [==============================] - 0s 101us/step - loss: -5.1213e-04 - accuracy: 0.9905\n",
            "At the end of episode 2063 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2443/2443 [==============================] - 0s 106us/step - loss: -9.7704e-04 - accuracy: 0.9877\n",
            "At the end of episode 2064 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2334/2334 [==============================] - 0s 109us/step - loss: -0.0048 - accuracy: 0.9863\n",
            "At the end of episode 2065 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2751/2751 [==============================] - 0s 101us/step - loss: -0.0144 - accuracy: 0.9876\n",
            "At the end of episode 2066 the total reward was : -13.0\n",
            "Epoch 1/1\n",
            "3748/3748 [==============================] - 0s 109us/step - loss: 0.0138 - accuracy: 0.9837\n",
            "At the end of episode 2067 the total reward was : -18.0\n",
            "Epoch 1/1\n",
            "2698/2698 [==============================] - 0s 105us/step - loss: 0.0182 - accuracy: 0.9874\n",
            "At the end of episode 2068 the total reward was : -20.0\n",
            "Epoch 1/1\n",
            "1726/1726 [==============================] - 0s 102us/step - loss: -9.6725e-04 - accuracy: 0.9925\n",
            "At the end of episode 2069 the total reward was : -18.0\n",
            "Epoch 1/1\n",
            "2446/2446 [==============================] - 0s 101us/step - loss: -0.0067 - accuracy: 0.9898\n",
            "At the end of episode 2070 the total reward was : -18.0\n",
            "Epoch 1/1\n",
            "1972/1972 [==============================] - 0s 106us/step - loss: 0.0015 - accuracy: 0.9873\n",
            "At the end of episode 2071 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "2155/2155 [==============================] - 0s 105us/step - loss: 0.0037 - accuracy: 0.9926\n",
            "At the end of episode 2072 the total reward was : -18.0\n",
            "Epoch 1/1\n",
            "2135/2135 [==============================] - 0s 106us/step - loss: -0.0034 - accuracy: 0.9902\n",
            "At the end of episode 2073 the total reward was : -18.0\n",
            "Epoch 1/1\n",
            "2446/2446 [==============================] - 0s 104us/step - loss: 0.0060 - accuracy: 0.9926\n",
            "At the end of episode 2074 the total reward was : -20.0\n",
            "Epoch 1/1\n",
            "2939/2939 [==============================] - 0s 103us/step - loss: 4.7001e-04 - accuracy: 0.9850\n",
            "At the end of episode 2075 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "3095/3095 [==============================] - 0s 110us/step - loss: 1.4115e-04 - accuracy: 0.9929\n",
            "At the end of episode 2076 the total reward was : -15.0\n",
            "Epoch 1/1\n",
            "3261/3261 [==============================] - 0s 108us/step - loss: -0.0052 - accuracy: 0.9929\n",
            "At the end of episode 2077 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2255/2255 [==============================] - 0s 105us/step - loss: -0.0039 - accuracy: 0.9876\n",
            "At the end of episode 2078 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2879/2879 [==============================] - 0s 103us/step - loss: 0.0034 - accuracy: 0.9899\n",
            "At the end of episode 2079 the total reward was : -15.0\n",
            "Epoch 1/1\n",
            "2680/2680 [==============================] - 0s 105us/step - loss: -0.0048 - accuracy: 0.9896\n",
            "At the end of episode 2080 the total reward was : -20.0\n",
            "Epoch 1/1\n",
            "2219/2219 [==============================] - 0s 103us/step - loss: 4.8466e-04 - accuracy: 0.9874\n",
            "At the end of episode 2081 the total reward was : -16.0\n",
            "Epoch 1/1\n",
            "2331/2331 [==============================] - 0s 102us/step - loss: -9.9622e-04 - accuracy: 0.9914\n",
            "At the end of episode 2082 the total reward was : -18.0\n",
            "Epoch 1/1\n",
            "2557/2557 [==============================] - 0s 105us/step - loss: 7.9817e-04 - accuracy: 0.9910\n",
            "At the end of episode 2083 the total reward was : -16.0\n",
            "Epoch 1/1\n",
            "2778/2778 [==============================] - 0s 105us/step - loss: -0.0089 - accuracy: 0.9838\n",
            "At the end of episode 2084 the total reward was : -18.0\n",
            "Epoch 1/1\n",
            "2619/2619 [==============================] - 0s 104us/step - loss: -0.0013 - accuracy: 0.9927\n",
            "At the end of episode 2085 the total reward was : -18.0\n",
            "Epoch 1/1\n",
            "2622/2622 [==============================] - 0s 105us/step - loss: 0.0030 - accuracy: 0.9897\n",
            "At the end of episode 2086 the total reward was : -16.0\n",
            "Epoch 1/1\n",
            "3599/3599 [==============================] - 0s 111us/step - loss: 0.0021 - accuracy: 0.9875\n",
            "At the end of episode 2087 the total reward was : -16.0\n",
            "Epoch 1/1\n",
            "2628/2628 [==============================] - 0s 111us/step - loss: 0.0065 - accuracy: 0.9890\n",
            "At the end of episode 2088 the total reward was : -18.0\n",
            "Epoch 1/1\n",
            "2879/2879 [==============================] - 0s 100us/step - loss: 0.0135 - accuracy: 0.9840\n",
            "At the end of episode 2089 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2578/2578 [==============================] - 0s 104us/step - loss: -0.0133 - accuracy: 0.9903\n",
            "At the end of episode 2090 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "2963/2963 [==============================] - 0s 104us/step - loss: 0.0044 - accuracy: 0.9916\n",
            "At the end of episode 2091 the total reward was : -21.0\n",
            "Epoch 1/1\n",
            "2721/2721 [==============================] - 0s 102us/step - loss: 0.0138 - accuracy: 0.9868\n",
            "At the end of episode 2092 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "3151/3151 [==============================] - 0s 105us/step - loss: -0.0025 - accuracy: 0.9905\n",
            "At the end of episode 2093 the total reward was : -21.0\n",
            "Epoch 1/1\n",
            "2390/2390 [==============================] - 0s 102us/step - loss: 0.0077 - accuracy: 0.9904\n",
            "At the end of episode 2094 the total reward was : -18.0\n",
            "Epoch 1/1\n",
            "2932/2932 [==============================] - 0s 109us/step - loss: 0.0140 - accuracy: 0.9870\n",
            "At the end of episode 2095 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "2976/2976 [==============================] - 0s 101us/step - loss: -0.0144 - accuracy: 0.9825\n",
            "At the end of episode 2096 the total reward was : -12.0\n",
            "Epoch 1/1\n",
            "3064/3064 [==============================] - 0s 108us/step - loss: -0.0033 - accuracy: 0.9931\n",
            "At the end of episode 2097 the total reward was : -18.0\n",
            "Epoch 1/1\n",
            "3366/3366 [==============================] - 0s 115us/step - loss: 0.0044 - accuracy: 0.9869\n",
            "At the end of episode 2098 the total reward was : -15.0\n",
            "Epoch 1/1\n",
            "3315/3315 [==============================] - 0s 109us/step - loss: 9.9073e-05 - accuracy: 0.9900\n",
            "At the end of episode 2099 the total reward was : -14.0\n",
            "Epoch 1/1\n",
            "2720/2720 [==============================] - 0s 108us/step - loss: -9.6292e-04 - accuracy: 0.9901\n",
            "At the end of episode 2100 the total reward was : -18.0\n",
            "Epoch 1/1\n",
            "3098/3098 [==============================] - 0s 112us/step - loss: 2.1931e-04 - accuracy: 0.9919\n",
            "At the end of episode 2101 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "2985/2985 [==============================] - 0s 109us/step - loss: -0.0016 - accuracy: 0.9903\n",
            "At the end of episode 2102 the total reward was : -15.0\n",
            "Epoch 1/1\n",
            "2668/2668 [==============================] - 0s 103us/step - loss: 0.0170 - accuracy: 0.9839\n",
            "At the end of episode 2103 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "2599/2599 [==============================] - 0s 102us/step - loss: 0.0019 - accuracy: 0.9896\n",
            "At the end of episode 2104 the total reward was : -20.0\n",
            "Epoch 1/1\n",
            "2463/2463 [==============================] - 0s 108us/step - loss: -0.0016 - accuracy: 0.9935\n",
            "At the end of episode 2105 the total reward was : -18.0\n",
            "Epoch 1/1\n",
            "2452/2452 [==============================] - 0s 108us/step - loss: -0.0012 - accuracy: 0.9890\n",
            "At the end of episode 2106 the total reward was : -14.0\n",
            "Epoch 1/1\n",
            "3197/3197 [==============================] - 0s 107us/step - loss: -0.0101 - accuracy: 0.9903\n",
            "At the end of episode 2107 the total reward was : -16.0\n",
            "Epoch 1/1\n",
            "2406/2406 [==============================] - 0s 104us/step - loss: -8.8009e-04 - accuracy: 0.9946\n",
            "At the end of episode 2108 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2673/2673 [==============================] - 0s 106us/step - loss: -0.0031 - accuracy: 0.9906\n",
            "At the end of episode 2109 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2728/2728 [==============================] - 0s 104us/step - loss: -0.0021 - accuracy: 0.9879\n",
            "At the end of episode 2110 the total reward was : -20.0\n",
            "Epoch 1/1\n",
            "2351/2351 [==============================] - 0s 101us/step - loss: 4.9023e-04 - accuracy: 0.9877\n",
            "At the end of episode 2111 the total reward was : -14.0\n",
            "Epoch 1/1\n",
            "2969/2969 [==============================] - 0s 104us/step - loss: -1.4979e-04 - accuracy: 0.9970\n",
            "At the end of episode 2112 the total reward was : -16.0\n",
            "Epoch 1/1\n",
            "2804/2804 [==============================] - 0s 105us/step - loss: 0.0136 - accuracy: 0.9904\n",
            "At the end of episode 2113 the total reward was : -16.0\n",
            "Epoch 1/1\n",
            "2408/2408 [==============================] - 0s 101us/step - loss: 0.0063 - accuracy: 0.9909\n",
            "At the end of episode 2114 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "2903/2903 [==============================] - 0s 104us/step - loss: -0.0020 - accuracy: 0.9866\n",
            "At the end of episode 2115 the total reward was : -12.0\n",
            "Epoch 1/1\n",
            "2672/2672 [==============================] - 0s 100us/step - loss: -0.0070 - accuracy: 0.9906\n",
            "At the end of episode 2116 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "2676/2676 [==============================] - 0s 102us/step - loss: -0.0011 - accuracy: 0.9925\n",
            "At the end of episode 2117 the total reward was : -18.0\n",
            "Epoch 1/1\n",
            "2465/2465 [==============================] - 0s 102us/step - loss: 3.2345e-04 - accuracy: 0.9923\n",
            "At the end of episode 2118 the total reward was : -18.0\n",
            "Epoch 1/1\n",
            "2721/2721 [==============================] - 0s 106us/step - loss: 0.0062 - accuracy: 0.9879\n",
            "At the end of episode 2119 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "2402/2402 [==============================] - 0s 108us/step - loss: -0.0059 - accuracy: 0.9913\n",
            "At the end of episode 2120 the total reward was : -14.0\n",
            "Epoch 1/1\n",
            "3387/3387 [==============================] - 0s 114us/step - loss: 0.0075 - accuracy: 0.9888\n",
            "At the end of episode 2121 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2499/2499 [==============================] - 0s 105us/step - loss: -0.0099 - accuracy: 0.9900\n",
            "At the end of episode 2122 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2175/2175 [==============================] - 0s 112us/step - loss: -0.0071 - accuracy: 0.9908\n",
            "At the end of episode 2123 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "2664/2664 [==============================] - 0s 109us/step - loss: -0.0045 - accuracy: 0.9917\n",
            "At the end of episode 2124 the total reward was : -14.0\n",
            "Epoch 1/1\n",
            "2640/2640 [==============================] - 0s 105us/step - loss: -0.0026 - accuracy: 0.9913\n",
            "At the end of episode 2125 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2734/2734 [==============================] - 0s 106us/step - loss: 0.0028 - accuracy: 0.9890\n",
            "At the end of episode 2126 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "2423/2423 [==============================] - 0s 102us/step - loss: -0.0024 - accuracy: 0.9905\n",
            "At the end of episode 2127 the total reward was : -20.0\n",
            "Epoch 1/1\n",
            "2113/2113 [==============================] - 0s 102us/step - loss: -0.0052 - accuracy: 0.9896\n",
            "At the end of episode 2128 the total reward was : -18.0\n",
            "Epoch 1/1\n",
            "2838/2838 [==============================] - 0s 106us/step - loss: -0.0037 - accuracy: 0.9937\n",
            "At the end of episode 2129 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "2245/2245 [==============================] - 0s 102us/step - loss: -0.0074 - accuracy: 0.9902\n",
            "At the end of episode 2130 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2563/2563 [==============================] - 0s 111us/step - loss: -4.8882e-04 - accuracy: 0.9899\n",
            "At the end of episode 2131 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2497/2497 [==============================] - 0s 100us/step - loss: -0.0014 - accuracy: 0.9904\n",
            "At the end of episode 2132 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "3077/3077 [==============================] - 0s 103us/step - loss: 0.0089 - accuracy: 0.9851\n",
            "At the end of episode 2133 the total reward was : -15.0\n",
            "Epoch 1/1\n",
            "2933/2933 [==============================] - 0s 101us/step - loss: 0.0015 - accuracy: 0.9908\n",
            "At the end of episode 2134 the total reward was : -13.0\n",
            "Epoch 1/1\n",
            "2940/2940 [==============================] - 0s 111us/step - loss: -0.0037 - accuracy: 0.9915\n",
            "At the end of episode 2135 the total reward was : -14.0\n",
            "Epoch 1/1\n",
            "2630/2630 [==============================] - 0s 102us/step - loss: -8.0059e-05 - accuracy: 0.9958\n",
            "At the end of episode 2136 the total reward was : -15.0\n",
            "Epoch 1/1\n",
            "3272/3272 [==============================] - 0s 110us/step - loss: -0.0094 - accuracy: 0.9838\n",
            "At the end of episode 2137 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "2496/2496 [==============================] - 0s 101us/step - loss: -0.0049 - accuracy: 0.9924\n",
            "At the end of episode 2138 the total reward was : -14.0\n",
            "Epoch 1/1\n",
            "3102/3102 [==============================] - 0s 107us/step - loss: -0.0058 - accuracy: 0.9897\n",
            "At the end of episode 2139 the total reward was : -18.0\n",
            "Epoch 1/1\n",
            "2551/2551 [==============================] - 0s 110us/step - loss: -9.3005e-04 - accuracy: 0.9922\n",
            "At the end of episode 2140 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "2658/2658 [==============================] - 0s 107us/step - loss: 0.0053 - accuracy: 0.9929\n",
            "At the end of episode 2141 the total reward was : -15.0\n",
            "Epoch 1/1\n",
            "2625/2625 [==============================] - 0s 109us/step - loss: 0.0035 - accuracy: 0.9905\n",
            "At the end of episode 2142 the total reward was : -12.0\n",
            "Epoch 1/1\n",
            "2993/2993 [==============================] - 0s 107us/step - loss: 0.0025 - accuracy: 0.9873\n",
            "At the end of episode 2143 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2887/2887 [==============================] - 0s 103us/step - loss: -0.0028 - accuracy: 0.9882\n",
            "At the end of episode 2144 the total reward was : -16.0\n",
            "Epoch 1/1\n",
            "3026/3026 [==============================] - 0s 106us/step - loss: 0.0026 - accuracy: 0.9874\n",
            "At the end of episode 2145 the total reward was : -16.0\n",
            "Epoch 1/1\n",
            "3063/3063 [==============================] - 0s 107us/step - loss: 0.0141 - accuracy: 0.9879\n",
            "At the end of episode 2146 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "3440/3440 [==============================] - 0s 110us/step - loss: 0.0052 - accuracy: 0.9930\n",
            "At the end of episode 2147 the total reward was : -18.0\n",
            "Epoch 1/1\n",
            "2382/2382 [==============================] - 0s 105us/step - loss: 0.0028 - accuracy: 0.9908\n",
            "At the end of episode 2148 the total reward was : -14.0\n",
            "Epoch 1/1\n",
            "3303/3303 [==============================] - 0s 106us/step - loss: -0.0039 - accuracy: 0.9888\n",
            "At the end of episode 2149 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "2521/2521 [==============================] - 0s 101us/step - loss: -0.0013 - accuracy: 0.9909\n",
            "At the end of episode 2150 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "3196/3196 [==============================] - 0s 105us/step - loss: -0.0046 - accuracy: 0.9894\n",
            "At the end of episode 2151 the total reward was : -21.0\n",
            "Epoch 1/1\n",
            "2948/2948 [==============================] - 0s 101us/step - loss: -0.0023 - accuracy: 0.9881\n",
            "At the end of episode 2152 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "3065/3065 [==============================] - 0s 101us/step - loss: 9.8062e-04 - accuracy: 0.9938\n",
            "At the end of episode 2153 the total reward was : -14.0\n",
            "Epoch 1/1\n",
            "2534/2534 [==============================] - 0s 106us/step - loss: -0.0031 - accuracy: 0.9909\n",
            "At the end of episode 2154 the total reward was : -15.0\n",
            "Epoch 1/1\n",
            "3093/3093 [==============================] - 0s 108us/step - loss: -0.0028 - accuracy: 0.9903\n",
            "At the end of episode 2155 the total reward was : -20.0\n",
            "Epoch 1/1\n",
            "2768/2768 [==============================] - 0s 108us/step - loss: -0.0060 - accuracy: 0.9884\n",
            "At the end of episode 2156 the total reward was : -15.0\n",
            "Epoch 1/1\n",
            "2840/2840 [==============================] - 0s 111us/step - loss: 0.0067 - accuracy: 0.9884\n",
            "At the end of episode 2157 the total reward was : -15.0\n",
            "Epoch 1/1\n",
            "3253/3253 [==============================] - 0s 113us/step - loss: -0.0160 - accuracy: 0.9905\n",
            "At the end of episode 2158 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "3221/3221 [==============================] - 0s 111us/step - loss: -0.0131 - accuracy: 0.9873\n",
            "At the end of episode 2159 the total reward was : -21.0\n",
            "Epoch 1/1\n",
            "2571/2571 [==============================] - 0s 103us/step - loss: -0.0025 - accuracy: 0.9879\n",
            "At the end of episode 2160 the total reward was : -20.0\n",
            "Epoch 1/1\n",
            "2680/2680 [==============================] - 0s 103us/step - loss: 2.9357e-04 - accuracy: 0.9832\n",
            "At the end of episode 2161 the total reward was : -16.0\n",
            "Epoch 1/1\n",
            "2796/2796 [==============================] - 0s 103us/step - loss: -0.0041 - accuracy: 0.9907\n",
            "At the end of episode 2162 the total reward was : -18.0\n",
            "Epoch 1/1\n",
            "2812/2812 [==============================] - 0s 103us/step - loss: 0.0026 - accuracy: 0.9897\n",
            "At the end of episode 2163 the total reward was : -18.0\n",
            "Epoch 1/1\n",
            "2767/2767 [==============================] - 0s 105us/step - loss: 0.0023 - accuracy: 0.9931\n",
            "At the end of episode 2164 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "3648/3648 [==============================] - 0s 106us/step - loss: -0.0135 - accuracy: 0.9901\n",
            "At the end of episode 2165 the total reward was : -14.0\n",
            "Epoch 1/1\n",
            "2724/2724 [==============================] - 0s 102us/step - loss: -0.0166 - accuracy: 0.9901\n",
            "At the end of episode 2166 the total reward was : -16.0\n",
            "Epoch 1/1\n",
            "2704/2704 [==============================] - 0s 104us/step - loss: 0.0061 - accuracy: 0.9878\n",
            "At the end of episode 2167 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2559/2559 [==============================] - 0s 106us/step - loss: 0.0036 - accuracy: 0.9945\n",
            "At the end of episode 2168 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "2686/2686 [==============================] - 0s 106us/step - loss: -0.0041 - accuracy: 0.9937\n",
            "At the end of episode 2169 the total reward was : -14.0\n",
            "Epoch 1/1\n",
            "2630/2630 [==============================] - 0s 106us/step - loss: -0.0072 - accuracy: 0.9935\n",
            "At the end of episode 2170 the total reward was : -18.0\n",
            "Epoch 1/1\n",
            "2365/2365 [==============================] - 0s 103us/step - loss: 0.0161 - accuracy: 0.9903\n",
            "At the end of episode 2171 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "2759/2759 [==============================] - 0s 105us/step - loss: -0.0060 - accuracy: 0.9924\n",
            "At the end of episode 2172 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "2963/2963 [==============================] - 0s 104us/step - loss: -0.0012 - accuracy: 0.9922\n",
            "At the end of episode 2173 the total reward was : -15.0\n",
            "Epoch 1/1\n",
            "3010/3010 [==============================] - 0s 107us/step - loss: -0.0084 - accuracy: 0.9900\n",
            "At the end of episode 2174 the total reward was : -13.0\n",
            "Epoch 1/1\n",
            "2685/2685 [==============================] - 0s 107us/step - loss: 0.0024 - accuracy: 0.9888\n",
            "At the end of episode 2175 the total reward was : -21.0\n",
            "Epoch 1/1\n",
            "2820/2820 [==============================] - 0s 116us/step - loss: -0.0068 - accuracy: 0.9876\n",
            "At the end of episode 2176 the total reward was : -16.0\n",
            "Epoch 1/1\n",
            "2894/2894 [==============================] - 0s 102us/step - loss: -0.0023 - accuracy: 0.9924\n",
            "At the end of episode 2177 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "2571/2571 [==============================] - 0s 105us/step - loss: -9.9953e-04 - accuracy: 0.9903\n",
            "At the end of episode 2178 the total reward was : -16.0\n",
            "Epoch 1/1\n",
            "2780/2780 [==============================] - 0s 101us/step - loss: 0.0023 - accuracy: 0.9914\n",
            "At the end of episode 2179 the total reward was : -18.0\n",
            "Epoch 1/1\n",
            "2060/2060 [==============================] - 0s 104us/step - loss: 0.0132 - accuracy: 0.9869\n",
            "At the end of episode 2180 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "2745/2745 [==============================] - 0s 103us/step - loss: 0.0026 - accuracy: 0.9909\n",
            "At the end of episode 2181 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "2517/2517 [==============================] - 0s 107us/step - loss: 0.0084 - accuracy: 0.9877\n",
            "At the end of episode 2182 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2662/2662 [==============================] - 0s 103us/step - loss: -0.0030 - accuracy: 0.9910\n",
            "At the end of episode 2183 the total reward was : -18.0\n",
            "Epoch 1/1\n",
            "2449/2449 [==============================] - 0s 105us/step - loss: -0.0054 - accuracy: 0.9902\n",
            "At the end of episode 2184 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2672/2672 [==============================] - 0s 107us/step - loss: 0.0030 - accuracy: 0.9936\n",
            "At the end of episode 2185 the total reward was : -21.0\n",
            "Epoch 1/1\n",
            "3182/3182 [==============================] - 0s 106us/step - loss: -8.9281e-04 - accuracy: 0.9915\n",
            "At the end of episode 2186 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2499/2499 [==============================] - 0s 105us/step - loss: -0.0034 - accuracy: 0.9932\n",
            "At the end of episode 2187 the total reward was : -20.0\n",
            "Epoch 1/1\n",
            "3007/3007 [==============================] - 0s 106us/step - loss: -0.0023 - accuracy: 0.9940\n",
            "At the end of episode 2188 the total reward was : -18.0\n",
            "Epoch 1/1\n",
            "3185/3185 [==============================] - 0s 111us/step - loss: -0.0094 - accuracy: 0.9874\n",
            "At the end of episode 2189 the total reward was : -16.0\n",
            "Epoch 1/1\n",
            "3037/3037 [==============================] - 0s 106us/step - loss: 0.0012 - accuracy: 0.9911\n",
            "At the end of episode 2190 the total reward was : -15.0\n",
            "Epoch 1/1\n",
            "2822/2822 [==============================] - 0s 105us/step - loss: -0.0017 - accuracy: 0.9933\n",
            "At the end of episode 2191 the total reward was : -21.0\n",
            "Epoch 1/1\n",
            "2474/2474 [==============================] - 0s 108us/step - loss: -9.4924e-04 - accuracy: 0.9923\n",
            "At the end of episode 2192 the total reward was : -11.0\n",
            "Epoch 1/1\n",
            "3294/3294 [==============================] - 0s 106us/step - loss: -0.0029 - accuracy: 0.9885\n",
            "At the end of episode 2193 the total reward was : -16.0\n",
            "Epoch 1/1\n",
            "3454/3454 [==============================] - 0s 108us/step - loss: -0.0022 - accuracy: 0.9916\n",
            "At the end of episode 2194 the total reward was : -10.0\n",
            "Epoch 1/1\n",
            "3300/3300 [==============================] - 0s 109us/step - loss: -0.0099 - accuracy: 0.9918\n",
            "At the end of episode 2195 the total reward was : -16.0\n",
            "Epoch 1/1\n",
            "2649/2649 [==============================] - 0s 108us/step - loss: -0.0028 - accuracy: 0.9958\n",
            "At the end of episode 2196 the total reward was : -12.0\n",
            "Epoch 1/1\n",
            "3062/3062 [==============================] - 0s 104us/step - loss: -0.0100 - accuracy: 0.9915\n",
            "At the end of episode 2197 the total reward was : -18.0\n",
            "Epoch 1/1\n",
            "2527/2527 [==============================] - 0s 100us/step - loss: -1.5924e-04 - accuracy: 0.9929\n",
            "At the end of episode 2198 the total reward was : -21.0\n",
            "Epoch 1/1\n",
            "2087/2087 [==============================] - 0s 105us/step - loss: -0.0094 - accuracy: 0.9895\n",
            "At the end of episode 2199 the total reward was : -12.0\n",
            "Epoch 1/1\n",
            "3453/3453 [==============================] - 0s 102us/step - loss: -0.0043 - accuracy: 0.9902\n",
            "At the end of episode 2200 the total reward was : -14.0\n",
            "Epoch 1/1\n",
            "2561/2561 [==============================] - 0s 102us/step - loss: -0.0049 - accuracy: 0.9945\n",
            "At the end of episode 2201 the total reward was : -15.0\n",
            "Epoch 1/1\n",
            "2852/2852 [==============================] - 0s 101us/step - loss: 0.0073 - accuracy: 0.9895\n",
            "At the end of episode 2202 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2562/2562 [==============================] - 0s 105us/step - loss: 3.2447e-04 - accuracy: 0.9930\n",
            "At the end of episode 2203 the total reward was : -18.0\n",
            "Epoch 1/1\n",
            "2687/2687 [==============================] - 0s 102us/step - loss: 2.3796e-04 - accuracy: 0.9948\n",
            "At the end of episode 2204 the total reward was : -15.0\n",
            "Epoch 1/1\n",
            "3265/3265 [==============================] - 0s 107us/step - loss: -0.0066 - accuracy: 0.9911\n",
            "At the end of episode 2205 the total reward was : -13.0\n",
            "Epoch 1/1\n",
            "2824/2824 [==============================] - 0s 100us/step - loss: -0.0011 - accuracy: 0.9933\n",
            "At the end of episode 2206 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2156/2156 [==============================] - 0s 107us/step - loss: -0.0050 - accuracy: 0.9912\n",
            "At the end of episode 2207 the total reward was : -14.0\n",
            "Epoch 1/1\n",
            "2878/2878 [==============================] - 0s 103us/step - loss: 0.0044 - accuracy: 0.9931\n",
            "At the end of episode 2208 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "2512/2512 [==============================] - 0s 104us/step - loss: -0.0013 - accuracy: 0.9956\n",
            "At the end of episode 2209 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2167/2167 [==============================] - 0s 103us/step - loss: -0.0039 - accuracy: 0.9922\n",
            "At the end of episode 2210 the total reward was : -14.0\n",
            "Epoch 1/1\n",
            "2782/2782 [==============================] - 0s 103us/step - loss: -0.0017 - accuracy: 0.9942\n",
            "At the end of episode 2211 the total reward was : -16.0\n",
            "Epoch 1/1\n",
            "2701/2701 [==============================] - 0s 103us/step - loss: 0.0015 - accuracy: 0.9930\n",
            "At the end of episode 2212 the total reward was : -18.0\n",
            "Epoch 1/1\n",
            "2451/2451 [==============================] - 0s 103us/step - loss: 7.7281e-04 - accuracy: 0.9906\n",
            "At the end of episode 2213 the total reward was : -20.0\n",
            "Epoch 1/1\n",
            "2696/2696 [==============================] - 0s 109us/step - loss: 2.1171e-04 - accuracy: 0.9941\n",
            "At the end of episode 2214 the total reward was : -21.0\n",
            "Epoch 1/1\n",
            "2900/2900 [==============================] - 0s 103us/step - loss: 0.0058 - accuracy: 0.9910\n",
            "At the end of episode 2215 the total reward was : -16.0\n",
            "Epoch 1/1\n",
            "2795/2795 [==============================] - 0s 106us/step - loss: -0.0039 - accuracy: 0.9896\n",
            "At the end of episode 2216 the total reward was : -16.0\n",
            "Epoch 1/1\n",
            "2488/2488 [==============================] - 0s 102us/step - loss: -0.0083 - accuracy: 0.9916\n",
            "At the end of episode 2217 the total reward was : -21.0\n",
            "Epoch 1/1\n",
            "2409/2409 [==============================] - 0s 101us/step - loss: 5.4684e-04 - accuracy: 0.9925\n",
            "At the end of episode 2218 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2576/2576 [==============================] - 0s 109us/step - loss: 0.0043 - accuracy: 0.9938\n",
            "At the end of episode 2219 the total reward was : -18.0\n",
            "Epoch 1/1\n",
            "2198/2198 [==============================] - 0s 101us/step - loss: -0.0024 - accuracy: 0.9864\n",
            "At the end of episode 2220 the total reward was : -18.0\n",
            "Epoch 1/1\n",
            "2213/2213 [==============================] - 0s 103us/step - loss: 0.0046 - accuracy: 0.9851\n",
            "At the end of episode 2221 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2809/2809 [==============================] - 0s 103us/step - loss: -0.0031 - accuracy: 0.9925\n",
            "At the end of episode 2222 the total reward was : -16.0\n",
            "Epoch 1/1\n",
            "2700/2700 [==============================] - 0s 104us/step - loss: -0.0055 - accuracy: 0.9907\n",
            "At the end of episode 2223 the total reward was : -15.0\n",
            "Epoch 1/1\n",
            "2854/2854 [==============================] - 0s 105us/step - loss: -0.0017 - accuracy: 0.9912\n",
            "At the end of episode 2224 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2238/2238 [==============================] - 0s 102us/step - loss: 1.3223e-04 - accuracy: 0.9951\n",
            "At the end of episode 2225 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "2649/2649 [==============================] - 0s 101us/step - loss: 0.0022 - accuracy: 0.9868\n",
            "At the end of episode 2226 the total reward was : -16.0\n",
            "Epoch 1/1\n",
            "2311/2311 [==============================] - 0s 102us/step - loss: -5.2742e-04 - accuracy: 0.9909\n",
            "At the end of episode 2227 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "2164/2164 [==============================] - 0s 103us/step - loss: -0.0050 - accuracy: 0.9940\n",
            "At the end of episode 2228 the total reward was : -20.0\n",
            "Epoch 1/1\n",
            "2546/2546 [==============================] - 0s 101us/step - loss: -0.0096 - accuracy: 0.9788\n",
            "At the end of episode 2229 the total reward was : -13.0\n",
            "Epoch 1/1\n",
            "2567/2567 [==============================] - 0s 106us/step - loss: -0.0031 - accuracy: 0.9938\n",
            "At the end of episode 2230 the total reward was : -11.0\n",
            "Epoch 1/1\n",
            "3832/3832 [==============================] - 0s 112us/step - loss: 0.0046 - accuracy: 0.9893\n",
            "At the end of episode 2231 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2801/2801 [==============================] - 0s 111us/step - loss: -0.0013 - accuracy: 0.9950\n",
            "At the end of episode 2232 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "2583/2583 [==============================] - 0s 109us/step - loss: 0.0015 - accuracy: 0.9946\n",
            "At the end of episode 2233 the total reward was : -20.0\n",
            "Epoch 1/1\n",
            "3121/3121 [==============================] - 0s 103us/step - loss: -0.0019 - accuracy: 0.9859\n",
            "At the end of episode 2234 the total reward was : -21.0\n",
            "Epoch 1/1\n",
            "2794/2794 [==============================] - 0s 111us/step - loss: -0.0051 - accuracy: 0.9896\n",
            "At the end of episode 2235 the total reward was : -15.0\n",
            "Epoch 1/1\n",
            "3178/3178 [==============================] - 0s 104us/step - loss: -5.3264e-04 - accuracy: 0.9880\n",
            "At the end of episode 2236 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "2825/2825 [==============================] - 0s 107us/step - loss: 0.0050 - accuracy: 0.9943\n",
            "At the end of episode 2237 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "2684/2684 [==============================] - 0s 105us/step - loss: 0.0016 - accuracy: 0.9914\n",
            "At the end of episode 2238 the total reward was : -16.0\n",
            "Epoch 1/1\n",
            "2870/2870 [==============================] - 0s 104us/step - loss: -0.0064 - accuracy: 0.9871\n",
            "At the end of episode 2239 the total reward was : -20.0\n",
            "Epoch 1/1\n",
            "2452/2452 [==============================] - 0s 110us/step - loss: -0.0028 - accuracy: 0.9882\n",
            "At the end of episode 2240 the total reward was : -20.0\n",
            "Epoch 1/1\n",
            "2530/2530 [==============================] - 0s 101us/step - loss: 0.0022 - accuracy: 0.9921\n",
            "At the end of episode 2241 the total reward was : -18.0\n",
            "Epoch 1/1\n",
            "2927/2927 [==============================] - 0s 105us/step - loss: 6.0941e-04 - accuracy: 0.9891\n",
            "At the end of episode 2242 the total reward was : -14.0\n",
            "Epoch 1/1\n",
            "2887/2887 [==============================] - 0s 105us/step - loss: -0.0019 - accuracy: 0.9896\n",
            "At the end of episode 2243 the total reward was : -18.0\n",
            "Epoch 1/1\n",
            "2611/2611 [==============================] - 0s 107us/step - loss: 0.0062 - accuracy: 0.9908\n",
            "At the end of episode 2244 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2170/2170 [==============================] - 0s 103us/step - loss: -0.0012 - accuracy: 0.9940\n",
            "At the end of episode 2245 the total reward was : -18.0\n",
            "Epoch 1/1\n",
            "2840/2840 [==============================] - 0s 101us/step - loss: 0.0077 - accuracy: 0.9894\n",
            "At the end of episode 2246 the total reward was : -11.0\n",
            "Epoch 1/1\n",
            "2862/2862 [==============================] - 0s 104us/step - loss: -0.0014 - accuracy: 0.9888\n",
            "At the end of episode 2247 the total reward was : -15.0\n",
            "Epoch 1/1\n",
            "3142/3142 [==============================] - 0s 106us/step - loss: -0.0022 - accuracy: 0.9892\n",
            "At the end of episode 2248 the total reward was : -18.0\n",
            "Epoch 1/1\n",
            "2878/2878 [==============================] - 0s 107us/step - loss: 0.0114 - accuracy: 0.9885\n",
            "At the end of episode 2249 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2662/2662 [==============================] - 0s 107us/step - loss: 0.0038 - accuracy: 0.9906\n",
            "At the end of episode 2250 the total reward was : -20.0\n",
            "Epoch 1/1\n",
            "2477/2477 [==============================] - 0s 115us/step - loss: 0.0026 - accuracy: 0.9915\n",
            "At the end of episode 2251 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "3054/3054 [==============================] - 0s 108us/step - loss: 6.8160e-04 - accuracy: 0.9862\n",
            "At the end of episode 2252 the total reward was : -16.0\n",
            "Epoch 1/1\n",
            "2800/2800 [==============================] - 0s 102us/step - loss: -0.0015 - accuracy: 0.9932\n",
            "At the end of episode 2253 the total reward was : -14.0\n",
            "Epoch 1/1\n",
            "2880/2880 [==============================] - 0s 106us/step - loss: -9.8067e-06 - accuracy: 0.9944\n",
            "At the end of episode 2254 the total reward was : -15.0\n",
            "Epoch 1/1\n",
            "2843/2843 [==============================] - 0s 109us/step - loss: -5.7515e-04 - accuracy: 0.9940\n",
            "At the end of episode 2255 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2832/2832 [==============================] - 0s 101us/step - loss: 0.0102 - accuracy: 0.9866\n",
            "At the end of episode 2256 the total reward was : -16.0\n",
            "Epoch 1/1\n",
            "2133/2133 [==============================] - 0s 103us/step - loss: -0.0062 - accuracy: 0.9911\n",
            "At the end of episode 2257 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "2738/2738 [==============================] - 0s 101us/step - loss: -0.0062 - accuracy: 0.9923\n",
            "At the end of episode 2258 the total reward was : -20.0\n",
            "Epoch 1/1\n",
            "2681/2681 [==============================] - 0s 106us/step - loss: 0.0022 - accuracy: 0.9922\n",
            "At the end of episode 2259 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "2360/2360 [==============================] - 0s 116us/step - loss: -0.0046 - accuracy: 0.9941\n",
            "At the end of episode 2260 the total reward was : -18.0\n",
            "Epoch 1/1\n",
            "2480/2480 [==============================] - 0s 105us/step - loss: -0.0048 - accuracy: 0.9863\n",
            "At the end of episode 2261 the total reward was : -18.0\n",
            "Epoch 1/1\n",
            "2614/2614 [==============================] - 0s 100us/step - loss: -0.0035 - accuracy: 0.9946\n",
            "At the end of episode 2262 the total reward was : -16.0\n",
            "Epoch 1/1\n",
            "3574/3574 [==============================] - 0s 110us/step - loss: 0.0099 - accuracy: 0.9913\n",
            "At the end of episode 2263 the total reward was : -20.0\n",
            "Epoch 1/1\n",
            "2336/2336 [==============================] - 0s 102us/step - loss: 0.0041 - accuracy: 0.9932\n",
            "At the end of episode 2264 the total reward was : -16.0\n",
            "Epoch 1/1\n",
            "2540/2540 [==============================] - 0s 106us/step - loss: 5.1066e-04 - accuracy: 0.9917\n",
            "At the end of episode 2265 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "2479/2479 [==============================] - 0s 100us/step - loss: -0.0013 - accuracy: 0.9935\n",
            "At the end of episode 2266 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "2744/2744 [==============================] - 0s 104us/step - loss: 6.3767e-05 - accuracy: 0.9887\n",
            "At the end of episode 2267 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "3144/3144 [==============================] - 0s 107us/step - loss: -0.0044 - accuracy: 0.9914\n",
            "At the end of episode 2268 the total reward was : -16.0\n",
            "Epoch 1/1\n",
            "2566/2566 [==============================] - 0s 109us/step - loss: 8.5079e-04 - accuracy: 0.9910\n",
            "At the end of episode 2269 the total reward was : -18.0\n",
            "Epoch 1/1\n",
            "2708/2708 [==============================] - 0s 107us/step - loss: 0.0050 - accuracy: 0.9956\n",
            "At the end of episode 2270 the total reward was : -18.0\n",
            "Epoch 1/1\n",
            "2838/2838 [==============================] - 0s 104us/step - loss: -0.0026 - accuracy: 0.9915\n",
            "At the end of episode 2271 the total reward was : -14.0\n",
            "Epoch 1/1\n",
            "3420/3420 [==============================] - 0s 103us/step - loss: -0.0131 - accuracy: 0.9775\n",
            "At the end of episode 2272 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "2370/2370 [==============================] - 0s 109us/step - loss: -0.0060 - accuracy: 0.9907\n",
            "At the end of episode 2273 the total reward was : -20.0\n",
            "Epoch 1/1\n",
            "2442/2442 [==============================] - 0s 101us/step - loss: -2.7913e-04 - accuracy: 0.9922\n",
            "At the end of episode 2274 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2341/2341 [==============================] - 0s 102us/step - loss: -0.0045 - accuracy: 0.9936\n",
            "At the end of episode 2275 the total reward was : -18.0\n",
            "Epoch 1/1\n",
            "2708/2708 [==============================] - 0s 103us/step - loss: 6.1449e-04 - accuracy: 0.9941\n",
            "At the end of episode 2276 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2078/2078 [==============================] - 0s 100us/step - loss: 0.0043 - accuracy: 0.9942\n",
            "At the end of episode 2277 the total reward was : -21.0\n",
            "Epoch 1/1\n",
            "2881/2881 [==============================] - 0s 103us/step - loss: 0.0090 - accuracy: 0.9885\n",
            "At the end of episode 2278 the total reward was : -11.0\n",
            "Epoch 1/1\n",
            "2936/2936 [==============================] - 0s 104us/step - loss: 0.0056 - accuracy: 0.9809\n",
            "At the end of episode 2279 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "2980/2980 [==============================] - 0s 108us/step - loss: 0.0038 - accuracy: 0.9906\n",
            "At the end of episode 2280 the total reward was : -20.0\n",
            "Epoch 1/1\n",
            "3023/3023 [==============================] - 0s 102us/step - loss: 0.0021 - accuracy: 0.9907\n",
            "At the end of episode 2281 the total reward was : -18.0\n",
            "Epoch 1/1\n",
            "2447/2447 [==============================] - 0s 102us/step - loss: -0.0048 - accuracy: 0.9894\n",
            "At the end of episode 2282 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "2504/2504 [==============================] - 0s 107us/step - loss: -0.0012 - accuracy: 0.9892\n",
            "At the end of episode 2283 the total reward was : -15.0\n",
            "Epoch 1/1\n",
            "3489/3489 [==============================] - 0s 107us/step - loss: -0.0028 - accuracy: 0.9894\n",
            "At the end of episode 2284 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "3220/3220 [==============================] - 0s 101us/step - loss: 0.0069 - accuracy: 0.9904\n",
            "At the end of episode 2285 the total reward was : -15.0\n",
            "Epoch 1/1\n",
            "3308/3308 [==============================] - 0s 102us/step - loss: -8.8239e-04 - accuracy: 0.9876\n",
            "At the end of episode 2286 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2399/2399 [==============================] - 0s 104us/step - loss: 0.0051 - accuracy: 0.9887\n",
            "At the end of episode 2287 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "2589/2589 [==============================] - 0s 100us/step - loss: -0.0011 - accuracy: 0.9919\n",
            "At the end of episode 2288 the total reward was : -15.0\n",
            "Epoch 1/1\n",
            "3156/3156 [==============================] - 0s 102us/step - loss: 0.0059 - accuracy: 0.9873\n",
            "At the end of episode 2289 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2747/2747 [==============================] - 0s 106us/step - loss: -0.0080 - accuracy: 0.9887\n",
            "At the end of episode 2290 the total reward was : -15.0\n",
            "Epoch 1/1\n",
            "3016/3016 [==============================] - 0s 105us/step - loss: -0.0143 - accuracy: 0.9881\n",
            "At the end of episode 2291 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "3008/3008 [==============================] - 0s 108us/step - loss: -0.0040 - accuracy: 0.9900\n",
            "At the end of episode 2292 the total reward was : -18.0\n",
            "Epoch 1/1\n",
            "2468/2468 [==============================] - 0s 102us/step - loss: 0.0288 - accuracy: 0.9866\n",
            "At the end of episode 2293 the total reward was : -18.0\n",
            "Epoch 1/1\n",
            "2609/2609 [==============================] - 0s 105us/step - loss: -0.0025 - accuracy: 0.9912\n",
            "At the end of episode 2294 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2878/2878 [==============================] - 0s 114us/step - loss: 0.0019 - accuracy: 0.9920\n",
            "At the end of episode 2295 the total reward was : -20.0\n",
            "Epoch 1/1\n",
            "2266/2266 [==============================] - 0s 103us/step - loss: 0.0011 - accuracy: 0.9907\n",
            "At the end of episode 2296 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "2823/2823 [==============================] - 0s 101us/step - loss: -0.0061 - accuracy: 0.9926\n",
            "At the end of episode 2297 the total reward was : -20.0\n",
            "Epoch 1/1\n",
            "2197/2197 [==============================] - 0s 108us/step - loss: -0.0030 - accuracy: 0.9923\n",
            "At the end of episode 2298 the total reward was : -20.0\n",
            "Epoch 1/1\n",
            "2852/2852 [==============================] - 0s 108us/step - loss: -0.0042 - accuracy: 0.9912\n",
            "At the end of episode 2299 the total reward was : -20.0\n",
            "Epoch 1/1\n",
            "2767/2767 [==============================] - 0s 102us/step - loss: -0.0014 - accuracy: 0.9920\n",
            "At the end of episode 2300 the total reward was : -18.0\n",
            "Epoch 1/1\n",
            "2778/2778 [==============================] - 0s 102us/step - loss: -9.2910e-04 - accuracy: 0.9928\n",
            "At the end of episode 2301 the total reward was : -20.0\n",
            "Epoch 1/1\n",
            "2305/2305 [==============================] - 0s 103us/step - loss: -0.0025 - accuracy: 0.9905\n",
            "At the end of episode 2302 the total reward was : -16.0\n",
            "Epoch 1/1\n",
            "2695/2695 [==============================] - 0s 101us/step - loss: -2.9846e-04 - accuracy: 0.9937\n",
            "At the end of episode 2303 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2823/2823 [==============================] - 0s 106us/step - loss: -0.0018 - accuracy: 0.9904\n",
            "At the end of episode 2304 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "3489/3489 [==============================] - 0s 108us/step - loss: 0.0031 - accuracy: 0.9908\n",
            "At the end of episode 2305 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "3046/3046 [==============================] - 0s 101us/step - loss: -0.0027 - accuracy: 0.9911\n",
            "At the end of episode 2306 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2898/2898 [==============================] - 0s 102us/step - loss: 0.0066 - accuracy: 0.9917\n",
            "At the end of episode 2307 the total reward was : -20.0\n",
            "Epoch 1/1\n",
            "2678/2678 [==============================] - 0s 98us/step - loss: -6.0114e-04 - accuracy: 0.9910\n",
            "At the end of episode 2308 the total reward was : -20.0\n",
            "Epoch 1/1\n",
            "1886/1886 [==============================] - 0s 109us/step - loss: -0.0011 - accuracy: 0.9926\n",
            "At the end of episode 2309 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "3039/3039 [==============================] - 0s 104us/step - loss: -0.0045 - accuracy: 0.9901\n",
            "At the end of episode 2310 the total reward was : -16.0\n",
            "Epoch 1/1\n",
            "3507/3507 [==============================] - 0s 108us/step - loss: 0.0043 - accuracy: 0.9877\n",
            "At the end of episode 2311 the total reward was : -16.0\n",
            "Epoch 1/1\n",
            "2775/2775 [==============================] - 0s 105us/step - loss: 0.0026 - accuracy: 0.9917\n",
            "At the end of episode 2312 the total reward was : -18.0\n",
            "Epoch 1/1\n",
            "3101/3101 [==============================] - 0s 101us/step - loss: 0.0028 - accuracy: 0.9932\n",
            "At the end of episode 2313 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2741/2741 [==============================] - 0s 102us/step - loss: 3.5388e-04 - accuracy: 0.9916\n",
            "At the end of episode 2314 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "3181/3181 [==============================] - 0s 107us/step - loss: -0.0171 - accuracy: 0.9884\n",
            "At the end of episode 2315 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "2748/2748 [==============================] - 0s 103us/step - loss: -0.0144 - accuracy: 0.9844\n",
            "At the end of episode 2316 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "3807/3807 [==============================] - 0s 108us/step - loss: 8.7523e-04 - accuracy: 0.9926\n",
            "At the end of episode 2317 the total reward was : -21.0\n",
            "Epoch 1/1\n",
            "3027/3027 [==============================] - 0s 108us/step - loss: -0.0014 - accuracy: 0.9921\n",
            "At the end of episode 2318 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2003/2003 [==============================] - 0s 104us/step - loss: -5.2829e-04 - accuracy: 0.9935\n",
            "At the end of episode 2319 the total reward was : -15.0\n",
            "Epoch 1/1\n",
            "2501/2501 [==============================] - 0s 105us/step - loss: -0.0047 - accuracy: 0.9948\n",
            "At the end of episode 2320 the total reward was : -16.0\n",
            "Epoch 1/1\n",
            "2953/2953 [==============================] - 0s 104us/step - loss: -0.0012 - accuracy: 0.9949\n",
            "At the end of episode 2321 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "2103/2103 [==============================] - 0s 105us/step - loss: -0.0035 - accuracy: 0.9905\n",
            "At the end of episode 2322 the total reward was : -16.0\n",
            "Epoch 1/1\n",
            "2700/2700 [==============================] - 0s 116us/step - loss: 0.0014 - accuracy: 0.9885\n",
            "At the end of episode 2323 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "3371/3371 [==============================] - 0s 112us/step - loss: 6.2055e-04 - accuracy: 0.9935\n",
            "At the end of episode 2324 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "2836/2836 [==============================] - 0s 108us/step - loss: 0.0010 - accuracy: 0.9940\n",
            "At the end of episode 2325 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2506/2506 [==============================] - 0s 114us/step - loss: -0.0027 - accuracy: 0.9912\n",
            "At the end of episode 2326 the total reward was : -21.0\n",
            "Epoch 1/1\n",
            "2888/2888 [==============================] - 0s 101us/step - loss: -0.0016 - accuracy: 0.9893\n",
            "At the end of episode 2327 the total reward was : -14.0\n",
            "Epoch 1/1\n",
            "3230/3230 [==============================] - 0s 104us/step - loss: -0.0152 - accuracy: 0.9777\n",
            "At the end of episode 2328 the total reward was : -21.0\n",
            "Epoch 1/1\n",
            "2059/2059 [==============================] - 0s 103us/step - loss: -0.0038 - accuracy: 0.9898\n",
            "At the end of episode 2329 the total reward was : -21.0\n",
            "Epoch 1/1\n",
            "2656/2656 [==============================] - 0s 103us/step - loss: -0.0010 - accuracy: 0.9846\n",
            "At the end of episode 2330 the total reward was : -20.0\n",
            "Epoch 1/1\n",
            "2847/2847 [==============================] - 0s 108us/step - loss: 0.0028 - accuracy: 0.9919\n",
            "At the end of episode 2331 the total reward was : -18.0\n",
            "Epoch 1/1\n",
            "2943/2943 [==============================] - 0s 105us/step - loss: 0.0028 - accuracy: 0.9905\n",
            "At the end of episode 2332 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2663/2663 [==============================] - 0s 101us/step - loss: -0.0045 - accuracy: 0.9880\n",
            "At the end of episode 2333 the total reward was : -15.0\n",
            "Epoch 1/1\n",
            "2776/2776 [==============================] - 0s 105us/step - loss: 0.0076 - accuracy: 0.9896\n",
            "At the end of episode 2334 the total reward was : -18.0\n",
            "Epoch 1/1\n",
            "3178/3178 [==============================] - 0s 102us/step - loss: 0.0018 - accuracy: 0.9884\n",
            "At the end of episode 2335 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "3075/3075 [==============================] - 0s 105us/step - loss: -0.0017 - accuracy: 0.9896\n",
            "At the end of episode 2336 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2247/2247 [==============================] - 0s 102us/step - loss: -0.0065 - accuracy: 0.9920\n",
            "At the end of episode 2337 the total reward was : -21.0\n",
            "Epoch 1/1\n",
            "2797/2797 [==============================] - 0s 103us/step - loss: -0.0012 - accuracy: 0.9939\n",
            "At the end of episode 2338 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2893/2893 [==============================] - 0s 103us/step - loss: 0.0123 - accuracy: 0.9896\n",
            "At the end of episode 2339 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2335/2335 [==============================] - 0s 108us/step - loss: 0.0043 - accuracy: 0.9889\n",
            "At the end of episode 2340 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "2910/2910 [==============================] - 0s 103us/step - loss: -0.0038 - accuracy: 0.9921\n",
            "At the end of episode 2341 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "2740/2740 [==============================] - 0s 104us/step - loss: -0.0033 - accuracy: 0.9942\n",
            "At the end of episode 2342 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "2516/2516 [==============================] - 0s 103us/step - loss: -0.0052 - accuracy: 0.9928\n",
            "At the end of episode 2343 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "3051/3051 [==============================] - 0s 101us/step - loss: -0.0058 - accuracy: 0.9875\n",
            "At the end of episode 2344 the total reward was : -16.0\n",
            "Epoch 1/1\n",
            "3111/3111 [==============================] - 0s 104us/step - loss: -8.8325e-04 - accuracy: 0.9929\n",
            "At the end of episode 2345 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2872/2872 [==============================] - 0s 101us/step - loss: 0.0017 - accuracy: 0.9892\n",
            "At the end of episode 2346 the total reward was : -18.0\n",
            "Epoch 1/1\n",
            "2863/2863 [==============================] - 0s 105us/step - loss: -0.0054 - accuracy: 0.9808\n",
            "At the end of episode 2347 the total reward was : -20.0\n",
            "Epoch 1/1\n",
            "2706/2706 [==============================] - 0s 105us/step - loss: 0.0016 - accuracy: 0.9956\n",
            "At the end of episode 2348 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2417/2417 [==============================] - 0s 99us/step - loss: -7.5507e-04 - accuracy: 0.9892\n",
            "At the end of episode 2349 the total reward was : -20.0\n",
            "Epoch 1/1\n",
            "2357/2357 [==============================] - 0s 106us/step - loss: -0.0054 - accuracy: 0.9885\n",
            "At the end of episode 2350 the total reward was : -20.0\n",
            "Epoch 1/1\n",
            "2292/2292 [==============================] - 0s 104us/step - loss: 0.0018 - accuracy: 0.9935\n",
            "At the end of episode 2351 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "2983/2983 [==============================] - 0s 101us/step - loss: -0.0019 - accuracy: 0.9909\n",
            "At the end of episode 2352 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "3223/3223 [==============================] - 0s 102us/step - loss: -0.0053 - accuracy: 0.9907\n",
            "At the end of episode 2353 the total reward was : -18.0\n",
            "Epoch 1/1\n",
            "3023/3023 [==============================] - 0s 109us/step - loss: 0.0027 - accuracy: 0.9878\n",
            "At the end of episode 2354 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2328/2328 [==============================] - 0s 101us/step - loss: 7.8860e-04 - accuracy: 0.9905\n",
            "At the end of episode 2355 the total reward was : -15.0\n",
            "Epoch 1/1\n",
            "2646/2646 [==============================] - 0s 107us/step - loss: -0.0050 - accuracy: 0.9921\n",
            "At the end of episode 2356 the total reward was : -18.0\n",
            "Epoch 1/1\n",
            "2732/2732 [==============================] - 0s 102us/step - loss: -1.7366e-04 - accuracy: 0.9898\n",
            "At the end of episode 2357 the total reward was : -14.0\n",
            "Epoch 1/1\n",
            "2711/2711 [==============================] - 0s 101us/step - loss: -0.0045 - accuracy: 0.9889\n",
            "At the end of episode 2358 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2722/2722 [==============================] - 0s 102us/step - loss: -0.0101 - accuracy: 0.9864\n",
            "At the end of episode 2359 the total reward was : -20.0\n",
            "Epoch 1/1\n",
            "2973/2973 [==============================] - 0s 102us/step - loss: -0.0205 - accuracy: 0.9862\n",
            "At the end of episode 2360 the total reward was : -14.0\n",
            "Epoch 1/1\n",
            "3461/3461 [==============================] - 0s 107us/step - loss: 0.0082 - accuracy: 0.9896\n",
            "At the end of episode 2361 the total reward was : -16.0\n",
            "Epoch 1/1\n",
            "2480/2480 [==============================] - 0s 111us/step - loss: 0.0104 - accuracy: 0.9907\n",
            "At the end of episode 2362 the total reward was : -18.0\n",
            "Epoch 1/1\n",
            "3133/3133 [==============================] - 0s 101us/step - loss: -0.0044 - accuracy: 0.9907\n",
            "At the end of episode 2363 the total reward was : -10.0\n",
            "Epoch 1/1\n",
            "3554/3554 [==============================] - 0s 106us/step - loss: -0.0013 - accuracy: 0.9924\n",
            "At the end of episode 2364 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "3107/3107 [==============================] - 0s 108us/step - loss: -0.0055 - accuracy: 0.9923\n",
            "At the end of episode 2365 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2561/2561 [==============================] - 0s 107us/step - loss: 0.0010 - accuracy: 0.9949\n",
            "At the end of episode 2366 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "3228/3228 [==============================] - 0s 106us/step - loss: -0.0072 - accuracy: 0.9919\n",
            "At the end of episode 2367 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2731/2731 [==============================] - 0s 105us/step - loss: 0.0038 - accuracy: 0.9912\n",
            "At the end of episode 2368 the total reward was : -18.0\n",
            "Epoch 1/1\n",
            "2690/2690 [==============================] - 0s 105us/step - loss: -4.5316e-04 - accuracy: 0.9926\n",
            "At the end of episode 2369 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2748/2748 [==============================] - 0s 107us/step - loss: -0.0012 - accuracy: 0.9971\n",
            "At the end of episode 2370 the total reward was : -16.0\n",
            "Epoch 1/1\n",
            "2800/2800 [==============================] - 0s 107us/step - loss: -0.0055 - accuracy: 0.9914\n",
            "At the end of episode 2371 the total reward was : -21.0\n",
            "Epoch 1/1\n",
            "2745/2745 [==============================] - 0s 105us/step - loss: -0.0157 - accuracy: 0.9876\n",
            "At the end of episode 2372 the total reward was : -16.0\n",
            "Epoch 1/1\n",
            "3111/3111 [==============================] - 0s 102us/step - loss: -0.0066 - accuracy: 0.9894\n",
            "At the end of episode 2373 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2487/2487 [==============================] - 0s 100us/step - loss: -0.0019 - accuracy: 0.9871\n",
            "At the end of episode 2374 the total reward was : -21.0\n",
            "Epoch 1/1\n",
            "2166/2166 [==============================] - 0s 101us/step - loss: 0.0021 - accuracy: 0.9903\n",
            "At the end of episode 2375 the total reward was : -21.0\n",
            "Epoch 1/1\n",
            "2481/2481 [==============================] - 0s 101us/step - loss: 6.1406e-04 - accuracy: 0.9915\n",
            "At the end of episode 2376 the total reward was : -18.0\n",
            "Epoch 1/1\n",
            "2291/2291 [==============================] - 0s 106us/step - loss: 7.5903e-04 - accuracy: 0.9930\n",
            "At the end of episode 2377 the total reward was : -18.0\n",
            "Epoch 1/1\n",
            "2698/2698 [==============================] - 0s 104us/step - loss: -7.2792e-04 - accuracy: 0.9904\n",
            "At the end of episode 2378 the total reward was : -20.0\n",
            "Epoch 1/1\n",
            "3059/3059 [==============================] - 0s 102us/step - loss: -1.1694e-04 - accuracy: 0.9931\n",
            "At the end of episode 2379 the total reward was : -18.0\n",
            "Epoch 1/1\n",
            "2383/2383 [==============================] - 0s 102us/step - loss: -0.0024 - accuracy: 0.9899\n",
            "At the end of episode 2380 the total reward was : -20.0\n",
            "Epoch 1/1\n",
            "2507/2507 [==============================] - 0s 111us/step - loss: 0.0039 - accuracy: 0.9932\n",
            "At the end of episode 2381 the total reward was : -21.0\n",
            "Epoch 1/1\n",
            "2479/2479 [==============================] - 0s 105us/step - loss: -0.0093 - accuracy: 0.9895\n",
            "At the end of episode 2382 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2544/2544 [==============================] - 0s 110us/step - loss: 2.7073e-05 - accuracy: 0.9910\n",
            "At the end of episode 2383 the total reward was : -20.0\n",
            "Epoch 1/1\n",
            "2343/2343 [==============================] - 0s 103us/step - loss: -0.0024 - accuracy: 0.9945\n",
            "At the end of episode 2384 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "2421/2421 [==============================] - 0s 109us/step - loss: 0.0023 - accuracy: 0.9934\n",
            "At the end of episode 2385 the total reward was : -18.0\n",
            "Epoch 1/1\n",
            "2776/2776 [==============================] - 0s 106us/step - loss: 0.0010 - accuracy: 0.9939\n",
            "At the end of episode 2386 the total reward was : -14.0\n",
            "Epoch 1/1\n",
            "3891/3891 [==============================] - 0s 113us/step - loss: -0.0156 - accuracy: 0.9887\n",
            "At the end of episode 2387 the total reward was : -21.0\n",
            "Epoch 1/1\n",
            "2476/2476 [==============================] - 0s 106us/step - loss: -0.0109 - accuracy: 0.9891\n",
            "At the end of episode 2388 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2174/2174 [==============================] - 0s 111us/step - loss: -0.0059 - accuracy: 0.9899\n",
            "At the end of episode 2389 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "2344/2344 [==============================] - 0s 102us/step - loss: -0.0073 - accuracy: 0.9932\n",
            "At the end of episode 2390 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "2501/2501 [==============================] - 0s 108us/step - loss: 4.6736e-04 - accuracy: 0.9924\n",
            "At the end of episode 2391 the total reward was : -20.0\n",
            "Epoch 1/1\n",
            "2376/2376 [==============================] - 0s 101us/step - loss: -0.0495 - accuracy: 0.9840\n",
            "At the end of episode 2392 the total reward was : -14.0\n",
            "Epoch 1/1\n",
            "3352/3352 [==============================] - 0s 103us/step - loss: -0.0039 - accuracy: 0.9863\n",
            "At the end of episode 2393 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "3060/3060 [==============================] - 0s 106us/step - loss: 0.0011 - accuracy: 0.9931\n",
            "At the end of episode 2394 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2576/2576 [==============================] - 0s 104us/step - loss: -0.0060 - accuracy: 0.9895\n",
            "At the end of episode 2395 the total reward was : -21.0\n",
            "Epoch 1/1\n",
            "2902/2902 [==============================] - 0s 113us/step - loss: 0.0013 - accuracy: 0.9938\n",
            "At the end of episode 2396 the total reward was : -15.0\n",
            "Epoch 1/1\n",
            "2527/2527 [==============================] - 0s 112us/step - loss: 0.0015 - accuracy: 0.9905\n",
            "At the end of episode 2397 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "3150/3150 [==============================] - 0s 120us/step - loss: 0.0048 - accuracy: 0.9924\n",
            "At the end of episode 2398 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "2562/2562 [==============================] - 0s 105us/step - loss: -0.0023 - accuracy: 0.9945\n",
            "At the end of episode 2399 the total reward was : -20.0\n",
            "Epoch 1/1\n",
            "2286/2286 [==============================] - 0s 103us/step - loss: 0.0034 - accuracy: 0.9930\n",
            "At the end of episode 2400 the total reward was : -18.0\n",
            "Epoch 1/1\n",
            "3257/3257 [==============================] - 0s 106us/step - loss: 0.0082 - accuracy: 0.9889\n",
            "At the end of episode 2401 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2976/2976 [==============================] - 0s 104us/step - loss: 0.0089 - accuracy: 0.9923\n",
            "At the end of episode 2402 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "2484/2484 [==============================] - 0s 113us/step - loss: -0.0050 - accuracy: 0.9919\n",
            "At the end of episode 2403 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "2982/2982 [==============================] - 0s 102us/step - loss: -0.0018 - accuracy: 0.9883\n",
            "At the end of episode 2404 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2421/2421 [==============================] - 0s 104us/step - loss: 0.0016 - accuracy: 0.9938\n",
            "At the end of episode 2405 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2957/2957 [==============================] - 0s 102us/step - loss: -0.0046 - accuracy: 0.9932\n",
            "At the end of episode 2406 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "2832/2832 [==============================] - 0s 110us/step - loss: 0.0019 - accuracy: 0.9912\n",
            "At the end of episode 2407 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2315/2315 [==============================] - 0s 108us/step - loss: 5.6910e-04 - accuracy: 0.9905\n",
            "At the end of episode 2408 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2983/2983 [==============================] - 0s 103us/step - loss: -0.0018 - accuracy: 0.9940\n",
            "At the end of episode 2409 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "2498/2498 [==============================] - 0s 103us/step - loss: 0.0013 - accuracy: 0.9928\n",
            "At the end of episode 2410 the total reward was : -14.0\n",
            "Epoch 1/1\n",
            "2748/2748 [==============================] - 0s 102us/step - loss: -0.0016 - accuracy: 0.9938\n",
            "At the end of episode 2411 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "3582/3582 [==============================] - 0s 108us/step - loss: -0.0022 - accuracy: 0.9897\n",
            "At the end of episode 2412 the total reward was : -16.0\n",
            "Epoch 1/1\n",
            "2952/2952 [==============================] - 0s 104us/step - loss: 7.8904e-04 - accuracy: 0.9932\n",
            "At the end of episode 2413 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2813/2813 [==============================] - 0s 104us/step - loss: -0.0029 - accuracy: 0.9929\n",
            "At the end of episode 2414 the total reward was : -13.0\n",
            "Epoch 1/1\n",
            "3510/3510 [==============================] - 0s 102us/step - loss: 3.2971e-04 - accuracy: 0.9943\n",
            "At the end of episode 2415 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2500/2500 [==============================] - 0s 101us/step - loss: -0.0048 - accuracy: 0.9912\n",
            "At the end of episode 2416 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2328/2328 [==============================] - 0s 104us/step - loss: 0.0031 - accuracy: 0.9901\n",
            "At the end of episode 2417 the total reward was : -15.0\n",
            "Epoch 1/1\n",
            "3013/3013 [==============================] - 0s 104us/step - loss: 0.0034 - accuracy: 0.9914\n",
            "At the end of episode 2418 the total reward was : -20.0\n",
            "Epoch 1/1\n",
            "2994/2994 [==============================] - 0s 104us/step - loss: 0.0029 - accuracy: 0.9910\n",
            "At the end of episode 2419 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "3076/3076 [==============================] - 0s 106us/step - loss: 0.0048 - accuracy: 0.9893\n",
            "At the end of episode 2420 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "2643/2643 [==============================] - 0s 105us/step - loss: -0.0106 - accuracy: 0.9826\n",
            "At the end of episode 2421 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2500/2500 [==============================] - 0s 101us/step - loss: -0.0014 - accuracy: 0.9872\n",
            "At the end of episode 2422 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2825/2825 [==============================] - 0s 103us/step - loss: -0.0019 - accuracy: 0.9890\n",
            "At the end of episode 2423 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "3138/3138 [==============================] - 0s 103us/step - loss: -0.0040 - accuracy: 0.9895\n",
            "At the end of episode 2424 the total reward was : -15.0\n",
            "Epoch 1/1\n",
            "3254/3254 [==============================] - 0s 102us/step - loss: -0.0056 - accuracy: 0.9883\n",
            "At the end of episode 2425 the total reward was : -18.0\n",
            "Epoch 1/1\n",
            "2684/2684 [==============================] - 0s 101us/step - loss: -0.0090 - accuracy: 0.9914\n",
            "At the end of episode 2426 the total reward was : -18.0\n",
            "Epoch 1/1\n",
            "2770/2770 [==============================] - 0s 107us/step - loss: -0.0137 - accuracy: 0.9863\n",
            "At the end of episode 2427 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "3528/3528 [==============================] - 0s 109us/step - loss: -0.0043 - accuracy: 0.9898\n",
            "At the end of episode 2428 the total reward was : -10.0\n",
            "Epoch 1/1\n",
            "3229/3229 [==============================] - 0s 106us/step - loss: -0.0052 - accuracy: 0.9814\n",
            "At the end of episode 2429 the total reward was : -20.0\n",
            "Epoch 1/1\n",
            "2792/2792 [==============================] - 0s 102us/step - loss: 0.0018 - accuracy: 0.9893\n",
            "At the end of episode 2430 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "3083/3083 [==============================] - 0s 100us/step - loss: -0.0077 - accuracy: 0.9899\n",
            "At the end of episode 2431 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "2426/2426 [==============================] - 0s 107us/step - loss: 3.5723e-04 - accuracy: 0.9930\n",
            "At the end of episode 2432 the total reward was : -21.0\n",
            "Epoch 1/1\n",
            "3538/3538 [==============================] - 0s 109us/step - loss: 8.6001e-04 - accuracy: 0.9890\n",
            "At the end of episode 2433 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2997/2997 [==============================] - 0s 102us/step - loss: 0.0088 - accuracy: 0.9903\n",
            "At the end of episode 2434 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "2742/2742 [==============================] - 0s 105us/step - loss: -0.0010 - accuracy: 0.9964\n",
            "At the end of episode 2435 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2977/2977 [==============================] - 0s 114us/step - loss: 0.0025 - accuracy: 0.9916\n",
            "At the end of episode 2436 the total reward was : -18.0\n",
            "Epoch 1/1\n",
            "3083/3083 [==============================] - 0s 103us/step - loss: -8.2832e-04 - accuracy: 0.9955\n",
            "At the end of episode 2437 the total reward was : -18.0\n",
            "Epoch 1/1\n",
            "2694/2694 [==============================] - 0s 102us/step - loss: 2.8673e-04 - accuracy: 0.9967\n",
            "At the end of episode 2438 the total reward was : -15.0\n",
            "Epoch 1/1\n",
            "3236/3236 [==============================] - 0s 107us/step - loss: 0.0014 - accuracy: 0.9947\n",
            "At the end of episode 2439 the total reward was : -15.0\n",
            "Epoch 1/1\n",
            "2688/2688 [==============================] - 0s 103us/step - loss: 0.0072 - accuracy: 0.9940\n",
            "At the end of episode 2440 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2643/2643 [==============================] - 0s 102us/step - loss: 0.0014 - accuracy: 0.9894\n",
            "At the end of episode 2441 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "2756/2756 [==============================] - 0s 104us/step - loss: 0.0070 - accuracy: 0.9935\n",
            "At the end of episode 2442 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2401/2401 [==============================] - 0s 106us/step - loss: -0.0014 - accuracy: 0.9921\n",
            "At the end of episode 2443 the total reward was : -16.0\n",
            "Epoch 1/1\n",
            "3201/3201 [==============================] - 0s 102us/step - loss: -0.0051 - accuracy: 0.9844\n",
            "At the end of episode 2444 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2657/2657 [==============================] - 0s 102us/step - loss: 0.0022 - accuracy: 0.9913\n",
            "At the end of episode 2445 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "2831/2831 [==============================] - 0s 105us/step - loss: 0.0015 - accuracy: 0.9883\n",
            "At the end of episode 2446 the total reward was : -18.0\n",
            "Epoch 1/1\n",
            "3238/3238 [==============================] - 0s 104us/step - loss: -6.2572e-04 - accuracy: 0.9898\n",
            "At the end of episode 2447 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "3301/3301 [==============================] - 0s 102us/step - loss: 0.0055 - accuracy: 0.9927\n",
            "At the end of episode 2448 the total reward was : -20.0\n",
            "Epoch 1/1\n",
            "2870/2870 [==============================] - 0s 101us/step - loss: -0.0055 - accuracy: 0.9895\n",
            "At the end of episode 2449 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2564/2564 [==============================] - 0s 104us/step - loss: 0.0015 - accuracy: 0.9926\n",
            "At the end of episode 2450 the total reward was : -18.0\n",
            "Epoch 1/1\n",
            "2283/2283 [==============================] - 0s 102us/step - loss: 0.0049 - accuracy: 0.9917\n",
            "At the end of episode 2451 the total reward was : -21.0\n",
            "Epoch 1/1\n",
            "2575/2575 [==============================] - 0s 107us/step - loss: 0.0074 - accuracy: 0.9891\n",
            "At the end of episode 2452 the total reward was : -15.0\n",
            "Epoch 1/1\n",
            "2766/2766 [==============================] - 0s 103us/step - loss: -0.0054 - accuracy: 0.9913\n",
            "At the end of episode 2453 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "2912/2912 [==============================] - 0s 109us/step - loss: 0.0156 - accuracy: 0.9907\n",
            "At the end of episode 2454 the total reward was : -15.0\n",
            "Epoch 1/1\n",
            "3141/3141 [==============================] - 0s 103us/step - loss: -0.0041 - accuracy: 0.9908\n",
            "At the end of episode 2455 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "3583/3583 [==============================] - 0s 107us/step - loss: 3.3808e-04 - accuracy: 0.9844\n",
            "At the end of episode 2456 the total reward was : -12.0\n",
            "Epoch 1/1\n",
            "3154/3154 [==============================] - 0s 104us/step - loss: -0.0120 - accuracy: 0.9892\n",
            "At the end of episode 2457 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2741/2741 [==============================] - 0s 101us/step - loss: 7.1129e-04 - accuracy: 0.9927\n",
            "At the end of episode 2458 the total reward was : -18.0\n",
            "Epoch 1/1\n",
            "2872/2872 [==============================] - 0s 102us/step - loss: -0.0044 - accuracy: 0.9903\n",
            "At the end of episode 2459 the total reward was : -16.0\n",
            "Epoch 1/1\n",
            "3133/3133 [==============================] - 0s 102us/step - loss: 0.0043 - accuracy: 0.9914\n",
            "At the end of episode 2460 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2646/2646 [==============================] - 0s 101us/step - loss: -0.0032 - accuracy: 0.9940\n",
            "At the end of episode 2461 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2564/2564 [==============================] - 0s 101us/step - loss: 0.0015 - accuracy: 0.9961\n",
            "At the end of episode 2462 the total reward was : -20.0\n",
            "Epoch 1/1\n",
            "2836/2836 [==============================] - 0s 103us/step - loss: -0.0023 - accuracy: 0.9933\n",
            "At the end of episode 2463 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "2275/2275 [==============================] - 0s 106us/step - loss: -0.0057 - accuracy: 0.9908\n",
            "At the end of episode 2464 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2750/2750 [==============================] - 0s 107us/step - loss: 0.0011 - accuracy: 0.9913\n",
            "At the end of episode 2465 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "3159/3159 [==============================] - 0s 102us/step - loss: -3.8055e-04 - accuracy: 0.9908\n",
            "At the end of episode 2466 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2963/2963 [==============================] - 0s 107us/step - loss: 0.0030 - accuracy: 0.9919\n",
            "At the end of episode 2467 the total reward was : -15.0\n",
            "Epoch 1/1\n",
            "3263/3263 [==============================] - 0s 112us/step - loss: -8.4096e-04 - accuracy: 0.9923\n",
            "At the end of episode 2468 the total reward was : -15.0\n",
            "Epoch 1/1\n",
            "2842/2842 [==============================] - 0s 108us/step - loss: -0.0041 - accuracy: 0.9891\n",
            "At the end of episode 2469 the total reward was : -18.0\n",
            "Epoch 1/1\n",
            "3353/3353 [==============================] - 0s 104us/step - loss: 8.6110e-04 - accuracy: 0.9908\n",
            "At the end of episode 2470 the total reward was : -18.0\n",
            "Epoch 1/1\n",
            "2623/2623 [==============================] - 0s 103us/step - loss: 0.0072 - accuracy: 0.9878\n",
            "At the end of episode 2471 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2789/2789 [==============================] - 0s 101us/step - loss: -0.0019 - accuracy: 0.9932\n",
            "At the end of episode 2472 the total reward was : -14.0\n",
            "Epoch 1/1\n",
            "3223/3223 [==============================] - 0s 103us/step - loss: 0.0029 - accuracy: 0.9879\n",
            "At the end of episode 2473 the total reward was : -15.0\n",
            "Epoch 1/1\n",
            "3472/3472 [==============================] - 0s 103us/step - loss: -0.0017 - accuracy: 0.9919\n",
            "At the end of episode 2474 the total reward was : -15.0\n",
            "Epoch 1/1\n",
            "3069/3069 [==============================] - 0s 101us/step - loss: 0.0115 - accuracy: 0.9873\n",
            "At the end of episode 2475 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "2323/2323 [==============================] - 0s 105us/step - loss: -0.0042 - accuracy: 0.9944\n",
            "At the end of episode 2476 the total reward was : -14.0\n",
            "Epoch 1/1\n",
            "2725/2725 [==============================] - 0s 101us/step - loss: -0.0027 - accuracy: 0.9949\n",
            "At the end of episode 2477 the total reward was : -18.0\n",
            "Epoch 1/1\n",
            "2797/2797 [==============================] - 0s 108us/step - loss: -0.0032 - accuracy: 0.9911\n",
            "At the end of episode 2478 the total reward was : -13.0\n",
            "Epoch 1/1\n",
            "3410/3410 [==============================] - 0s 107us/step - loss: -0.0085 - accuracy: 0.9883\n",
            "At the end of episode 2479 the total reward was : -18.0\n",
            "Epoch 1/1\n",
            "2271/2271 [==============================] - 0s 103us/step - loss: -0.0070 - accuracy: 0.9890\n",
            "At the end of episode 2480 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "2585/2585 [==============================] - 0s 105us/step - loss: 0.0028 - accuracy: 0.9896\n",
            "At the end of episode 2481 the total reward was : -15.0\n",
            "Epoch 1/1\n",
            "3065/3065 [==============================] - 0s 101us/step - loss: -0.0017 - accuracy: 0.9902\n",
            "At the end of episode 2482 the total reward was : -18.0\n",
            "Epoch 1/1\n",
            "2631/2631 [==============================] - 0s 102us/step - loss: 0.0114 - accuracy: 0.9905\n",
            "At the end of episode 2483 the total reward was : -13.0\n",
            "Epoch 1/1\n",
            "2846/2846 [==============================] - 0s 106us/step - loss: -0.0019 - accuracy: 0.9898\n",
            "At the end of episode 2484 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2575/2575 [==============================] - 0s 101us/step - loss: -0.0085 - accuracy: 0.9887\n",
            "At the end of episode 2485 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "2840/2840 [==============================] - 0s 103us/step - loss: -0.0052 - accuracy: 0.9898\n",
            "At the end of episode 2486 the total reward was : -15.0\n",
            "Epoch 1/1\n",
            "2518/2518 [==============================] - 0s 106us/step - loss: -0.0046 - accuracy: 0.9913\n",
            "At the end of episode 2487 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "2511/2511 [==============================] - 0s 101us/step - loss: -0.0028 - accuracy: 0.9948\n",
            "At the end of episode 2488 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2656/2656 [==============================] - 0s 100us/step - loss: -8.8143e-04 - accuracy: 0.9917\n",
            "At the end of episode 2489 the total reward was : -15.0\n",
            "Epoch 1/1\n",
            "2433/2433 [==============================] - 0s 102us/step - loss: -0.0034 - accuracy: 0.9938\n",
            "At the end of episode 2490 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2107/2107 [==============================] - 0s 110us/step - loss: -0.0015 - accuracy: 0.9919\n",
            "At the end of episode 2491 the total reward was : -16.0\n",
            "Epoch 1/1\n",
            "2258/2258 [==============================] - 0s 101us/step - loss: -0.0010 - accuracy: 0.9920\n",
            "At the end of episode 2492 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "2832/2832 [==============================] - 0s 105us/step - loss: -0.0025 - accuracy: 0.9891\n",
            "At the end of episode 2493 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "1925/1925 [==============================] - 0s 102us/step - loss: 0.0044 - accuracy: 0.9922\n",
            "At the end of episode 2494 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "2412/2412 [==============================] - 0s 105us/step - loss: 0.0025 - accuracy: 0.9909\n",
            "At the end of episode 2495 the total reward was : -14.0\n",
            "Epoch 1/1\n",
            "3063/3063 [==============================] - 0s 102us/step - loss: 5.4641e-04 - accuracy: 0.9905\n",
            "At the end of episode 2496 the total reward was : -13.0\n",
            "Epoch 1/1\n",
            "3094/3094 [==============================] - 0s 105us/step - loss: -0.0056 - accuracy: 0.9893\n",
            "At the end of episode 2497 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "2365/2365 [==============================] - 0s 102us/step - loss: -0.0077 - accuracy: 0.9903\n",
            "At the end of episode 2498 the total reward was : -14.0\n",
            "Epoch 1/1\n",
            "2386/2386 [==============================] - 0s 107us/step - loss: -0.0026 - accuracy: 0.9946\n",
            "At the end of episode 2499 the total reward was : -18.0\n",
            "Epoch 1/1\n",
            "2605/2605 [==============================] - 0s 114us/step - loss: -0.0106 - accuracy: 0.9885\n",
            "At the end of episode 2500 the total reward was : -18.0\n",
            "Epoch 1/1\n",
            "2825/2825 [==============================] - 0s 103us/step - loss: -0.0056 - accuracy: 0.9837\n",
            "At the end of episode 2501 the total reward was : -16.0\n",
            "Epoch 1/1\n",
            "2459/2459 [==============================] - 0s 105us/step - loss: 0.0087 - accuracy: 0.9911\n",
            "At the end of episode 2502 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "3061/3061 [==============================] - 0s 104us/step - loss: 0.0030 - accuracy: 0.9863\n",
            "At the end of episode 2503 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "2989/2989 [==============================] - 0s 100us/step - loss: -0.0073 - accuracy: 0.9916\n",
            "At the end of episode 2504 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "2816/2816 [==============================] - 0s 105us/step - loss: 7.7681e-05 - accuracy: 0.9904\n",
            "At the end of episode 2505 the total reward was : -15.0\n",
            "Epoch 1/1\n",
            "2888/2888 [==============================] - 0s 104us/step - loss: 0.0017 - accuracy: 0.9931\n",
            "At the end of episode 2506 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "2714/2714 [==============================] - 0s 103us/step - loss: 4.6024e-04 - accuracy: 0.9937\n",
            "At the end of episode 2507 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2624/2624 [==============================] - 0s 106us/step - loss: 9.2779e-04 - accuracy: 0.9916\n",
            "At the end of episode 2508 the total reward was : -13.0\n",
            "Epoch 1/1\n",
            "3741/3741 [==============================] - 0s 108us/step - loss: -0.0050 - accuracy: 0.9890\n",
            "At the end of episode 2509 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "2590/2590 [==============================] - 0s 101us/step - loss: -0.0104 - accuracy: 0.9892\n",
            "At the end of episode 2510 the total reward was : -16.0\n",
            "Epoch 1/1\n",
            "2705/2705 [==============================] - 0s 102us/step - loss: 0.0015 - accuracy: 0.9933\n",
            "At the end of episode 2511 the total reward was : -15.0\n",
            "Epoch 1/1\n",
            "3020/3020 [==============================] - 0s 106us/step - loss: 0.0045 - accuracy: 0.9881\n",
            "At the end of episode 2512 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "2767/2767 [==============================] - 0s 105us/step - loss: 0.0110 - accuracy: 0.9877\n",
            "At the end of episode 2513 the total reward was : -16.0\n",
            "Epoch 1/1\n",
            "2952/2952 [==============================] - 0s 108us/step - loss: 1.0502e-04 - accuracy: 0.9868\n",
            "At the end of episode 2514 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2560/2560 [==============================] - 0s 106us/step - loss: 0.0028 - accuracy: 0.9910\n",
            "At the end of episode 2515 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "3059/3059 [==============================] - 0s 101us/step - loss: -7.5593e-04 - accuracy: 0.9908\n",
            "At the end of episode 2516 the total reward was : -15.0\n",
            "Epoch 1/1\n",
            "2934/2934 [==============================] - 0s 106us/step - loss: 0.0029 - accuracy: 0.9874\n",
            "At the end of episode 2517 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "2745/2745 [==============================] - 0s 107us/step - loss: -0.0033 - accuracy: 0.9920\n",
            "At the end of episode 2518 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2977/2977 [==============================] - 0s 102us/step - loss: -0.0012 - accuracy: 0.9896\n",
            "At the end of episode 2519 the total reward was : -21.0\n",
            "Epoch 1/1\n",
            "2441/2441 [==============================] - 0s 101us/step - loss: -0.0023 - accuracy: 0.9926\n",
            "At the end of episode 2520 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2591/2591 [==============================] - 0s 106us/step - loss: -0.0058 - accuracy: 0.9915\n",
            "At the end of episode 2521 the total reward was : -15.0\n",
            "Epoch 1/1\n",
            "2847/2847 [==============================] - 0s 101us/step - loss: -0.0067 - accuracy: 0.9902\n",
            "At the end of episode 2522 the total reward was : -21.0\n",
            "Epoch 1/1\n",
            "2885/2885 [==============================] - 0s 101us/step - loss: 0.0030 - accuracy: 0.9906\n",
            "At the end of episode 2523 the total reward was : -18.0\n",
            "Epoch 1/1\n",
            "3761/3761 [==============================] - 0s 109us/step - loss: 0.0096 - accuracy: 0.9910\n",
            "At the end of episode 2524 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "3299/3299 [==============================] - 0s 107us/step - loss: -0.0044 - accuracy: 0.9909\n",
            "At the end of episode 2525 the total reward was : -15.0\n",
            "Epoch 1/1\n",
            "3100/3100 [==============================] - 0s 100us/step - loss: -0.0025 - accuracy: 0.9916\n",
            "At the end of episode 2526 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2716/2716 [==============================] - 0s 101us/step - loss: 0.0055 - accuracy: 0.9912\n",
            "At the end of episode 2527 the total reward was : -16.0\n",
            "Epoch 1/1\n",
            "2886/2886 [==============================] - 0s 104us/step - loss: 0.0096 - accuracy: 0.9893\n",
            "At the end of episode 2528 the total reward was : -15.0\n",
            "Epoch 1/1\n",
            "3093/3093 [==============================] - 0s 102us/step - loss: -0.0035 - accuracy: 0.9958\n",
            "At the end of episode 2529 the total reward was : -15.0\n",
            "Epoch 1/1\n",
            "3016/3016 [==============================] - 0s 102us/step - loss: 0.0158 - accuracy: 0.9857\n",
            "At the end of episode 2530 the total reward was : -18.0\n",
            "Epoch 1/1\n",
            "3183/3183 [==============================] - 0s 103us/step - loss: -0.0059 - accuracy: 0.9796\n",
            "At the end of episode 2531 the total reward was : -18.0\n",
            "Epoch 1/1\n",
            "3020/3020 [==============================] - 0s 107us/step - loss: 0.0012 - accuracy: 0.9940\n",
            "At the end of episode 2532 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "3067/3067 [==============================] - 0s 104us/step - loss: -0.0069 - accuracy: 0.9915\n",
            "At the end of episode 2533 the total reward was : -15.0\n",
            "Epoch 1/1\n",
            "2683/2683 [==============================] - 0s 104us/step - loss: -0.0022 - accuracy: 0.9888\n",
            "At the end of episode 2534 the total reward was : -20.0\n",
            "Epoch 1/1\n",
            "2456/2456 [==============================] - 0s 106us/step - loss: -0.0138 - accuracy: 0.9849\n",
            "At the end of episode 2535 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "2837/2837 [==============================] - 0s 109us/step - loss: -0.0023 - accuracy: 0.9926\n",
            "At the end of episode 2536 the total reward was : -21.0\n",
            "Epoch 1/1\n",
            "1841/1841 [==============================] - 0s 109us/step - loss: -0.0072 - accuracy: 0.9908\n",
            "At the end of episode 2537 the total reward was : -13.0\n",
            "Epoch 1/1\n",
            "3179/3179 [==============================] - 0s 105us/step - loss: -0.0028 - accuracy: 0.9858\n",
            "At the end of episode 2538 the total reward was : -15.0\n",
            "Epoch 1/1\n",
            "3010/3010 [==============================] - 0s 105us/step - loss: 0.0073 - accuracy: 0.9867\n",
            "At the end of episode 2539 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "2971/2971 [==============================] - 0s 105us/step - loss: -0.0143 - accuracy: 0.9875\n",
            "At the end of episode 2540 the total reward was : -20.0\n",
            "Epoch 1/1\n",
            "2286/2286 [==============================] - 0s 105us/step - loss: -4.4788e-04 - accuracy: 0.9926\n",
            "At the end of episode 2541 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2723/2723 [==============================] - 0s 108us/step - loss: -7.9692e-04 - accuracy: 0.9901\n",
            "At the end of episode 2542 the total reward was : -16.0\n",
            "Epoch 1/1\n",
            "2464/2464 [==============================] - 0s 109us/step - loss: 0.0063 - accuracy: 0.9870\n",
            "At the end of episode 2543 the total reward was : -14.0\n",
            "Epoch 1/1\n",
            "3201/3201 [==============================] - 0s 103us/step - loss: -0.0014 - accuracy: 0.9919\n",
            "At the end of episode 2544 the total reward was : -15.0\n",
            "Epoch 1/1\n",
            "2754/2754 [==============================] - 0s 101us/step - loss: -0.0018 - accuracy: 0.9931\n",
            "At the end of episode 2545 the total reward was : -16.0\n",
            "Epoch 1/1\n",
            "2945/2945 [==============================] - 0s 103us/step - loss: 0.0032 - accuracy: 0.9912\n",
            "At the end of episode 2546 the total reward was : -15.0\n",
            "Epoch 1/1\n",
            "3041/3041 [==============================] - 0s 104us/step - loss: -0.0087 - accuracy: 0.9878\n",
            "At the end of episode 2547 the total reward was : -15.0\n",
            "Epoch 1/1\n",
            "3503/3503 [==============================] - 0s 108us/step - loss: 0.0030 - accuracy: 0.9894\n",
            "At the end of episode 2548 the total reward was : -15.0\n",
            "Epoch 1/1\n",
            "2617/2617 [==============================] - 0s 104us/step - loss: 0.0041 - accuracy: 0.9935\n",
            "At the end of episode 2549 the total reward was : -18.0\n",
            "Epoch 1/1\n",
            "2913/2913 [==============================] - 0s 112us/step - loss: 0.0044 - accuracy: 0.9890\n",
            "At the end of episode 2550 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "3070/3070 [==============================] - 0s 100us/step - loss: 0.0017 - accuracy: 0.9922\n",
            "At the end of episode 2551 the total reward was : -12.0\n",
            "Epoch 1/1\n",
            "3177/3177 [==============================] - 0s 105us/step - loss: 0.0072 - accuracy: 0.9896\n",
            "At the end of episode 2552 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2892/2892 [==============================] - 0s 108us/step - loss: -0.0013 - accuracy: 0.9945\n",
            "At the end of episode 2553 the total reward was : -20.0\n",
            "Epoch 1/1\n",
            "2943/2943 [==============================] - 0s 105us/step - loss: -0.0018 - accuracy: 0.9898\n",
            "At the end of episode 2554 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "3187/3187 [==============================] - 0s 110us/step - loss: -0.0024 - accuracy: 0.9890\n",
            "At the end of episode 2555 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2560/2560 [==============================] - 0s 109us/step - loss: -1.0413e-04 - accuracy: 0.9953\n",
            "At the end of episode 2556 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2902/2902 [==============================] - 0s 101us/step - loss: -0.0032 - accuracy: 0.9910\n",
            "At the end of episode 2557 the total reward was : -18.0\n",
            "Epoch 1/1\n",
            "3109/3109 [==============================] - 0s 106us/step - loss: -3.6854e-04 - accuracy: 0.9945\n",
            "At the end of episode 2558 the total reward was : -20.0\n",
            "Epoch 1/1\n",
            "2215/2215 [==============================] - 0s 103us/step - loss: -0.0012 - accuracy: 0.9901\n",
            "At the end of episode 2559 the total reward was : -16.0\n",
            "Epoch 1/1\n",
            "3142/3142 [==============================] - 0s 106us/step - loss: -0.0018 - accuracy: 0.9895\n",
            "At the end of episode 2560 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "2997/2997 [==============================] - 0s 108us/step - loss: 0.0014 - accuracy: 0.9943\n",
            "At the end of episode 2561 the total reward was : -16.0\n",
            "Epoch 1/1\n",
            "2961/2961 [==============================] - 0s 101us/step - loss: -0.0075 - accuracy: 0.9882\n",
            "At the end of episode 2562 the total reward was : -20.0\n",
            "Epoch 1/1\n",
            "2847/2847 [==============================] - 0s 104us/step - loss: 0.0017 - accuracy: 0.9923\n",
            "At the end of episode 2563 the total reward was : -13.0\n",
            "Epoch 1/1\n",
            "3417/3417 [==============================] - 0s 108us/step - loss: 0.0019 - accuracy: 0.9892\n",
            "At the end of episode 2564 the total reward was : -18.0\n",
            "Epoch 1/1\n",
            "2287/2287 [==============================] - 0s 110us/step - loss: 0.0014 - accuracy: 0.9860\n",
            "At the end of episode 2565 the total reward was : -16.0\n",
            "Epoch 1/1\n",
            "3358/3358 [==============================] - 0s 104us/step - loss: -0.0027 - accuracy: 0.9902\n",
            "At the end of episode 2566 the total reward was : -15.0\n",
            "Epoch 1/1\n",
            "3028/3028 [==============================] - 0s 112us/step - loss: 0.0012 - accuracy: 0.9914\n",
            "At the end of episode 2567 the total reward was : -16.0\n",
            "Epoch 1/1\n",
            "3609/3609 [==============================] - 0s 106us/step - loss: -0.0038 - accuracy: 0.9884\n",
            "At the end of episode 2568 the total reward was : -16.0\n",
            "Epoch 1/1\n",
            "3241/3241 [==============================] - 0s 104us/step - loss: -0.0020 - accuracy: 0.9914\n",
            "At the end of episode 2569 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "2749/2749 [==============================] - 0s 101us/step - loss: -0.0017 - accuracy: 0.9858\n",
            "At the end of episode 2570 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "2393/2393 [==============================] - 0s 102us/step - loss: 0.0124 - accuracy: 0.9896\n",
            "At the end of episode 2571 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "3540/3540 [==============================] - 0s 105us/step - loss: -0.0147 - accuracy: 0.9862\n",
            "At the end of episode 2572 the total reward was : -21.0\n",
            "Epoch 1/1\n",
            "3214/3214 [==============================] - 0s 105us/step - loss: 0.0069 - accuracy: 0.9894\n",
            "At the end of episode 2573 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "3487/3487 [==============================] - 0s 101us/step - loss: 0.0034 - accuracy: 0.9894\n",
            "At the end of episode 2574 the total reward was : -16.0\n",
            "Epoch 1/1\n",
            "3268/3268 [==============================] - 0s 101us/step - loss: -0.0059 - accuracy: 0.9930\n",
            "At the end of episode 2575 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "3040/3040 [==============================] - 0s 101us/step - loss: -2.2692e-04 - accuracy: 0.9928\n",
            "At the end of episode 2576 the total reward was : -20.0\n",
            "Epoch 1/1\n",
            "2534/2534 [==============================] - 0s 102us/step - loss: -0.0068 - accuracy: 0.9886\n",
            "At the end of episode 2577 the total reward was : -14.0\n",
            "Epoch 1/1\n",
            "3864/3864 [==============================] - 0s 107us/step - loss: 0.0048 - accuracy: 0.9896\n",
            "At the end of episode 2578 the total reward was : -15.0\n",
            "Epoch 1/1\n",
            "3218/3218 [==============================] - 0s 106us/step - loss: -0.0027 - accuracy: 0.9953\n",
            "At the end of episode 2579 the total reward was : -18.0\n",
            "Epoch 1/1\n",
            "2631/2631 [==============================] - 0s 108us/step - loss: -0.0018 - accuracy: 0.9954\n",
            "At the end of episode 2580 the total reward was : -18.0\n",
            "Epoch 1/1\n",
            "3259/3259 [==============================] - 0s 102us/step - loss: 3.8168e-04 - accuracy: 0.9960\n",
            "At the end of episode 2581 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "3226/3226 [==============================] - 0s 106us/step - loss: -3.9205e-04 - accuracy: 0.9944\n",
            "At the end of episode 2582 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "3360/3360 [==============================] - 0s 107us/step - loss: 0.0014 - accuracy: 0.9952\n",
            "At the end of episode 2583 the total reward was : -15.0\n",
            "Epoch 1/1\n",
            "2856/2856 [==============================] - 0s 103us/step - loss: 0.0041 - accuracy: 0.9933\n",
            "At the end of episode 2584 the total reward was : -14.0\n",
            "Epoch 1/1\n",
            "3389/3389 [==============================] - 0s 104us/step - loss: -6.3733e-04 - accuracy: 0.9911\n",
            "At the end of episode 2585 the total reward was : -18.0\n",
            "Epoch 1/1\n",
            "3036/3036 [==============================] - 0s 105us/step - loss: -0.0041 - accuracy: 0.9862\n",
            "At the end of episode 2586 the total reward was : -14.0\n",
            "Epoch 1/1\n",
            "3397/3397 [==============================] - 0s 105us/step - loss: 0.0047 - accuracy: 0.9832\n",
            "At the end of episode 2587 the total reward was : -18.0\n",
            "Epoch 1/1\n",
            "2541/2541 [==============================] - 0s 112us/step - loss: -0.0055 - accuracy: 0.9898\n",
            "At the end of episode 2588 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "3373/3373 [==============================] - 0s 108us/step - loss: -0.0042 - accuracy: 0.9914\n",
            "At the end of episode 2589 the total reward was : -16.0\n",
            "Epoch 1/1\n",
            "2942/2942 [==============================] - 0s 103us/step - loss: 8.3223e-04 - accuracy: 0.9929\n",
            "At the end of episode 2590 the total reward was : -16.0\n",
            "Epoch 1/1\n",
            "3263/3263 [==============================] - 0s 102us/step - loss: -0.0018 - accuracy: 0.9896\n",
            "At the end of episode 2591 the total reward was : -16.0\n",
            "Epoch 1/1\n",
            "3037/3037 [==============================] - 0s 103us/step - loss: -0.0036 - accuracy: 0.9895\n",
            "At the end of episode 2592 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "3081/3081 [==============================] - 0s 103us/step - loss: -0.0027 - accuracy: 0.9942\n",
            "At the end of episode 2593 the total reward was : -20.0\n",
            "Epoch 1/1\n",
            "2831/2831 [==============================] - 0s 101us/step - loss: 0.0075 - accuracy: 0.9915\n",
            "At the end of episode 2594 the total reward was : -15.0\n",
            "Epoch 1/1\n",
            "3270/3270 [==============================] - 0s 101us/step - loss: -0.0023 - accuracy: 0.9865\n",
            "At the end of episode 2595 the total reward was : -13.0\n",
            "Epoch 1/1\n",
            "3408/3408 [==============================] - 0s 101us/step - loss: -0.0049 - accuracy: 0.9886\n",
            "At the end of episode 2596 the total reward was : -18.0\n",
            "Epoch 1/1\n",
            "2771/2771 [==============================] - 0s 103us/step - loss: 0.0028 - accuracy: 0.9848\n",
            "At the end of episode 2597 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2721/2721 [==============================] - 0s 104us/step - loss: -0.0208 - accuracy: 0.9868\n",
            "At the end of episode 2598 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "3079/3079 [==============================] - 0s 105us/step - loss: -0.0050 - accuracy: 0.9929\n",
            "At the end of episode 2599 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "3551/3551 [==============================] - 0s 109us/step - loss: 0.0044 - accuracy: 0.9879\n",
            "At the end of episode 2600 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "2753/2753 [==============================] - 0s 102us/step - loss: -0.0176 - accuracy: 0.9891\n",
            "At the end of episode 2601 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "2892/2892 [==============================] - 0s 101us/step - loss: -0.0152 - accuracy: 0.9865\n",
            "At the end of episode 2602 the total reward was : -16.0\n",
            "Epoch 1/1\n",
            "3025/3025 [==============================] - 0s 105us/step - loss: -0.0062 - accuracy: 0.9924\n",
            "At the end of episode 2603 the total reward was : -18.0\n",
            "Epoch 1/1\n",
            "3207/3207 [==============================] - 0s 102us/step - loss: 0.0064 - accuracy: 0.9922\n",
            "At the end of episode 2604 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "2687/2687 [==============================] - 0s 109us/step - loss: -0.0055 - accuracy: 0.9933\n",
            "At the end of episode 2605 the total reward was : -15.0\n",
            "Epoch 1/1\n",
            "3169/3169 [==============================] - 0s 104us/step - loss: 0.0021 - accuracy: 0.9943\n",
            "At the end of episode 2606 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "1753/1753 [==============================] - 0s 103us/step - loss: -0.0021 - accuracy: 0.9914\n",
            "At the end of episode 2607 the total reward was : -16.0\n",
            "Epoch 1/1\n",
            "2890/2890 [==============================] - 0s 105us/step - loss: 0.0035 - accuracy: 0.9927\n",
            "At the end of episode 2608 the total reward was : -15.0\n",
            "Epoch 1/1\n",
            "3080/3080 [==============================] - 0s 111us/step - loss: -0.0018 - accuracy: 0.9916\n",
            "At the end of episode 2609 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2651/2651 [==============================] - 0s 112us/step - loss: -0.0031 - accuracy: 0.9898\n",
            "At the end of episode 2610 the total reward was : -16.0\n",
            "Epoch 1/1\n",
            "2794/2794 [==============================] - 0s 105us/step - loss: 0.0058 - accuracy: 0.9921\n",
            "At the end of episode 2611 the total reward was : -20.0\n",
            "Epoch 1/1\n",
            "2203/2203 [==============================] - 0s 101us/step - loss: 7.0467e-04 - accuracy: 0.9946\n",
            "At the end of episode 2612 the total reward was : -16.0\n",
            "Epoch 1/1\n",
            "2642/2642 [==============================] - 0s 100us/step - loss: -0.0054 - accuracy: 0.9917\n",
            "At the end of episode 2613 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2823/2823 [==============================] - 0s 102us/step - loss: 0.0086 - accuracy: 0.9936\n",
            "At the end of episode 2614 the total reward was : -15.0\n",
            "Epoch 1/1\n",
            "2920/2920 [==============================] - 0s 110us/step - loss: 0.0015 - accuracy: 0.9928\n",
            "At the end of episode 2615 the total reward was : -16.0\n",
            "Epoch 1/1\n",
            "3279/3279 [==============================] - 0s 103us/step - loss: 0.0082 - accuracy: 0.9927\n",
            "At the end of episode 2616 the total reward was : -18.0\n",
            "Epoch 1/1\n",
            "2771/2771 [==============================] - 0s 100us/step - loss: -0.0046 - accuracy: 0.9910\n",
            "At the end of episode 2617 the total reward was : -12.0\n",
            "Epoch 1/1\n",
            "2724/2724 [==============================] - 0s 101us/step - loss: -0.0076 - accuracy: 0.9912\n",
            "At the end of episode 2618 the total reward was : -18.0\n",
            "Epoch 1/1\n",
            "3206/3206 [==============================] - 0s 105us/step - loss: -0.0010 - accuracy: 0.9928\n",
            "At the end of episode 2619 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "3076/3076 [==============================] - 0s 105us/step - loss: -0.0104 - accuracy: 0.9893\n",
            "At the end of episode 2620 the total reward was : -13.0\n",
            "Epoch 1/1\n",
            "2932/2932 [==============================] - 0s 103us/step - loss: -7.4636e-04 - accuracy: 0.9918\n",
            "At the end of episode 2621 the total reward was : -15.0\n",
            "Epoch 1/1\n",
            "3115/3115 [==============================] - 0s 104us/step - loss: -2.0158e-04 - accuracy: 0.9917\n",
            "At the end of episode 2622 the total reward was : -15.0\n",
            "Epoch 1/1\n",
            "3466/3466 [==============================] - 0s 107us/step - loss: 0.0045 - accuracy: 0.9908\n",
            "At the end of episode 2623 the total reward was : -18.0\n",
            "Epoch 1/1\n",
            "3176/3176 [==============================] - 0s 102us/step - loss: -0.0021 - accuracy: 0.9934\n",
            "At the end of episode 2624 the total reward was : -16.0\n",
            "Epoch 1/1\n",
            "2794/2794 [==============================] - 0s 108us/step - loss: -5.4872e-04 - accuracy: 0.9918\n",
            "At the end of episode 2625 the total reward was : -18.0\n",
            "Epoch 1/1\n",
            "3260/3260 [==============================] - 0s 101us/step - loss: -0.0020 - accuracy: 0.9896\n",
            "At the end of episode 2626 the total reward was : -16.0\n",
            "Epoch 1/1\n",
            "2802/2802 [==============================] - 0s 110us/step - loss: 0.0066 - accuracy: 0.9900\n",
            "At the end of episode 2627 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "2757/2757 [==============================] - 0s 106us/step - loss: -0.0022 - accuracy: 0.9946\n",
            "At the end of episode 2628 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "2810/2810 [==============================] - 0s 100us/step - loss: 0.0041 - accuracy: 0.9904\n",
            "At the end of episode 2629 the total reward was : -16.0\n",
            "Epoch 1/1\n",
            "3210/3210 [==============================] - 0s 105us/step - loss: 6.9368e-04 - accuracy: 0.9938\n",
            "At the end of episode 2630 the total reward was : -14.0\n",
            "Epoch 1/1\n",
            "3287/3287 [==============================] - 0s 108us/step - loss: -0.0023 - accuracy: 0.9939\n",
            "At the end of episode 2631 the total reward was : -16.0\n",
            "Epoch 1/1\n",
            "2684/2684 [==============================] - 0s 102us/step - loss: -0.0072 - accuracy: 0.9918\n",
            "At the end of episode 2632 the total reward was : -13.0\n",
            "Epoch 1/1\n",
            "3448/3448 [==============================] - 0s 100us/step - loss: -0.0021 - accuracy: 0.9933\n",
            "At the end of episode 2633 the total reward was : -15.0\n",
            "Epoch 1/1\n",
            "2857/2857 [==============================] - 0s 111us/step - loss: 0.0107 - accuracy: 0.9926\n",
            "At the end of episode 2634 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "3213/3213 [==============================] - 0s 100us/step - loss: -0.0038 - accuracy: 0.9900\n",
            "At the end of episode 2635 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2233/2233 [==============================] - 0s 101us/step - loss: 0.0012 - accuracy: 0.9942\n",
            "At the end of episode 2636 the total reward was : -16.0\n",
            "Epoch 1/1\n",
            "3217/3217 [==============================] - 0s 105us/step - loss: 0.0048 - accuracy: 0.9910\n",
            "At the end of episode 2637 the total reward was : -16.0\n",
            "Epoch 1/1\n",
            "3737/3737 [==============================] - 0s 107us/step - loss: 0.0030 - accuracy: 0.9888\n",
            "At the end of episode 2638 the total reward was : -15.0\n",
            "Epoch 1/1\n",
            "3734/3734 [==============================] - 0s 108us/step - loss: 0.0060 - accuracy: 0.9901\n",
            "At the end of episode 2639 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "3066/3066 [==============================] - 0s 101us/step - loss: 7.3155e-04 - accuracy: 0.9876\n",
            "At the end of episode 2640 the total reward was : -13.0\n",
            "Epoch 1/1\n",
            "3105/3105 [==============================] - 0s 107us/step - loss: 0.0106 - accuracy: 0.9932\n",
            "At the end of episode 2641 the total reward was : -16.0\n",
            "Epoch 1/1\n",
            "2871/2871 [==============================] - 0s 101us/step - loss: -0.0036 - accuracy: 0.9937\n",
            "At the end of episode 2642 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "3656/3656 [==============================] - 0s 105us/step - loss: 0.0115 - accuracy: 0.9926\n",
            "At the end of episode 2643 the total reward was : -15.0\n",
            "Epoch 1/1\n",
            "3135/3135 [==============================] - 0s 105us/step - loss: -0.0040 - accuracy: 0.9917\n",
            "At the end of episode 2644 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "3318/3318 [==============================] - 0s 102us/step - loss: -0.0024 - accuracy: 0.9895\n",
            "At the end of episode 2645 the total reward was : -10.0\n",
            "Epoch 1/1\n",
            "4040/4040 [==============================] - 0s 108us/step - loss: 0.0036 - accuracy: 0.9891\n",
            "At the end of episode 2646 the total reward was : -18.0\n",
            "Epoch 1/1\n",
            "2542/2542 [==============================] - 0s 100us/step - loss: 0.0073 - accuracy: 0.9929\n",
            "At the end of episode 2647 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "3077/3077 [==============================] - 0s 106us/step - loss: -4.4918e-04 - accuracy: 0.9854\n",
            "At the end of episode 2648 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "2962/2962 [==============================] - 0s 101us/step - loss: 0.0024 - accuracy: 0.9909\n",
            "At the end of episode 2649 the total reward was : -12.0\n",
            "Epoch 1/1\n",
            "3058/3058 [==============================] - 0s 106us/step - loss: -0.0085 - accuracy: 0.9905\n",
            "At the end of episode 2650 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "2913/2913 [==============================] - 0s 103us/step - loss: 0.0059 - accuracy: 0.9942\n",
            "At the end of episode 2651 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "2493/2493 [==============================] - 0s 100us/step - loss: 5.5091e-04 - accuracy: 0.9956\n",
            "At the end of episode 2652 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "2915/2915 [==============================] - 0s 108us/step - loss: 0.0061 - accuracy: 0.9877\n",
            "At the end of episode 2653 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "3394/3394 [==============================] - 0s 107us/step - loss: 0.0011 - accuracy: 0.9844\n",
            "At the end of episode 2654 the total reward was : -21.0\n",
            "Epoch 1/1\n",
            "3278/3278 [==============================] - 0s 107us/step - loss: -0.0014 - accuracy: 0.9927\n",
            "At the end of episode 2655 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "3047/3047 [==============================] - 0s 101us/step - loss: 0.0030 - accuracy: 0.9911\n",
            "At the end of episode 2656 the total reward was : -21.0\n",
            "Epoch 1/1\n",
            "2953/2953 [==============================] - 0s 109us/step - loss: -8.8582e-04 - accuracy: 0.9936\n",
            "At the end of episode 2657 the total reward was : -14.0\n",
            "Epoch 1/1\n",
            "2958/2958 [==============================] - 0s 104us/step - loss: -0.0018 - accuracy: 0.9943\n",
            "At the end of episode 2658 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "2662/2662 [==============================] - 0s 103us/step - loss: 6.6799e-04 - accuracy: 0.9902\n",
            "At the end of episode 2659 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "3071/3071 [==============================] - 0s 101us/step - loss: -0.0063 - accuracy: 0.9906\n",
            "At the end of episode 2660 the total reward was : -15.0\n",
            "Epoch 1/1\n",
            "2364/2364 [==============================] - 0s 103us/step - loss: -4.3269e-04 - accuracy: 0.9907\n",
            "At the end of episode 2661 the total reward was : -18.0\n",
            "Epoch 1/1\n",
            "2497/2497 [==============================] - 0s 107us/step - loss: -0.0011 - accuracy: 0.9944\n",
            "At the end of episode 2662 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "3316/3316 [==============================] - 0s 107us/step - loss: -9.6683e-04 - accuracy: 0.9919\n",
            "At the end of episode 2663 the total reward was : -16.0\n",
            "Epoch 1/1\n",
            "3345/3345 [==============================] - 0s 106us/step - loss: 0.0026 - accuracy: 0.9916\n",
            "At the end of episode 2664 the total reward was : -18.0\n",
            "Epoch 1/1\n",
            "2849/2849 [==============================] - 0s 106us/step - loss: 5.0461e-04 - accuracy: 0.9937\n",
            "At the end of episode 2665 the total reward was : -14.0\n",
            "Epoch 1/1\n",
            "2893/2893 [==============================] - 0s 102us/step - loss: 0.0041 - accuracy: 0.9927\n",
            "At the end of episode 2666 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "2913/2913 [==============================] - 0s 103us/step - loss: 0.0211 - accuracy: 0.9900\n",
            "At the end of episode 2667 the total reward was : -13.0\n",
            "Epoch 1/1\n",
            "3175/3175 [==============================] - 0s 104us/step - loss: -0.0014 - accuracy: 0.9928\n",
            "At the end of episode 2668 the total reward was : -18.0\n",
            "Epoch 1/1\n",
            "2533/2533 [==============================] - 0s 111us/step - loss: 5.0201e-04 - accuracy: 0.9917\n",
            "At the end of episode 2669 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "2495/2495 [==============================] - 0s 101us/step - loss: -0.0075 - accuracy: 0.9916\n",
            "At the end of episode 2670 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "2830/2830 [==============================] - 0s 104us/step - loss: 0.0012 - accuracy: 0.9954\n",
            "At the end of episode 2671 the total reward was : -18.0\n",
            "Epoch 1/1\n",
            "2687/2687 [==============================] - 0s 107us/step - loss: 8.5913e-04 - accuracy: 0.9907\n",
            "At the end of episode 2672 the total reward was : -15.0\n",
            "Epoch 1/1\n",
            "3417/3417 [==============================] - 0s 105us/step - loss: 7.8977e-04 - accuracy: 0.9851\n",
            "At the end of episode 2673 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2390/2390 [==============================] - 0s 101us/step - loss: -0.0140 - accuracy: 0.9870\n",
            "At the end of episode 2674 the total reward was : -15.0\n",
            "Epoch 1/1\n",
            "3399/3399 [==============================] - 0s 101us/step - loss: 0.0041 - accuracy: 0.9891\n",
            "At the end of episode 2675 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "3238/3238 [==============================] - 0s 101us/step - loss: -0.0011 - accuracy: 0.9901\n",
            "At the end of episode 2676 the total reward was : -15.0\n",
            "Epoch 1/1\n",
            "3177/3177 [==============================] - 0s 111us/step - loss: 9.0299e-04 - accuracy: 0.9950\n",
            "At the end of episode 2677 the total reward was : -18.0\n",
            "Epoch 1/1\n",
            "3386/3386 [==============================] - 0s 108us/step - loss: -0.0011 - accuracy: 0.9950\n",
            "At the end of episode 2678 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "2570/2570 [==============================] - 0s 102us/step - loss: -0.0027 - accuracy: 0.9946\n",
            "At the end of episode 2679 the total reward was : -15.0\n",
            "Epoch 1/1\n",
            "3096/3096 [==============================] - 0s 106us/step - loss: 0.0020 - accuracy: 0.9858\n",
            "At the end of episode 2680 the total reward was : -15.0\n",
            "Epoch 1/1\n",
            "2831/2831 [==============================] - 0s 101us/step - loss: -0.0034 - accuracy: 0.9908\n",
            "At the end of episode 2681 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2828/2828 [==============================] - 0s 102us/step - loss: -0.0035 - accuracy: 0.9926\n",
            "At the end of episode 2682 the total reward was : -15.0\n",
            "Epoch 1/1\n",
            "3407/3407 [==============================] - 0s 102us/step - loss: -6.3524e-04 - accuracy: 0.9924\n",
            "At the end of episode 2683 the total reward was : -15.0\n",
            "Epoch 1/1\n",
            "3316/3316 [==============================] - 0s 102us/step - loss: 0.0024 - accuracy: 0.9894\n",
            "At the end of episode 2684 the total reward was : -20.0\n",
            "Epoch 1/1\n",
            "3015/3015 [==============================] - 0s 108us/step - loss: 0.0017 - accuracy: 0.9950\n",
            "At the end of episode 2685 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "3323/3323 [==============================] - 0s 104us/step - loss: -2.6572e-04 - accuracy: 0.9946\n",
            "At the end of episode 2686 the total reward was : -18.0\n",
            "Epoch 1/1\n",
            "2545/2545 [==============================] - 0s 111us/step - loss: -0.0012 - accuracy: 0.9898\n",
            "At the end of episode 2687 the total reward was : -16.0\n",
            "Epoch 1/1\n",
            "3287/3287 [==============================] - 0s 101us/step - loss: 0.0042 - accuracy: 0.9887\n",
            "At the end of episode 2688 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "3193/3193 [==============================] - 0s 107us/step - loss: 0.0018 - accuracy: 0.9894\n",
            "At the end of episode 2689 the total reward was : -15.0\n",
            "Epoch 1/1\n",
            "3600/3600 [==============================] - 0s 109us/step - loss: 0.0022 - accuracy: 0.9903\n",
            "At the end of episode 2690 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2888/2888 [==============================] - 0s 100us/step - loss: -0.0035 - accuracy: 0.9886\n",
            "At the end of episode 2691 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "3392/3392 [==============================] - 0s 101us/step - loss: -0.0112 - accuracy: 0.9856\n",
            "At the end of episode 2692 the total reward was : -16.0\n",
            "Epoch 1/1\n",
            "3339/3339 [==============================] - 0s 102us/step - loss: -0.0019 - accuracy: 0.9898\n",
            "At the end of episode 2693 the total reward was : -16.0\n",
            "Epoch 1/1\n",
            "2863/2863 [==============================] - 0s 109us/step - loss: -0.0023 - accuracy: 0.9944\n",
            "At the end of episode 2694 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2088/2088 [==============================] - 0s 106us/step - loss: -0.0023 - accuracy: 0.9928\n",
            "At the end of episode 2695 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "3255/3255 [==============================] - 0s 108us/step - loss: 0.0037 - accuracy: 0.9929\n",
            "At the end of episode 2696 the total reward was : -18.0\n",
            "Epoch 1/1\n",
            "2535/2535 [==============================] - 0s 103us/step - loss: 0.0048 - accuracy: 0.9929\n",
            "At the end of episode 2697 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2559/2559 [==============================] - 0s 100us/step - loss: -0.0128 - accuracy: 0.9887\n",
            "At the end of episode 2698 the total reward was : -16.0\n",
            "Epoch 1/1\n",
            "3125/3125 [==============================] - 0s 107us/step - loss: 0.0041 - accuracy: 0.9933\n",
            "At the end of episode 2699 the total reward was : -18.0\n",
            "Epoch 1/1\n",
            "2545/2545 [==============================] - 0s 104us/step - loss: -0.0023 - accuracy: 0.9925\n",
            "At the end of episode 2700 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "3489/3489 [==============================] - 0s 110us/step - loss: -0.0140 - accuracy: 0.9877\n",
            "At the end of episode 2701 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "3401/3401 [==============================] - 0s 104us/step - loss: -0.0251 - accuracy: 0.9877\n",
            "At the end of episode 2702 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2597/2597 [==============================] - 0s 108us/step - loss: 0.0039 - accuracy: 0.9911\n",
            "At the end of episode 2703 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "3390/3390 [==============================] - 0s 104us/step - loss: 0.0209 - accuracy: 0.9914\n",
            "At the end of episode 2704 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2871/2871 [==============================] - 0s 107us/step - loss: 0.0078 - accuracy: 0.9902\n",
            "At the end of episode 2705 the total reward was : -14.0\n",
            "Epoch 1/1\n",
            "3053/3053 [==============================] - 0s 102us/step - loss: -0.0100 - accuracy: 0.9895\n",
            "At the end of episode 2706 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "3712/3712 [==============================] - 0s 108us/step - loss: 1.9778e-04 - accuracy: 0.9914\n",
            "At the end of episode 2707 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "2415/2415 [==============================] - 0s 105us/step - loss: -0.0089 - accuracy: 0.9863\n",
            "At the end of episode 2708 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "2432/2432 [==============================] - 0s 102us/step - loss: -7.1943e-04 - accuracy: 0.9901\n",
            "At the end of episode 2709 the total reward was : -16.0\n",
            "Epoch 1/1\n",
            "2882/2882 [==============================] - 0s 105us/step - loss: -0.0039 - accuracy: 0.9896\n",
            "At the end of episode 2710 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "2565/2565 [==============================] - 0s 103us/step - loss: 0.0026 - accuracy: 0.9879\n",
            "At the end of episode 2711 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "2823/2823 [==============================] - 0s 104us/step - loss: 0.0031 - accuracy: 0.9919\n",
            "At the end of episode 2712 the total reward was : -18.0\n",
            "Epoch 1/1\n",
            "2064/2064 [==============================] - 0s 102us/step - loss: 0.0043 - accuracy: 0.9922\n",
            "At the end of episode 2713 the total reward was : -15.0\n",
            "Epoch 1/1\n",
            "3333/3333 [==============================] - 0s 104us/step - loss: 0.0101 - accuracy: 0.9922\n",
            "At the end of episode 2714 the total reward was : -14.0\n",
            "Epoch 1/1\n",
            "3073/3073 [==============================] - 0s 110us/step - loss: 0.0026 - accuracy: 0.9964\n",
            "At the end of episode 2715 the total reward was : -18.0\n",
            "Epoch 1/1\n",
            "2529/2529 [==============================] - 0s 107us/step - loss: 0.0079 - accuracy: 0.9925\n",
            "At the end of episode 2716 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2489/2489 [==============================] - 0s 101us/step - loss: -0.0048 - accuracy: 0.9924\n",
            "At the end of episode 2717 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "2731/2731 [==============================] - 0s 102us/step - loss: 0.0019 - accuracy: 0.9908\n",
            "At the end of episode 2718 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2008/2008 [==============================] - 0s 102us/step - loss: 2.6042e-04 - accuracy: 0.9945\n",
            "At the end of episode 2719 the total reward was : -16.0\n",
            "Epoch 1/1\n",
            "2960/2960 [==============================] - 0s 109us/step - loss: -0.0038 - accuracy: 0.9919\n",
            "At the end of episode 2720 the total reward was : -16.0\n",
            "Epoch 1/1\n",
            "2870/2870 [==============================] - 0s 103us/step - loss: -7.5915e-04 - accuracy: 0.9948\n",
            "At the end of episode 2721 the total reward was : -20.0\n",
            "Epoch 1/1\n",
            "3155/3155 [==============================] - 0s 106us/step - loss: -0.0028 - accuracy: 0.9933\n",
            "At the end of episode 2722 the total reward was : -15.0\n",
            "Epoch 1/1\n",
            "2737/2737 [==============================] - 0s 103us/step - loss: 0.0018 - accuracy: 0.9945\n",
            "At the end of episode 2723 the total reward was : -20.0\n",
            "Epoch 1/1\n",
            "2449/2449 [==============================] - 0s 104us/step - loss: -0.0027 - accuracy: 0.9914\n",
            "At the end of episode 2724 the total reward was : -15.0\n",
            "Epoch 1/1\n",
            "3611/3611 [==============================] - 0s 106us/step - loss: 0.0014 - accuracy: 0.9867\n",
            "At the end of episode 2725 the total reward was : -16.0\n",
            "Epoch 1/1\n",
            "3120/3120 [==============================] - 0s 104us/step - loss: 0.0018 - accuracy: 0.9881\n",
            "At the end of episode 2726 the total reward was : -21.0\n",
            "Epoch 1/1\n",
            "2395/2395 [==============================] - 0s 104us/step - loss: 0.0011 - accuracy: 0.9900\n",
            "At the end of episode 2727 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "3353/3353 [==============================] - 0s 102us/step - loss: -0.0090 - accuracy: 0.9919\n",
            "At the end of episode 2728 the total reward was : -16.0\n",
            "Epoch 1/1\n",
            "2453/2453 [==============================] - 0s 103us/step - loss: -0.0021 - accuracy: 0.9927\n",
            "At the end of episode 2729 the total reward was : -18.0\n",
            "Epoch 1/1\n",
            "2523/2523 [==============================] - 0s 102us/step - loss: 0.0078 - accuracy: 0.9929\n",
            "At the end of episode 2730 the total reward was : -16.0\n",
            "Epoch 1/1\n",
            "2491/2491 [==============================] - 0s 109us/step - loss: 0.0020 - accuracy: 0.9932\n",
            "At the end of episode 2731 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2665/2665 [==============================] - 0s 107us/step - loss: 0.0010 - accuracy: 0.9944\n",
            "At the end of episode 2732 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "3212/3212 [==============================] - 0s 104us/step - loss: -0.0111 - accuracy: 0.9903\n",
            "At the end of episode 2733 the total reward was : -14.0\n",
            "Epoch 1/1\n",
            "3323/3323 [==============================] - 0s 101us/step - loss: 0.0023 - accuracy: 0.9880\n",
            "At the end of episode 2734 the total reward was : -16.0\n",
            "Epoch 1/1\n",
            "2931/2931 [==============================] - 0s 107us/step - loss: -0.0041 - accuracy: 0.9942\n",
            "At the end of episode 2735 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "3226/3226 [==============================] - 0s 101us/step - loss: 0.0036 - accuracy: 0.9923\n",
            "At the end of episode 2736 the total reward was : -16.0\n",
            "Epoch 1/1\n",
            "2867/2867 [==============================] - 0s 111us/step - loss: -0.0045 - accuracy: 0.9902\n",
            "At the end of episode 2737 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2730/2730 [==============================] - 0s 105us/step - loss: 0.0023 - accuracy: 0.9908\n",
            "At the end of episode 2738 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2669/2669 [==============================] - 0s 107us/step - loss: -0.0030 - accuracy: 0.9951\n",
            "At the end of episode 2739 the total reward was : -21.0\n",
            "Epoch 1/1\n",
            "2350/2350 [==============================] - 0s 103us/step - loss: 0.0018 - accuracy: 0.9945\n",
            "At the end of episode 2740 the total reward was : -15.0\n",
            "Epoch 1/1\n",
            "3464/3464 [==============================] - 0s 106us/step - loss: 0.0016 - accuracy: 0.9974\n",
            "At the end of episode 2741 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "3057/3057 [==============================] - 0s 103us/step - loss: -0.0015 - accuracy: 0.9957\n",
            "At the end of episode 2742 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "3465/3465 [==============================] - 0s 104us/step - loss: 0.0078 - accuracy: 0.9942\n",
            "At the end of episode 2743 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "3242/3242 [==============================] - 0s 104us/step - loss: -0.0043 - accuracy: 0.9923\n",
            "At the end of episode 2744 the total reward was : -21.0\n",
            "Epoch 1/1\n",
            "3036/3036 [==============================] - 0s 103us/step - loss: 7.4117e-04 - accuracy: 0.9951\n",
            "At the end of episode 2745 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "3473/3473 [==============================] - 0s 116us/step - loss: -0.0032 - accuracy: 0.9940\n",
            "At the end of episode 2746 the total reward was : -21.0\n",
            "Epoch 1/1\n",
            "2578/2578 [==============================] - 0s 111us/step - loss: -0.0035 - accuracy: 0.9922\n",
            "At the end of episode 2747 the total reward was : -16.0\n",
            "Epoch 1/1\n",
            "2542/2542 [==============================] - 0s 116us/step - loss: -0.0030 - accuracy: 0.9941\n",
            "At the end of episode 2748 the total reward was : -15.0\n",
            "Epoch 1/1\n",
            "3404/3404 [==============================] - 0s 108us/step - loss: -0.0083 - accuracy: 0.9903\n",
            "At the end of episode 2749 the total reward was : -21.0\n",
            "Epoch 1/1\n",
            "2313/2313 [==============================] - 0s 106us/step - loss: -0.0057 - accuracy: 0.9905\n",
            "At the end of episode 2750 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "2792/2792 [==============================] - 0s 101us/step - loss: -0.0026 - accuracy: 0.9943\n",
            "At the end of episode 2751 the total reward was : -16.0\n",
            "Epoch 1/1\n",
            "3048/3048 [==============================] - 0s 106us/step - loss: 0.0038 - accuracy: 0.9931\n",
            "At the end of episode 2752 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "3079/3079 [==============================] - 0s 103us/step - loss: -7.9306e-04 - accuracy: 0.9958\n",
            "At the end of episode 2753 the total reward was : -18.0\n",
            "Epoch 1/1\n",
            "3094/3094 [==============================] - 0s 105us/step - loss: -0.0116 - accuracy: 0.9887\n",
            "At the end of episode 2754 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2427/2427 [==============================] - 0s 116us/step - loss: -6.8488e-04 - accuracy: 0.9934\n",
            "At the end of episode 2755 the total reward was : -13.0\n",
            "Epoch 1/1\n",
            "3660/3660 [==============================] - 0s 107us/step - loss: -0.0047 - accuracy: 0.9934\n",
            "At the end of episode 2756 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "3042/3042 [==============================] - 0s 109us/step - loss: -0.0013 - accuracy: 0.9957\n",
            "At the end of episode 2757 the total reward was : -18.0\n",
            "Epoch 1/1\n",
            "2762/2762 [==============================] - 0s 107us/step - loss: 8.5491e-05 - accuracy: 0.9964\n",
            "At the end of episode 2758 the total reward was : -15.0\n",
            "Epoch 1/1\n",
            "3567/3567 [==============================] - 0s 104us/step - loss: 0.0076 - accuracy: 0.9857\n",
            "At the end of episode 2759 the total reward was : -18.0\n",
            "Epoch 1/1\n",
            "2607/2607 [==============================] - 0s 103us/step - loss: -0.0010 - accuracy: 0.9896\n",
            "At the end of episode 2760 the total reward was : -16.0\n",
            "Epoch 1/1\n",
            "3114/3114 [==============================] - 0s 105us/step - loss: -0.0018 - accuracy: 0.9955\n",
            "At the end of episode 2761 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2675/2675 [==============================] - 0s 101us/step - loss: 0.0043 - accuracy: 0.9936\n",
            "At the end of episode 2762 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "3114/3114 [==============================] - 0s 108us/step - loss: 0.0032 - accuracy: 0.9933\n",
            "At the end of episode 2763 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "3153/3153 [==============================] - 0s 110us/step - loss: 0.0057 - accuracy: 0.9946\n",
            "At the end of episode 2764 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "3059/3059 [==============================] - 0s 100us/step - loss: 0.0039 - accuracy: 0.9902\n",
            "At the end of episode 2765 the total reward was : -18.0\n",
            "Epoch 1/1\n",
            "2155/2155 [==============================] - 0s 102us/step - loss: -7.5645e-04 - accuracy: 0.9930\n",
            "At the end of episode 2766 the total reward was : -18.0\n",
            "Epoch 1/1\n",
            "3538/3538 [==============================] - 0s 110us/step - loss: -7.3536e-04 - accuracy: 0.9929\n",
            "At the end of episode 2767 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2741/2741 [==============================] - 0s 108us/step - loss: 0.0010 - accuracy: 0.9920\n",
            "At the end of episode 2768 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "3652/3652 [==============================] - 0s 106us/step - loss: -0.0102 - accuracy: 0.9904\n",
            "At the end of episode 2769 the total reward was : -15.0\n",
            "Epoch 1/1\n",
            "4194/4194 [==============================] - 0s 104us/step - loss: 0.0116 - accuracy: 0.9902\n",
            "At the end of episode 2770 the total reward was : -16.0\n",
            "Epoch 1/1\n",
            "2863/2863 [==============================] - 0s 105us/step - loss: -0.0016 - accuracy: 0.9913\n",
            "At the end of episode 2771 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "2328/2328 [==============================] - 0s 101us/step - loss: 0.0080 - accuracy: 0.9936\n",
            "At the end of episode 2772 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2265/2265 [==============================] - 0s 107us/step - loss: -5.9924e-04 - accuracy: 0.9947\n",
            "At the end of episode 2773 the total reward was : -21.0\n",
            "Epoch 1/1\n",
            "2533/2533 [==============================] - 0s 105us/step - loss: 0.0033 - accuracy: 0.9893\n",
            "At the end of episode 2774 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "1677/1677 [==============================] - 0s 105us/step - loss: -9.5979e-04 - accuracy: 0.9946\n",
            "At the end of episode 2775 the total reward was : -16.0\n",
            "Epoch 1/1\n",
            "2490/2490 [==============================] - 0s 102us/step - loss: -0.0027 - accuracy: 0.9916\n",
            "At the end of episode 2776 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "3357/3357 [==============================] - 0s 102us/step - loss: 0.0035 - accuracy: 0.9929\n",
            "At the end of episode 2777 the total reward was : -12.0\n",
            "Epoch 1/1\n",
            "2730/2730 [==============================] - 0s 105us/step - loss: -5.0640e-04 - accuracy: 0.9912\n",
            "At the end of episode 2778 the total reward was : -21.0\n",
            "Epoch 1/1\n",
            "2323/2323 [==============================] - 0s 102us/step - loss: 0.0056 - accuracy: 0.9905\n",
            "At the end of episode 2779 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "3074/3074 [==============================] - 0s 102us/step - loss: 0.0011 - accuracy: 0.9945\n",
            "At the end of episode 2780 the total reward was : -20.0\n",
            "Epoch 1/1\n",
            "2524/2524 [==============================] - 0s 110us/step - loss: -7.6447e-04 - accuracy: 0.9905\n",
            "At the end of episode 2781 the total reward was : -20.0\n",
            "Epoch 1/1\n",
            "2744/2744 [==============================] - 0s 101us/step - loss: 0.0038 - accuracy: 0.9931\n",
            "At the end of episode 2782 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2743/2743 [==============================] - 0s 101us/step - loss: 0.0018 - accuracy: 0.9938\n",
            "At the end of episode 2783 the total reward was : -16.0\n",
            "Epoch 1/1\n",
            "2471/2471 [==============================] - 0s 103us/step - loss: -0.0021 - accuracy: 0.9935\n",
            "At the end of episode 2784 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2960/2960 [==============================] - 0s 102us/step - loss: -0.0066 - accuracy: 0.9834\n",
            "At the end of episode 2785 the total reward was : -18.0\n",
            "Epoch 1/1\n",
            "2108/2108 [==============================] - 0s 101us/step - loss: 3.1771e-05 - accuracy: 0.9943\n",
            "At the end of episode 2786 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "2767/2767 [==============================] - 0s 105us/step - loss: 0.0037 - accuracy: 0.9920\n",
            "At the end of episode 2787 the total reward was : -13.0\n",
            "Epoch 1/1\n",
            "3163/3163 [==============================] - 0s 103us/step - loss: 0.0052 - accuracy: 0.9937\n",
            "At the end of episode 2788 the total reward was : -20.0\n",
            "Epoch 1/1\n",
            "2181/2181 [==============================] - 0s 111us/step - loss: -0.0013 - accuracy: 0.9972\n",
            "At the end of episode 2789 the total reward was : -18.0\n",
            "Epoch 1/1\n",
            "3607/3607 [==============================] - 0s 109us/step - loss: 0.0013 - accuracy: 0.9939\n",
            "At the end of episode 2790 the total reward was : -20.0\n",
            "Epoch 1/1\n",
            "2610/2610 [==============================] - 0s 105us/step - loss: 0.0028 - accuracy: 0.9916\n",
            "At the end of episode 2791 the total reward was : -21.0\n",
            "Epoch 1/1\n",
            "2320/2320 [==============================] - 0s 100us/step - loss: 0.0070 - accuracy: 0.9892\n",
            "At the end of episode 2792 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "2606/2606 [==============================] - 0s 102us/step - loss: 1.1548e-05 - accuracy: 0.9916\n",
            "At the end of episode 2793 the total reward was : -18.0\n",
            "Epoch 1/1\n",
            "2473/2473 [==============================] - 0s 105us/step - loss: -8.3374e-04 - accuracy: 0.9935\n",
            "At the end of episode 2794 the total reward was : -16.0\n",
            "Epoch 1/1\n",
            "2708/2708 [==============================] - 0s 108us/step - loss: -0.0034 - accuracy: 0.9915\n",
            "At the end of episode 2795 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "1997/1997 [==============================] - 0s 109us/step - loss: 9.1755e-04 - accuracy: 0.9920\n",
            "At the end of episode 2796 the total reward was : -20.0\n",
            "Epoch 1/1\n",
            "2598/2598 [==============================] - 0s 103us/step - loss: 0.0011 - accuracy: 0.9954\n",
            "At the end of episode 2797 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "2430/2430 [==============================] - 0s 101us/step - loss: 3.1692e-04 - accuracy: 0.9938\n",
            "At the end of episode 2798 the total reward was : -20.0\n",
            "Epoch 1/1\n",
            "3178/3178 [==============================] - 0s 110us/step - loss: -0.0070 - accuracy: 0.9921\n",
            "At the end of episode 2799 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "2641/2641 [==============================] - 0s 105us/step - loss: -6.9268e-04 - accuracy: 0.9924\n",
            "At the end of episode 2800 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "1937/1937 [==============================] - 0s 102us/step - loss: -4.5762e-04 - accuracy: 0.9969\n",
            "At the end of episode 2801 the total reward was : -20.0\n",
            "Epoch 1/1\n",
            "3022/3022 [==============================] - 0s 104us/step - loss: 0.0013 - accuracy: 0.9937\n",
            "At the end of episode 2802 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "3318/3318 [==============================] - 0s 107us/step - loss: 0.0106 - accuracy: 0.9901\n",
            "At the end of episode 2803 the total reward was : -20.0\n",
            "Epoch 1/1\n",
            "2445/2445 [==============================] - 0s 102us/step - loss: 0.0034 - accuracy: 0.9910\n",
            "At the end of episode 2804 the total reward was : -20.0\n",
            "Epoch 1/1\n",
            "3079/3079 [==============================] - 0s 103us/step - loss: 0.0058 - accuracy: 0.9893\n",
            "At the end of episode 2805 the total reward was : -21.0\n",
            "Epoch 1/1\n",
            "1824/1824 [==============================] - 0s 113us/step - loss: 0.0067 - accuracy: 0.9918\n",
            "At the end of episode 2806 the total reward was : -16.0\n",
            "Epoch 1/1\n",
            "2937/2937 [==============================] - 0s 103us/step - loss: -0.0021 - accuracy: 0.9952\n",
            "At the end of episode 2807 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2666/2666 [==============================] - 0s 102us/step - loss: -0.0026 - accuracy: 0.9940\n",
            "At the end of episode 2808 the total reward was : -18.0\n",
            "Epoch 1/1\n",
            "2790/2790 [==============================] - 0s 103us/step - loss: 0.0084 - accuracy: 0.9907\n",
            "At the end of episode 2809 the total reward was : -21.0\n",
            "Epoch 1/1\n",
            "2798/2798 [==============================] - 0s 102us/step - loss: 0.0035 - accuracy: 0.9932\n",
            "At the end of episode 2810 the total reward was : -16.0\n",
            "Epoch 1/1\n",
            "2610/2610 [==============================] - 0s 102us/step - loss: 0.0073 - accuracy: 0.9931\n",
            "At the end of episode 2811 the total reward was : -20.0\n",
            "Epoch 1/1\n",
            "2517/2517 [==============================] - 0s 100us/step - loss: 9.3543e-04 - accuracy: 0.9932\n",
            "At the end of episode 2812 the total reward was : -15.0\n",
            "Epoch 1/1\n",
            "2993/2993 [==============================] - 0s 107us/step - loss: -0.0010 - accuracy: 0.9930\n",
            "At the end of episode 2813 the total reward was : -15.0\n",
            "Epoch 1/1\n",
            "3125/3125 [==============================] - 0s 109us/step - loss: 0.0021 - accuracy: 0.9949\n",
            "At the end of episode 2814 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2968/2968 [==============================] - 0s 106us/step - loss: -7.1883e-04 - accuracy: 0.9956\n",
            "At the end of episode 2815 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "3129/3129 [==============================] - 0s 104us/step - loss: -0.0024 - accuracy: 0.9898\n",
            "At the end of episode 2816 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "3286/3286 [==============================] - 0s 104us/step - loss: -0.0016 - accuracy: 0.9933\n",
            "At the end of episode 2817 the total reward was : -20.0\n",
            "Epoch 1/1\n",
            "2762/2762 [==============================] - 0s 107us/step - loss: -0.0086 - accuracy: 0.9902\n",
            "At the end of episode 2818 the total reward was : -15.0\n",
            "Epoch 1/1\n",
            "3343/3343 [==============================] - 0s 114us/step - loss: -0.0062 - accuracy: 0.9916\n",
            "At the end of episode 2819 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2984/2984 [==============================] - 0s 109us/step - loss: -0.0077 - accuracy: 0.9893\n",
            "At the end of episode 2820 the total reward was : -21.0\n",
            "Epoch 1/1\n",
            "2544/2544 [==============================] - 0s 110us/step - loss: 0.0096 - accuracy: 0.9945\n",
            "At the end of episode 2821 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "3278/3278 [==============================] - 0s 105us/step - loss: 0.0079 - accuracy: 0.9872\n",
            "At the end of episode 2822 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "3293/3293 [==============================] - 0s 104us/step - loss: 0.0067 - accuracy: 0.9900\n",
            "At the end of episode 2823 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2899/2899 [==============================] - 0s 109us/step - loss: 5.2916e-04 - accuracy: 0.9938\n",
            "At the end of episode 2824 the total reward was : -18.0\n",
            "Epoch 1/1\n",
            "3694/3694 [==============================] - 0s 113us/step - loss: 0.0031 - accuracy: 0.9924\n",
            "At the end of episode 2825 the total reward was : -16.0\n",
            "Epoch 1/1\n",
            "3615/3615 [==============================] - 0s 106us/step - loss: -0.0037 - accuracy: 0.9917\n",
            "At the end of episode 2826 the total reward was : -18.0\n",
            "Epoch 1/1\n",
            "2770/2770 [==============================] - 0s 101us/step - loss: 0.0032 - accuracy: 0.9942\n",
            "At the end of episode 2827 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "1901/1901 [==============================] - 0s 106us/step - loss: 0.0111 - accuracy: 0.9942\n",
            "At the end of episode 2828 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "3265/3265 [==============================] - 0s 102us/step - loss: -0.0101 - accuracy: 0.9926\n",
            "At the end of episode 2829 the total reward was : -18.0\n",
            "Epoch 1/1\n",
            "3197/3197 [==============================] - 0s 101us/step - loss: -5.7590e-04 - accuracy: 0.9928\n",
            "At the end of episode 2830 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "2844/2844 [==============================] - 0s 104us/step - loss: 0.0012 - accuracy: 0.9951\n",
            "At the end of episode 2831 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2825/2825 [==============================] - 0s 108us/step - loss: 0.0085 - accuracy: 0.9912\n",
            "At the end of episode 2832 the total reward was : -20.0\n",
            "Epoch 1/1\n",
            "2760/2760 [==============================] - 0s 106us/step - loss: -0.0079 - accuracy: 0.9928\n",
            "At the end of episode 2833 the total reward was : -18.0\n",
            "Epoch 1/1\n",
            "2930/2930 [==============================] - 0s 102us/step - loss: -0.0045 - accuracy: 0.9870\n",
            "At the end of episode 2834 the total reward was : -18.0\n",
            "Epoch 1/1\n",
            "2441/2441 [==============================] - 0s 104us/step - loss: 7.1641e-04 - accuracy: 0.9939\n",
            "At the end of episode 2835 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "2998/2998 [==============================] - 0s 103us/step - loss: 0.0017 - accuracy: 0.9940\n",
            "At the end of episode 2836 the total reward was : -18.0\n",
            "Epoch 1/1\n",
            "3668/3668 [==============================] - 0s 106us/step - loss: 0.0053 - accuracy: 0.9902\n",
            "At the end of episode 2837 the total reward was : -21.0\n",
            "Epoch 1/1\n",
            "2722/2722 [==============================] - 0s 102us/step - loss: 1.9079e-06 - accuracy: 0.9912\n",
            "At the end of episode 2838 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "3366/3366 [==============================] - 0s 103us/step - loss: -0.0079 - accuracy: 0.9899\n",
            "At the end of episode 2839 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2425/2425 [==============================] - 0s 101us/step - loss: -0.0014 - accuracy: 0.9922\n",
            "At the end of episode 2840 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "2648/2648 [==============================] - 0s 106us/step - loss: 0.0027 - accuracy: 0.9951\n",
            "At the end of episode 2841 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2484/2484 [==============================] - 0s 105us/step - loss: 0.0027 - accuracy: 0.9944\n",
            "At the end of episode 2842 the total reward was : -15.0\n",
            "Epoch 1/1\n",
            "3230/3230 [==============================] - 0s 103us/step - loss: -0.0039 - accuracy: 0.9944\n",
            "At the end of episode 2843 the total reward was : -20.0\n",
            "Epoch 1/1\n",
            "2510/2510 [==============================] - 0s 111us/step - loss: 0.0015 - accuracy: 0.9968\n",
            "At the end of episode 2844 the total reward was : -18.0\n",
            "Epoch 1/1\n",
            "2601/2601 [==============================] - 0s 103us/step - loss: 0.0013 - accuracy: 0.9958\n",
            "At the end of episode 2845 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2746/2746 [==============================] - 0s 102us/step - loss: 2.3498e-04 - accuracy: 0.9916\n",
            "At the end of episode 2846 the total reward was : -15.0\n",
            "Epoch 1/1\n",
            "2774/2774 [==============================] - 0s 103us/step - loss: 0.0018 - accuracy: 0.9946\n",
            "At the end of episode 2847 the total reward was : -16.0\n",
            "Epoch 1/1\n",
            "2884/2884 [==============================] - 0s 105us/step - loss: -0.0016 - accuracy: 0.9920\n",
            "At the end of episode 2848 the total reward was : -16.0\n",
            "Epoch 1/1\n",
            "3106/3106 [==============================] - 0s 103us/step - loss: -0.0026 - accuracy: 0.9903\n",
            "At the end of episode 2849 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "3489/3489 [==============================] - 0s 101us/step - loss: -0.0061 - accuracy: 0.9900\n",
            "At the end of episode 2850 the total reward was : -16.0\n",
            "Epoch 1/1\n",
            "3351/3351 [==============================] - 0s 108us/step - loss: 0.0013 - accuracy: 0.9937\n",
            "At the end of episode 2851 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "3158/3158 [==============================] - 0s 105us/step - loss: -0.0022 - accuracy: 0.9959\n",
            "At the end of episode 2852 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2736/2736 [==============================] - 0s 101us/step - loss: 0.0140 - accuracy: 0.9956\n",
            "At the end of episode 2853 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "2581/2581 [==============================] - 0s 105us/step - loss: 4.8569e-04 - accuracy: 0.9895\n",
            "At the end of episode 2854 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "2894/2894 [==============================] - 0s 106us/step - loss: 0.0086 - accuracy: 0.9945\n",
            "At the end of episode 2855 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "2350/2350 [==============================] - 0s 102us/step - loss: -0.0023 - accuracy: 0.9970\n",
            "At the end of episode 2856 the total reward was : -18.0\n",
            "Epoch 1/1\n",
            "3014/3014 [==============================] - 0s 102us/step - loss: 2.7231e-04 - accuracy: 0.9947\n",
            "At the end of episode 2857 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "2655/2655 [==============================] - 0s 104us/step - loss: 0.0012 - accuracy: 0.9913\n",
            "At the end of episode 2858 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "3332/3332 [==============================] - 0s 106us/step - loss: -0.0024 - accuracy: 0.9931\n",
            "At the end of episode 2859 the total reward was : -13.0\n",
            "Epoch 1/1\n",
            "3256/3256 [==============================] - 0s 104us/step - loss: -0.0023 - accuracy: 0.9920\n",
            "At the end of episode 2860 the total reward was : -18.0\n",
            "Epoch 1/1\n",
            "2614/2614 [==============================] - 0s 103us/step - loss: 1.9834e-04 - accuracy: 0.9962\n",
            "At the end of episode 2861 the total reward was : -18.0\n",
            "Epoch 1/1\n",
            "3106/3106 [==============================] - 0s 103us/step - loss: 5.4443e-04 - accuracy: 0.9923\n",
            "At the end of episode 2862 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "2907/2907 [==============================] - 0s 103us/step - loss: -0.0088 - accuracy: 0.9862\n",
            "At the end of episode 2863 the total reward was : -15.0\n",
            "Epoch 1/1\n",
            "3315/3315 [==============================] - 0s 103us/step - loss: 3.1289e-04 - accuracy: 0.9940\n",
            "At the end of episode 2864 the total reward was : -21.0\n",
            "Epoch 1/1\n",
            "3116/3116 [==============================] - 0s 103us/step - loss: -0.0092 - accuracy: 0.9933\n",
            "At the end of episode 2865 the total reward was : -18.0\n",
            "Epoch 1/1\n",
            "2630/2630 [==============================] - 0s 102us/step - loss: -0.0056 - accuracy: 0.9932\n",
            "At the end of episode 2866 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2338/2338 [==============================] - 0s 107us/step - loss: 0.0049 - accuracy: 0.9927\n",
            "At the end of episode 2867 the total reward was : -16.0\n",
            "Epoch 1/1\n",
            "2946/2946 [==============================] - 0s 106us/step - loss: -7.1544e-04 - accuracy: 0.9952\n",
            "At the end of episode 2868 the total reward was : -14.0\n",
            "Epoch 1/1\n",
            "2976/2976 [==============================] - 0s 104us/step - loss: 0.0167 - accuracy: 0.9936\n",
            "At the end of episode 2869 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "2829/2829 [==============================] - 0s 104us/step - loss: 0.0051 - accuracy: 0.9912\n",
            "At the end of episode 2870 the total reward was : -20.0\n",
            "Epoch 1/1\n",
            "2677/2677 [==============================] - 0s 106us/step - loss: 0.0034 - accuracy: 0.9959\n",
            "At the end of episode 2871 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2181/2181 [==============================] - 0s 108us/step - loss: 0.0038 - accuracy: 0.9936\n",
            "At the end of episode 2872 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "3227/3227 [==============================] - 0s 100us/step - loss: 0.0056 - accuracy: 0.9913\n",
            "At the end of episode 2873 the total reward was : -18.0\n",
            "Epoch 1/1\n",
            "3295/3295 [==============================] - 0s 103us/step - loss: -0.0096 - accuracy: 0.9882\n",
            "At the end of episode 2874 the total reward was : -16.0\n",
            "Epoch 1/1\n",
            "3105/3105 [==============================] - 0s 107us/step - loss: -0.0058 - accuracy: 0.9913\n",
            "At the end of episode 2875 the total reward was : -15.0\n",
            "Epoch 1/1\n",
            "3158/3158 [==============================] - 0s 106us/step - loss: -0.0020 - accuracy: 0.9892\n",
            "At the end of episode 2876 the total reward was : -18.0\n",
            "Epoch 1/1\n",
            "3564/3564 [==============================] - 0s 113us/step - loss: -0.0070 - accuracy: 0.9804\n",
            "At the end of episode 2877 the total reward was : -21.0\n",
            "Epoch 1/1\n",
            "3315/3315 [==============================] - 0s 110us/step - loss: -0.0019 - accuracy: 0.9882\n",
            "At the end of episode 2878 the total reward was : -15.0\n",
            "Epoch 1/1\n",
            "3648/3648 [==============================] - 0s 108us/step - loss: -0.0038 - accuracy: 0.9907\n",
            "At the end of episode 2879 the total reward was : -18.0\n",
            "Epoch 1/1\n",
            "2689/2689 [==============================] - 0s 107us/step - loss: -0.0039 - accuracy: 0.9922\n",
            "At the end of episode 2880 the total reward was : -18.0\n",
            "Epoch 1/1\n",
            "2474/2474 [==============================] - 0s 110us/step - loss: -0.0104 - accuracy: 0.9895\n",
            "At the end of episode 2881 the total reward was : -21.0\n",
            "Epoch 1/1\n",
            "2958/2958 [==============================] - 0s 103us/step - loss: 7.6730e-04 - accuracy: 0.9926\n",
            "At the end of episode 2882 the total reward was : -18.0\n",
            "Epoch 1/1\n",
            "2449/2449 [==============================] - 0s 102us/step - loss: 0.0072 - accuracy: 0.9873\n",
            "At the end of episode 2883 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "3099/3099 [==============================] - 0s 107us/step - loss: -4.4798e-04 - accuracy: 0.9948\n",
            "At the end of episode 2884 the total reward was : -15.0\n",
            "Epoch 1/1\n",
            "2273/2273 [==============================] - 0s 107us/step - loss: -0.0041 - accuracy: 0.9938\n",
            "At the end of episode 2885 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2611/2611 [==============================] - 0s 107us/step - loss: 0.0026 - accuracy: 0.9939\n",
            "At the end of episode 2886 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2606/2606 [==============================] - 0s 105us/step - loss: 0.0040 - accuracy: 0.9923\n",
            "At the end of episode 2887 the total reward was : -18.0\n",
            "Epoch 1/1\n",
            "2423/2423 [==============================] - 0s 103us/step - loss: -0.0025 - accuracy: 0.9938\n",
            "At the end of episode 2888 the total reward was : -18.0\n",
            "Epoch 1/1\n",
            "2926/2926 [==============================] - 0s 104us/step - loss: 0.0149 - accuracy: 0.9935\n",
            "At the end of episode 2889 the total reward was : -15.0\n",
            "Epoch 1/1\n",
            "2691/2691 [==============================] - 0s 111us/step - loss: -9.1184e-04 - accuracy: 0.9900\n",
            "At the end of episode 2890 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "2262/2262 [==============================] - 0s 109us/step - loss: -0.0036 - accuracy: 0.9907\n",
            "At the end of episode 2891 the total reward was : -20.0\n",
            "Epoch 1/1\n",
            "2374/2374 [==============================] - 0s 104us/step - loss: 2.8524e-04 - accuracy: 0.9945\n",
            "At the end of episode 2892 the total reward was : -16.0\n",
            "Epoch 1/1\n",
            "2950/2950 [==============================] - 0s 101us/step - loss: -0.0030 - accuracy: 0.9905\n",
            "At the end of episode 2893 the total reward was : -15.0\n",
            "Epoch 1/1\n",
            "2492/2492 [==============================] - 0s 107us/step - loss: -0.0064 - accuracy: 0.9916\n",
            "At the end of episode 2894 the total reward was : -20.0\n",
            "Epoch 1/1\n",
            "2538/2538 [==============================] - 0s 110us/step - loss: -0.0033 - accuracy: 0.9957\n",
            "At the end of episode 2895 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2243/2243 [==============================] - 0s 103us/step - loss: -0.0017 - accuracy: 0.9947\n",
            "At the end of episode 2896 the total reward was : -21.0\n",
            "Epoch 1/1\n",
            "2559/2559 [==============================] - 0s 100us/step - loss: 0.0034 - accuracy: 0.9949\n",
            "At the end of episode 2897 the total reward was : -18.0\n",
            "Epoch 1/1\n",
            "2690/2690 [==============================] - 0s 108us/step - loss: -9.0798e-04 - accuracy: 0.9981\n",
            "At the end of episode 2898 the total reward was : -18.0\n",
            "Epoch 1/1\n",
            "2596/2596 [==============================] - 0s 112us/step - loss: -0.0197 - accuracy: 0.9846\n",
            "At the end of episode 2899 the total reward was : -18.0\n",
            "Epoch 1/1\n",
            "2525/2525 [==============================] - 0s 111us/step - loss: -0.0022 - accuracy: 0.9901\n",
            "At the end of episode 2900 the total reward was : -18.0\n",
            "Epoch 1/1\n",
            "2120/2120 [==============================] - 0s 109us/step - loss: 0.0152 - accuracy: 0.9925\n",
            "At the end of episode 2901 the total reward was : -16.0\n",
            "Epoch 1/1\n",
            "2391/2391 [==============================] - 0s 101us/step - loss: 0.0079 - accuracy: 0.9916\n",
            "At the end of episode 2902 the total reward was : -18.0\n",
            "Epoch 1/1\n",
            "2118/2118 [==============================] - 0s 99us/step - loss: 0.0011 - accuracy: 0.9943\n",
            "At the end of episode 2903 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2653/2653 [==============================] - 0s 101us/step - loss: -0.0074 - accuracy: 0.9827\n",
            "At the end of episode 2904 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2884/2884 [==============================] - 0s 105us/step - loss: -0.0055 - accuracy: 0.9927\n",
            "At the end of episode 2905 the total reward was : -21.0\n",
            "Epoch 1/1\n",
            "2318/2318 [==============================] - 0s 105us/step - loss: -0.0055 - accuracy: 0.9905\n",
            "At the end of episode 2906 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2486/2486 [==============================] - 0s 106us/step - loss: -0.0018 - accuracy: 0.9928\n",
            "At the end of episode 2907 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "2338/2338 [==============================] - 0s 103us/step - loss: -3.2554e-04 - accuracy: 0.9936\n",
            "At the end of episode 2908 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2333/2333 [==============================] - 0s 108us/step - loss: -0.0031 - accuracy: 0.9940\n",
            "At the end of episode 2909 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2253/2253 [==============================] - 0s 104us/step - loss: 0.0015 - accuracy: 0.9964\n",
            "At the end of episode 2910 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "1580/1580 [==============================] - 0s 127us/step - loss: 0.0019 - accuracy: 0.9962\n",
            "At the end of episode 2911 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2426/2426 [==============================] - 0s 102us/step - loss: -0.0024 - accuracy: 0.9955\n",
            "At the end of episode 2912 the total reward was : -16.0\n",
            "Epoch 1/1\n",
            "3209/3209 [==============================] - 0s 103us/step - loss: -7.2277e-04 - accuracy: 0.9941\n",
            "At the end of episode 2913 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2591/2591 [==============================] - 0s 99us/step - loss: -6.6689e-04 - accuracy: 0.9946\n",
            "At the end of episode 2914 the total reward was : -18.0\n",
            "Epoch 1/1\n",
            "2602/2602 [==============================] - 0s 101us/step - loss: -0.0028 - accuracy: 0.9942\n",
            "At the end of episode 2915 the total reward was : -20.0\n",
            "Epoch 1/1\n",
            "3095/3095 [==============================] - 0s 106us/step - loss: -0.0015 - accuracy: 0.9929\n",
            "At the end of episode 2916 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2652/2652 [==============================] - 0s 106us/step - loss: 0.0029 - accuracy: 0.9925\n",
            "At the end of episode 2917 the total reward was : -15.0\n",
            "Epoch 1/1\n",
            "2889/2889 [==============================] - 0s 104us/step - loss: 0.0027 - accuracy: 0.9900\n",
            "At the end of episode 2918 the total reward was : -18.0\n",
            "Epoch 1/1\n",
            "3102/3102 [==============================] - 0s 103us/step - loss: 0.0015 - accuracy: 0.9919\n",
            "At the end of episode 2919 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "2430/2430 [==============================] - 0s 101us/step - loss: -0.0027 - accuracy: 0.9967\n",
            "At the end of episode 2920 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2648/2648 [==============================] - 0s 105us/step - loss: 0.0070 - accuracy: 0.9928\n",
            "At the end of episode 2921 the total reward was : -16.0\n",
            "Epoch 1/1\n",
            "2699/2699 [==============================] - 0s 103us/step - loss: 0.0046 - accuracy: 0.9941\n",
            "At the end of episode 2922 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "2678/2678 [==============================] - 0s 103us/step - loss: -0.0085 - accuracy: 0.9937\n",
            "At the end of episode 2923 the total reward was : -15.0\n",
            "Epoch 1/1\n",
            "2759/2759 [==============================] - 0s 101us/step - loss: -0.0040 - accuracy: 0.9906\n",
            "At the end of episode 2924 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "2569/2569 [==============================] - 0s 105us/step - loss: -0.0050 - accuracy: 0.9949\n",
            "At the end of episode 2925 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "3095/3095 [==============================] - 0s 109us/step - loss: -4.3837e-04 - accuracy: 0.9913\n",
            "At the end of episode 2926 the total reward was : -15.0\n",
            "Epoch 1/1\n",
            "2946/2946 [==============================] - 0s 101us/step - loss: -0.0028 - accuracy: 0.9942\n",
            "At the end of episode 2927 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "2189/2189 [==============================] - 0s 103us/step - loss: 0.0072 - accuracy: 0.9904\n",
            "At the end of episode 2928 the total reward was : -21.0\n",
            "Epoch 1/1\n",
            "2564/2564 [==============================] - 0s 102us/step - loss: 7.2237e-04 - accuracy: 0.9906\n",
            "At the end of episode 2929 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2651/2651 [==============================] - 0s 99us/step - loss: -0.0099 - accuracy: 0.9921\n",
            "At the end of episode 2930 the total reward was : -16.0\n",
            "Epoch 1/1\n",
            "2387/2387 [==============================] - 0s 104us/step - loss: -0.0065 - accuracy: 0.9920\n",
            "At the end of episode 2931 the total reward was : -18.0\n",
            "Epoch 1/1\n",
            "2203/2203 [==============================] - 0s 109us/step - loss: 0.0154 - accuracy: 0.9909\n",
            "At the end of episode 2932 the total reward was : -16.0\n",
            "Epoch 1/1\n",
            "2551/2551 [==============================] - 0s 101us/step - loss: -0.0023 - accuracy: 0.9929\n",
            "At the end of episode 2933 the total reward was : -16.0\n",
            "Epoch 1/1\n",
            "2628/2628 [==============================] - 0s 109us/step - loss: 0.0033 - accuracy: 0.9935\n",
            "At the end of episode 2934 the total reward was : -15.0\n",
            "Epoch 1/1\n",
            "2200/2200 [==============================] - 0s 102us/step - loss: 0.0041 - accuracy: 0.9873\n",
            "At the end of episode 2935 the total reward was : -15.0\n",
            "Epoch 1/1\n",
            "1953/1953 [==============================] - 0s 100us/step - loss: -0.0022 - accuracy: 0.9928\n",
            "At the end of episode 2936 the total reward was : -16.0\n",
            "Epoch 1/1\n",
            "2148/2148 [==============================] - 0s 102us/step - loss: 0.0042 - accuracy: 0.9949\n",
            "At the end of episode 2937 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "1928/1928 [==============================] - 0s 103us/step - loss: -0.0026 - accuracy: 0.9927\n",
            "At the end of episode 2938 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "1913/1913 [==============================] - 0s 103us/step - loss: -0.0013 - accuracy: 0.9969\n",
            "At the end of episode 2939 the total reward was : -21.0\n",
            "Epoch 1/1\n",
            "1985/1985 [==============================] - 0s 103us/step - loss: -0.0035 - accuracy: 0.9945\n",
            "At the end of episode 2940 the total reward was : -18.0\n",
            "Epoch 1/1\n",
            "2220/2220 [==============================] - 0s 102us/step - loss: -0.0018 - accuracy: 0.9928\n",
            "At the end of episode 2941 the total reward was : -20.0\n",
            "Epoch 1/1\n",
            "1874/1874 [==============================] - 0s 104us/step - loss: -0.0057 - accuracy: 0.9941\n",
            "At the end of episode 2942 the total reward was : -21.0\n",
            "Epoch 1/1\n",
            "1490/1490 [==============================] - 0s 104us/step - loss: -0.0138 - accuracy: 0.9866\n",
            "At the end of episode 2943 the total reward was : -20.0\n",
            "Epoch 1/1\n",
            "1954/1954 [==============================] - 0s 103us/step - loss: 0.0078 - accuracy: 0.9908\n",
            "At the end of episode 2944 the total reward was : -16.0\n",
            "Epoch 1/1\n",
            "2495/2495 [==============================] - 0s 101us/step - loss: -0.0035 - accuracy: 0.9912\n",
            "At the end of episode 2945 the total reward was : -15.0\n",
            "Epoch 1/1\n",
            "2744/2744 [==============================] - 0s 104us/step - loss: 0.0036 - accuracy: 0.9894\n",
            "At the end of episode 2946 the total reward was : -16.0\n",
            "Epoch 1/1\n",
            "2468/2468 [==============================] - 0s 104us/step - loss: -0.0066 - accuracy: 0.9887\n",
            "At the end of episode 2947 the total reward was : -20.0\n",
            "Epoch 1/1\n",
            "1889/1889 [==============================] - 0s 110us/step - loss: -0.0040 - accuracy: 0.9894\n",
            "At the end of episode 2948 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2499/2499 [==============================] - 0s 103us/step - loss: 0.0056 - accuracy: 0.9944\n",
            "At the end of episode 2949 the total reward was : -15.0\n",
            "Epoch 1/1\n",
            "2688/2688 [==============================] - 0s 100us/step - loss: -3.9107e-04 - accuracy: 0.9944\n",
            "At the end of episode 2950 the total reward was : -16.0\n",
            "Epoch 1/1\n",
            "2331/2331 [==============================] - 0s 103us/step - loss: 2.6364e-04 - accuracy: 0.9927\n",
            "At the end of episode 2951 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2329/2329 [==============================] - 0s 101us/step - loss: -0.0102 - accuracy: 0.9871\n",
            "At the end of episode 2952 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "2846/2846 [==============================] - 0s 102us/step - loss: -0.0031 - accuracy: 0.9951\n",
            "At the end of episode 2953 the total reward was : -12.0\n",
            "Epoch 1/1\n",
            "2649/2649 [==============================] - 0s 103us/step - loss: -7.0567e-04 - accuracy: 0.9924\n",
            "At the end of episode 2954 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2256/2256 [==============================] - 0s 103us/step - loss: -0.0071 - accuracy: 0.9885\n",
            "At the end of episode 2955 the total reward was : -18.0\n",
            "Epoch 1/1\n",
            "2993/2993 [==============================] - 0s 106us/step - loss: 0.0068 - accuracy: 0.9933\n",
            "At the end of episode 2956 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "2827/2827 [==============================] - 0s 103us/step - loss: -0.0041 - accuracy: 0.9915\n",
            "At the end of episode 2957 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "2558/2558 [==============================] - 0s 107us/step - loss: 0.0041 - accuracy: 0.9941\n",
            "At the end of episode 2958 the total reward was : -15.0\n",
            "Epoch 1/1\n",
            "2830/2830 [==============================] - 0s 103us/step - loss: -0.0015 - accuracy: 0.9965\n",
            "At the end of episode 2959 the total reward was : -18.0\n",
            "Epoch 1/1\n",
            "3018/3018 [==============================] - 0s 104us/step - loss: -0.0019 - accuracy: 0.9940\n",
            "At the end of episode 2960 the total reward was : -18.0\n",
            "Epoch 1/1\n",
            "3036/3036 [==============================] - 0s 108us/step - loss: -0.0043 - accuracy: 0.9895\n",
            "At the end of episode 2961 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2333/2333 [==============================] - 0s 109us/step - loss: 0.0034 - accuracy: 0.9919\n",
            "At the end of episode 2962 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2678/2678 [==============================] - 0s 106us/step - loss: 0.0068 - accuracy: 0.9940\n",
            "At the end of episode 2963 the total reward was : -18.0\n",
            "Epoch 1/1\n",
            "2709/2709 [==============================] - 0s 109us/step - loss: 0.0042 - accuracy: 0.9904\n",
            "At the end of episode 2964 the total reward was : -15.0\n",
            "Epoch 1/1\n",
            "2760/2760 [==============================] - 0s 109us/step - loss: -0.0040 - accuracy: 0.9924\n",
            "At the end of episode 2965 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "2746/2746 [==============================] - 0s 102us/step - loss: -0.0058 - accuracy: 0.9920\n",
            "At the end of episode 2966 the total reward was : -16.0\n",
            "Epoch 1/1\n",
            "2781/2781 [==============================] - 0s 103us/step - loss: -0.0015 - accuracy: 0.9950\n",
            "At the end of episode 2967 the total reward was : -18.0\n",
            "Epoch 1/1\n",
            "2609/2609 [==============================] - 0s 99us/step - loss: -0.0141 - accuracy: 0.9889\n",
            "At the end of episode 2968 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2639/2639 [==============================] - 0s 107us/step - loss: 0.0062 - accuracy: 0.9928\n",
            "At the end of episode 2969 the total reward was : -18.0\n",
            "Epoch 1/1\n",
            "2853/2853 [==============================] - 0s 101us/step - loss: -0.0342 - accuracy: 0.9867\n",
            "At the end of episode 2970 the total reward was : -20.0\n",
            "Epoch 1/1\n",
            "2764/2764 [==============================] - 0s 107us/step - loss: -0.0033 - accuracy: 0.9920\n",
            "At the end of episode 2971 the total reward was : -16.0\n",
            "Epoch 1/1\n",
            "2465/2465 [==============================] - 0s 106us/step - loss: -0.0017 - accuracy: 0.9951\n",
            "At the end of episode 2972 the total reward was : -16.0\n",
            "Epoch 1/1\n",
            "2306/2306 [==============================] - 0s 107us/step - loss: 6.5104e-04 - accuracy: 0.9944\n",
            "At the end of episode 2973 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "2801/2801 [==============================] - 0s 107us/step - loss: 0.0018 - accuracy: 0.9946\n",
            "At the end of episode 2974 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "2512/2512 [==============================] - 0s 103us/step - loss: -0.0077 - accuracy: 0.9900\n",
            "At the end of episode 2975 the total reward was : -20.0\n",
            "Epoch 1/1\n",
            "2038/2038 [==============================] - 0s 101us/step - loss: 0.0018 - accuracy: 0.9951\n",
            "At the end of episode 2976 the total reward was : -15.0\n",
            "Epoch 1/1\n",
            "2840/2840 [==============================] - 0s 108us/step - loss: -0.0049 - accuracy: 0.9923\n",
            "At the end of episode 2977 the total reward was : -13.0\n",
            "Epoch 1/1\n",
            "3878/3878 [==============================] - 0s 104us/step - loss: -0.0038 - accuracy: 0.9899\n",
            "At the end of episode 2978 the total reward was : -14.0\n",
            "Epoch 1/1\n",
            "3124/3124 [==============================] - 0s 108us/step - loss: -0.0075 - accuracy: 0.9901\n",
            "At the end of episode 2979 the total reward was : -20.0\n",
            "Epoch 1/1\n",
            "2438/2438 [==============================] - 0s 105us/step - loss: 8.2633e-04 - accuracy: 0.9959\n",
            "At the end of episode 2980 the total reward was : -21.0\n",
            "Epoch 1/1\n",
            "2717/2717 [==============================] - 0s 108us/step - loss: 0.0039 - accuracy: 0.9934\n",
            "At the end of episode 2981 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "3312/3312 [==============================] - 0s 107us/step - loss: -0.0019 - accuracy: 0.9885\n",
            "At the end of episode 2982 the total reward was : -18.0\n",
            "Epoch 1/1\n",
            "2294/2294 [==============================] - 0s 101us/step - loss: -0.0012 - accuracy: 0.9922\n",
            "At the end of episode 2983 the total reward was : -15.0\n",
            "Epoch 1/1\n",
            "2281/2281 [==============================] - 0s 104us/step - loss: 0.0077 - accuracy: 0.9899\n",
            "At the end of episode 2984 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "2770/2770 [==============================] - 0s 102us/step - loss: -7.2956e-04 - accuracy: 0.9968\n",
            "At the end of episode 2985 the total reward was : -20.0\n",
            "Epoch 1/1\n",
            "1706/1706 [==============================] - 0s 101us/step - loss: -0.0043 - accuracy: 0.9959\n",
            "At the end of episode 2986 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "1693/1693 [==============================] - 0s 106us/step - loss: -0.0021 - accuracy: 0.9947\n",
            "At the end of episode 2987 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "2819/2819 [==============================] - 0s 106us/step - loss: 0.0028 - accuracy: 0.9965\n",
            "At the end of episode 2988 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "1928/1928 [==============================] - 0s 104us/step - loss: -9.8504e-05 - accuracy: 0.9953\n",
            "At the end of episode 2989 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2157/2157 [==============================] - 0s 107us/step - loss: -0.0010 - accuracy: 0.9940\n",
            "At the end of episode 2990 the total reward was : -20.0\n",
            "Epoch 1/1\n",
            "3025/3025 [==============================] - 0s 101us/step - loss: 0.0051 - accuracy: 0.9944\n",
            "At the end of episode 2991 the total reward was : -18.0\n",
            "Epoch 1/1\n",
            "2791/2791 [==============================] - 0s 101us/step - loss: 5.2438e-05 - accuracy: 0.9961\n",
            "At the end of episode 2992 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "3630/3630 [==============================] - 0s 113us/step - loss: 0.0132 - accuracy: 0.9873\n",
            "At the end of episode 2993 the total reward was : -20.0\n",
            "Epoch 1/1\n",
            "2983/2983 [==============================] - 0s 105us/step - loss: 0.0031 - accuracy: 0.9960\n",
            "At the end of episode 2994 the total reward was : -21.0\n",
            "Epoch 1/1\n",
            "2552/2552 [==============================] - 0s 101us/step - loss: 0.0024 - accuracy: 0.9902\n",
            "At the end of episode 2995 the total reward was : -18.0\n",
            "Epoch 1/1\n",
            "2877/2877 [==============================] - 0s 108us/step - loss: 0.0042 - accuracy: 0.9944\n",
            "At the end of episode 2996 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "2354/2354 [==============================] - 0s 105us/step - loss: -0.0033 - accuracy: 0.9958\n",
            "At the end of episode 2997 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "2332/2332 [==============================] - 0s 103us/step - loss: -0.0016 - accuracy: 0.9961\n",
            "At the end of episode 2998 the total reward was : -15.0\n",
            "Epoch 1/1\n",
            "3085/3085 [==============================] - 0s 105us/step - loss: 0.0069 - accuracy: 0.9906\n",
            "At the end of episode 2999 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "3473/3473 [==============================] - 0s 103us/step - loss: 0.0106 - accuracy: 0.9899\n",
            "At the end of episode 3000 the total reward was : -16.0\n",
            "Epoch 1/1\n",
            "3202/3202 [==============================] - 0s 101us/step - loss: 5.5843e-04 - accuracy: 0.9928\n",
            "At the end of episode 3001 the total reward was : -18.0\n",
            "Epoch 1/1\n",
            "2546/2546 [==============================] - 0s 100us/step - loss: 2.4706e-04 - accuracy: 0.9914\n",
            "At the end of episode 3002 the total reward was : -18.0\n",
            "Epoch 1/1\n",
            "3025/3025 [==============================] - 0s 115us/step - loss: -0.0045 - accuracy: 0.9914\n",
            "At the end of episode 3003 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2393/2393 [==============================] - 0s 106us/step - loss: -4.9295e-04 - accuracy: 0.9983\n",
            "At the end of episode 3004 the total reward was : -16.0\n",
            "Epoch 1/1\n",
            "2961/2961 [==============================] - 0s 106us/step - loss: -0.0022 - accuracy: 0.9932\n",
            "At the end of episode 3005 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2194/2194 [==============================] - 0s 102us/step - loss: 0.0036 - accuracy: 0.9954\n",
            "At the end of episode 3006 the total reward was : -18.0\n",
            "Epoch 1/1\n",
            "3329/3329 [==============================] - 0s 108us/step - loss: -8.0223e-06 - accuracy: 0.9910\n",
            "At the end of episode 3007 the total reward was : -18.0\n",
            "Epoch 1/1\n",
            "2614/2614 [==============================] - 0s 108us/step - loss: 0.0018 - accuracy: 0.9954\n",
            "At the end of episode 3008 the total reward was : -16.0\n",
            "Epoch 1/1\n",
            "2644/2644 [==============================] - 0s 109us/step - loss: 7.1253e-04 - accuracy: 0.9921\n",
            "At the end of episode 3009 the total reward was : -19.0\n",
            "Epoch 1/1\n",
            "2562/2562 [==============================] - 0s 107us/step - loss: 0.0028 - accuracy: 0.9953\n",
            "At the end of episode 3010 the total reward was : -17.0\n",
            "Epoch 1/1\n",
            "2655/2655 [==============================] - 0s 103us/step - loss: 0.0036 - accuracy: 0.9906\n",
            "At the end of episode 3011 the total reward was : -16.0\n",
            "Epoch 1/1\n",
            "2873/2873 [==============================] - 0s 106us/step - loss: 6.7596e-04 - accuracy: 0.9920\n",
            "At the end of episode 3012 the total reward was : -15.0\n",
            "Epoch 1/1\n",
            "2609/2609 [==============================] - 0s 103us/step - loss: 0.0046 - accuracy: 0.9916\n",
            "At the end of episode 3013 the total reward was : -20.0\n",
            "Epoch 1/1\n",
            "2684/2684 [==============================] - 0s 102us/step - loss: 0.0039 - accuracy: 0.9899\n",
            "At the end of episode 3014 the total reward was : -20.0\n",
            "Epoch 1/1\n",
            "2539/2539 [==============================] - 0s 107us/step - loss: 2.4655e-04 - accuracy: 0.9945\n",
            "At the end of episode 3015 the total reward was : -21.0\n",
            "Epoch 1/1\n",
            "2717/2717 [==============================] - 0s 105us/step - loss: 0.0014 - accuracy: 0.9901\n",
            "At the end of episode 3016 the total reward was : -12.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fCw3UvnoKfJ4",
        "colab_type": "code",
        "outputId": "4cece93c-a069-4645-f2c3-c439243fac73",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "plt.plot(history)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XQz1o8RGW3cH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save(\"model.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8paHYCNPKn27",
        "colab_type": "code",
        "outputId": "b41bb12a-5e5c-4057-d940-9a3a8a3b6e9b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 421
        }
      },
      "source": [
        "import gym\n",
        "from gym import logger as gymlogger\n",
        "from gym.wrappers import Monitor\n",
        "gymlogger.set_level(40) #error only\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import random\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import math\n",
        "import glob\n",
        "import io\n",
        "import base64\n",
        "from IPython.display import HTML\n",
        "from IPython import display as ipythondisplay\n",
        "from pyvirtualdisplay import Display\n",
        "display = Display(visible=0, size=(1400, 900))\n",
        "display.start()\n",
        "\n",
        "def show_video():\n",
        "  mp4list = glob.glob('video/*.mp4')\n",
        "  if len(mp4list) > 0:\n",
        "    mp4 = mp4list[0]\n",
        "    video = io.open(mp4, 'r+b').read()\n",
        "    encoded = base64.b64encode(video)\n",
        "    ipythondisplay.display(HTML(data='''<video alt=\"test\" autoplay \n",
        "                loop controls style=\"height: 400px;\">\n",
        "                <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" />\n",
        "             </video>'''.format(encoded.decode('ascii'))))\n",
        "  else: \n",
        "    print(\"Could not find video\")\n",
        "def wrap_env(env):\n",
        "  env = Monitor(env, './video', force=True)\n",
        "  return env\n",
        "# Evaluate enviroment based on trained weigths\n",
        "env = wrap_env(gym.make('Pong-v0'))\n",
        "observation = env.reset()\n",
        "new_observation = observation\n",
        "prev_input = None\n",
        "done = False\n",
        "while True:\n",
        "  if True: \n",
        "    \n",
        "    #set input to network to be difference image\n",
        "    cur_input = prepro(observation)\n",
        "    x = cur_input - prev_input if prev_input is not None else np.zeros(80 * 80)\n",
        "    prev_input = cur_input\n",
        "  \n",
        "    # Sample an action\n",
        "    proba = model.predict(np.expand_dims(x, axis=1).T)\n",
        "    action = UP_ACTION if np.random.uniform() < proba else DOWN_ACTION\n",
        "        \n",
        "    env.render()\n",
        "    # Return action to environment and extract\n",
        "    #next observation, reward, and status\n",
        "    observation = new_observation\n",
        "    new_observation, reward, done, info = env.step(action)\n",
        "    if done: \n",
        "      #observation = env.reset()\n",
        "      break\n",
        "      \n",
        "env.close()\n",
        "show_video()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<video alt=\"test\" autoplay \n",
              "                loop controls style=\"height: 400px;\">\n",
              "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
              "             </video>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}